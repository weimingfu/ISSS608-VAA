[
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html",
    "title": "Be Weatherwise or Otherwise",
    "section": "",
    "text": "Singapore has undertaken three National Climate Change Studies to better understand the potential impact of climate change on the country. A report from the study documented the following findings on the possible impact of climate change in Singapore:\n\nDaily mean temperature are projected to increase by 1.4 to 4.6, and\nThe contrast between the wet months (November to January) and dry month (February and June to September) is likely to be more pronounced.\n\n\n\n\n\n\n\n\n\nIn this take-home exercise, we will explore the impact of climate change on daily temperature, boxed-up in red in the diagram above, in Singapore by applying interactive techniques to enhance the user experience in data discovery and/or visual story-telling. In doing so, we will use visual interactivity and visualising uncertainty methods to validate these claims:\n\nFrom 1948 to 2016, annual mean temperatures rose at an average rate of 0.25℃ per decade\nDaily mean temperatures are projected to increase by 1.4℃ to 4.6℃\n\n\n\n\nThe data used in this study are the historical daily temperature data obtained from the Meteorological Service Singapore website. The daily temperature records of the years 1983, 1993, 2003, 2013 and 2023 for Changi weather station are downloaded and used in this study to create an analytics-driven data visualisation."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#setting-the-scene",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#setting-the-scene",
    "title": "Be Weatherwise or Otherwise",
    "section": "",
    "text": "Singapore has undertaken three National Climate Change Studies to better understand the potential impact of climate change on the country. A report from the study documented the following findings on the possible impact of climate change in Singapore:\n\nDaily mean temperature are projected to increase by 1.4 to 4.6, and\nThe contrast between the wet months (November to January) and dry month (February and June to September) is likely to be more pronounced."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#the-task",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#the-task",
    "title": "Be Weatherwise or Otherwise",
    "section": "",
    "text": "In this take-home exercise, we will explore the impact of climate change on daily temperature, boxed-up in red in the diagram above, in Singapore by applying interactive techniques to enhance the user experience in data discovery and/or visual story-telling. In doing so, we will use visual interactivity and visualising uncertainty methods to validate these claims:\n\nFrom 1948 to 2016, annual mean temperatures rose at an average rate of 0.25℃ per decade\nDaily mean temperatures are projected to increase by 1.4℃ to 4.6℃"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#the-data",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#the-data",
    "title": "Be Weatherwise or Otherwise",
    "section": "",
    "text": "The data used in this study are the historical daily temperature data obtained from the Meteorological Service Singapore website. The daily temperature records of the years 1983, 1993, 2003, 2013 and 2023 for Changi weather station are downloaded and used in this study to create an analytics-driven data visualisation."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#loading-r-packages",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#loading-r-packages",
    "title": "Be Weatherwise or Otherwise",
    "section": "2.1 Loading R packages",
    "text": "2.1 Loading R packages\nThe pacman::p_load() function is used to install and load the required R packages into the R environment, as below.\n\ntidyverse: collection of R packages designed for data science\npatchwork: an R package for preparing composite figure created using ggplot2\nDT: an R package to render interactive DataTables\nplotly: an R graphing library for plotting interactive, publication-quality graphs\nggiraph: an R library for creating interactive ggplot2 graphics using ’htmlwidgets\ngifski: an R library for converting images to gif animations\ngganimate: an R package that extends ggplot2 to include the description of animation\nggthemes: an R package provides some extra themes, geoms, and scales for ‘ggplot2’\nknitr: an R package for dynamic report generation\nungeviz: an R package for visualizing uncertainty with ggplot2\nmanipulateWidget: A framework for creating HTML widgets that render in various contexts including the R console, ‘R Markdown’ documents, and ‘Shiny’ web applications.\n\n\n\nShow code\npacman::p_load(tidyverse, patchwork, DT, plotly, ggiraph, gifski, gganimate, ggthemes, knitr, ungeviz, crosstalk, manipulateWidget)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#importing-data",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#importing-data",
    "title": "Be Weatherwise or Otherwise",
    "section": "2.2 Importing data",
    "text": "2.2 Importing data\nThe code chunk below does the following:\n\nUse “list.files” to enumerate all the individual excel files which stores the daily temperature records in a month\nUse “Read.csv” is then used to read and concatenate all records from the individual files into a dataframe, while the relevant columns with the temperature records are selected\nUse mutate function to change data type of some columns and derive a Date field consisting of year, month, day\n\n\n\nShow code\ncolnames = c(\"Station\", \"Year\", \"Month\",    \"Day\",  \"Daily_Rainfall_mm\",    \"Highest_30_Min_Rainfall_mm\",   \"Highest_60_Min_Rainfall_mm\",   \"Highest_120_Min_Rainfall_mm\",  \"Mean_Temp_celcius\",    \"Max_Temp_celcius\", \"Min_Temp_celcius\", \"Mean_Wind_Speed_km/h\", \"Max_Wind_Speed_km/h\")\n\nweather_data &lt;- list.files(path = \"./data/\", \n                           pattern = \"\\\\.csv$\",\n                           full.names = T) %&gt;% \n  map_df(~read.csv(.,header = F, col.names=colnames)) %&gt;% \n  filter(grepl('Changi', Station)) %&gt;% \n  select(c(\"Station\",   \"Year\", \"Month\",    \"Day\", \"Mean_Temp_celcius\", \"Max_Temp_celcius\", \"Min_Temp_celcius\")) %&gt;% \n  mutate(Mean_Temp_celcius = as.numeric(Mean_Temp_celcius),\n         Max_Temp_celcius = as.numeric(Max_Temp_celcius),\n         Min_Temp_celcius = as.numeric(Min_Temp_celcius),\n         Year = factor(Year, levels = c('1983', '1993', '2003', '2013', '2023')),\n         Month = factor(Month, levels = 1:12),\n         Day = factor(Day, levels = 1:31),\n         Date = paste0(Year, '-', Month, '-', Day))"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#summary-statistics-of-data",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#summary-statistics-of-data",
    "title": "Be Weatherwise or Otherwise",
    "section": "2.3 Summary statistics of data",
    "text": "2.3 Summary statistics of data\nBelow code chunks detail initial observations and summary statistics relating to the weather data.\n\nData PreviewData SummaryData Check\n\n\n\n\nShow code\nkable(head(weather_data, 10))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nStation\nYear\nMonth\nDay\nMean_Temp_celcius\nMax_Temp_celcius\nMin_Temp_celcius\nDate\n\n\n\n\nChangi\n1983\n1\n1\n26.5\n28.7\n25.1\n1983-1-1\n\n\nChangi\n1983\n1\n2\n26.8\n30.6\n24.8\n1983-1-2\n\n\nChangi\n1983\n1\n3\n27.0\n31.3\n24.5\n1983-1-3\n\n\nChangi\n1983\n1\n4\n27.3\n30.8\n25.0\n1983-1-4\n\n\nChangi\n1983\n1\n5\n27.1\n31.8\n23.7\n1983-1-5\n\n\nChangi\n1983\n1\n6\n27.2\n32.1\n23.7\n1983-1-6\n\n\nChangi\n1983\n1\n7\n26.1\n31.1\n24.3\n1983-1-7\n\n\nChangi\n1983\n1\n8\n27.0\n31.9\n24.1\n1983-1-8\n\n\nChangi\n1983\n1\n9\n27.3\n32.0\n24.1\n1983-1-9\n\n\nChangi\n1983\n1\n10\n26.9\n30.7\n24.1\n1983-1-10\n\n\n\n\n\n\n\n\n\nCode\nsummary(weather_data)\n\n\n   Station            Year         Month          Day       Mean_Temp_celcius\n Length:1825        1983:365   1      :155   1      :  60   Min.   :23.00    \n Class :character   1993:365   3      :155   2      :  60   1st Qu.:26.90    \n Mode  :character   2003:365   5      :155   3      :  60   Median :27.70    \n                    2013:365   7      :155   4      :  60   Mean   :27.73    \n                    2023:365   8      :155   5      :  60   3rd Qu.:28.70    \n                               10     :155   6      :  60   Max.   :30.70    \n                               (Other):895   (Other):1465                    \n Max_Temp_celcius Min_Temp_celcius     Date          \n Min.   :23.80    Min.   :20.90    Length:1825       \n 1st Qu.:30.70    1st Qu.:24.10    Class :character  \n Median :31.80    Median :25.00    Mode  :character  \n Mean   :31.53    Mean   :25.04                      \n 3rd Qu.:32.60    3rd Qu.:26.00                      \n Max.   :35.80    Max.   :29.00                      \n                                                     \n\n\n\n\nBelow code chunk shows no duplicate records found in dataset.\n\n\nShow code\nweather_data[duplicated(weather_data),]\n\n\n[1] Station           Year              Month             Day              \n[5] Mean_Temp_celcius Max_Temp_celcius  Min_Temp_celcius  Date             \n&lt;0 rows&gt; (or 0-length row.names)\n\n\nBelow code chunk no missing values in dataset.\n\n\nShow code\nsum(is.na(weather_data))\n\n\n[1] 0\n\n\n\n\n\n\n\n\n\n\n\nInitial observations on dataset\n\n\n\nThe dataset of Singapore students contains 1825 rows of records (365 records for each day of the 5 years) with 8 variables. A visual look at the overview of the data structure revealed the following:\n\nThe records contains the daily mean, max and min temperatures. Further data wrangling to derive monthly and annual averages will be necessary for effective visualisations.\nNo duplicates or missing values in the dataset."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#choosing-the-month-for-analysis",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#choosing-the-month-for-analysis",
    "title": "Be Weatherwise or Otherwise",
    "section": "2.4 Choosing the Month for Analysis",
    "text": "2.4 Choosing the Month for Analysis\nThe code chunk below is used to find a suitable month for analysis, by computing the month with the highest daily mean temperature. From the results obtained below, the month of May is chosen for analysis.\n\n\nShow code\nkable(head(weather_data %&gt;% \n  arrange(desc(Mean_Temp_celcius)),5))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nStation\nYear\nMonth\nDay\nMean_Temp_celcius\nMax_Temp_celcius\nMin_Temp_celcius\nDate\n\n\n\n\nChangi\n2023\n5\n13\n30.7\n35.0\n27.7\n2023-5-13\n\n\nChangi\n2003\n5\n24\n30.6\n33.9\n28.1\n2003-5-24\n\n\nChangi\n2023\n5\n10\n30.6\n34.0\n28.8\n2023-5-10\n\n\nChangi\n2013\n6\n19\n30.5\n34.5\n26.8\n2013-6-19\n\n\nChangi\n1983\n4\n12\n30.4\n34.7\n28.4\n1983-4-12"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#data-wrangling",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#data-wrangling",
    "title": "Be Weatherwise or Otherwise",
    "section": "3.1 Data Wrangling",
    "text": "3.1 Data Wrangling\n\n3.1.1 Filtering\nThe following code chunk is used to filter the records in May for further analysis.\n\n\nCode\nweather_data &lt;- weather_data %&gt;% \n  filter(Month == 5)\n\n\n\n\n3.1.2 Monthly Aggregates\nThe following code chunk is used to compute the monthly average, maximum and minimum daily mean temperatures for each month of the 5 years used for analysis, and the result is stored in a new dataframe.\n\n\nShow code\nweather_by_month &lt;- weather_data %&gt;% \n  group_by(Year) %&gt;% \n  summarise(`Monthly Average` = round(mean(Mean_Temp_celcius),2),\n            max_monthly_temp = max(Max_Temp_celcius), \n            min_monthly_temp = min(Min_Temp_celcius))"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#static-data-visualisation",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#static-data-visualisation",
    "title": "Be Weatherwise or Otherwise",
    "section": "4.1 Static Data Visualisation",
    "text": "4.1 Static Data Visualisation\nThe following code chunks are used to create a static data visualisation to display the following:\n\nDaily mean temperature and daily temperature range over the 4 decades\nDistribution of daily mean temperature\nChanges in monthly average of daily mean temperature over the 4 decades\nUncertainty in using a point estimate, i.e. the monthly average, for analysis\n\n\n4.1.1 First sub-plot\nThe first code chunk below produces the static plot for the plot of daily mean temperature and daily temperature range over the 5 years.\n\n\nShow code\np1s &lt;- ggplot(data=weather_data,\n             aes(x=Mean_Temp_celcius,\n                 y=Max_Temp_celcius - Min_Temp_celcius,\n                 colour=Year)) +\n  geom_point(alpha=0.8,\n             size = 1.5,\n             show.legend = T) +\n  labs(x=\"Daily Mean Temp\",\n       y=\"Daily Temp Range\") +\n  ggtitle (\"Daily Mean Temp vs \\nDaily Temp Range\") + \n  theme_bw() +\n  theme(legend.position = \"bottom\",\n        legend.key.size = unit(0.15, \"cm\"),\n        legend.text = element_text(size = 5),\n        title = element_text(size = 8),\n        axis.title = element_text(size = 6),\n        axis.text = element_text(size=5))\n\n\n\n\n4.1.2 Second sub-plot\nThe 2nd code chunk below produces the static plot for the plot of distribution of daily mean temperature.\n\n\nShow code\np2s &lt;- ggplot(data = weather_data,\n             aes(x = Mean_Temp_celcius, fill = Year)) +\n  geom_dotplot(stackgroups=T,\n               binwidth=0.15,\n               method=\"histodot\",\n               color = NA) +\n  scale_y_continuous(NULL, breaks = NULL) +\n  labs(x = \"Daily Mean Temp\", \n       title = \"Stacked Plot of \\nDaily Mean Temp\") +\n  theme_bw() +\n  theme(legend.position = \"none\",\n        title = element_text(size = 8),\n        axis.title = element_text(size = 6),\n        axis.text = element_text(size=5))\n\n\n\n\n4.1.3 Third sub-plot\nThe 3rd code chunk below produces the static plot for the plot of changes in monthly average of daily mean temperature over the 5 years.\n\n\nShow code\n#for labeling the plot\ndat_text &lt;- data.frame(\n  label = c(paste0(\"Month Average: \", weather_by_month$`Monthly Average`[1]), \n            paste0(\"Month Average: \", weather_by_month$`Monthly Average`[2]), \n            paste0(\"Month Average: \", weather_by_month$`Monthly Average`[3]), \n            paste0(\"Month Average: \", weather_by_month$`Monthly Average`[4]),\n            paste0(\"Month Average: \", weather_by_month$`Monthly Average`[5])),\n  Year = c(1983, 1993, 2003, 2013, 2023),\n  x = c(15.5, 15.5, 15.5, 15.5, 15.5),\n  y = c(weather_by_month$`Monthly Average`[1]-0.15, \n        weather_by_month$`Monthly Average`[2]-0.15, \n        weather_by_month$`Monthly Average`[3]-0.15, \n        weather_by_month$`Monthly Average`[4]-0.15, \n        weather_by_month$`Monthly Average`[5]-0.15),\n  clr = c(\"red\", \"black\", \"black\", \"black\", \"red\")\n)\n\np3s &lt;- ggplot(data = weather_data) +\n  geom_hline(data = weather_by_month,\n             aes(yintercept = `Monthly Average`),\n             color = \"black\",\n             alpha = 1.0,\n             size = 0.4) +\n  geom_line(aes(x=Day,\n                y=Mean_Temp_celcius,\n                group = Year,\n                color = Year,\n                alpha = 0.6)) +\n  facet_grid(~Year) + \n  labs(x = \"Day in Month of May\",\n       y = \"Daily Mean Temp\") +\n  ggtitle(\"Temparature change over 4 decades\") +\n  theme_bw() +\n  theme(legend.position=\"none\",\n        axis.text.x = element_blank(),\n        axis.ticks.x = element_blank(),\n        axis.title = element_text(size = 6),\n        title = element_text(size=10),\n        axis.text.y = element_text(size=5))\n\np3s &lt;- p3s +\n  geom_text(data = dat_text,\n            mapping = aes(x=x, y=y, label=label),\n            size = 2.5)\n\n\n\n\n4.1.4 Fourth sub-plot\nThe 4th code chunk below produces the static plot for the plot showing uncertainty in using a point estimate by displaying the 95% confidence interval of the records in May.\n\n\nShow code\n# computes the statistical standard error\nweather_se &lt;- weather_data %&gt;% \n  group_by(Year) %&gt;% \n  summarise(\n    n=n(),\n    mean=mean(Mean_Temp_celcius),\n    sd=sd(Mean_Temp_celcius)\n  ) %&gt;% \n  mutate(se=sd/sqrt(n-1))\n\np4s &lt;- ggplot(data = weather_se) +\n  geom_errorbar(aes(x=factor(Year),\n                    ymin=mean-1.96*se,\n                    ymax=mean+1.96*se),\n                width=0.4,\n                colour=\"black\",\n                alpha=0.9,\n                size=1.4) + \n  geom_point(aes(x=Year,\n                 y=mean),\n             stat = \"identity\",\n             color=\"red\",\n             size=3.0,\n             alpha=1) +\n  xlab(\"Year\") +\n  ylab(\"Average Daily Mean Temp\") +\n  ggtitle(\"95% Confidence Interval of \\n Daily Mean Temp\") +\n  coord_flip() +\n  theme_bw() +\n  theme(title = element_text(size=8),\n        axis.title = element_text(size=6),\n        axis.text = element_text(size=5))\n\n\n\n\n4.1.5 Combining all sub-plots\nThe code chunk below combines all the above plots into a static data visualisation.\n\n\nShow code\np_comb_s1 &lt;- p2s | p1s | p4s\np3s / p_comb_s1 +\n  plot_layout(heights = c(3,2)) +\n  plot_annotation(title = \"Has Daily Temperature Increased from 1983 - 2023?\")\n\n\n\n\n\n\n\n\n\n\n\n\n DISCUSSION AND EXPLANATION\n\n\n\n\n\nThe data visualisation above encompasses the following plots:\n\nA facet grid plot (top row) which shows the daily mean temperatures in May in each of the 5 years used in the analysis, as well as a horizontal line that depicts the monthly average of the daily mean temperature (actual value is labelled on the plot since it is static). This plot was used as it allows one to visually compare the daily mean and the corresponding monthly average temperatures.\nA stacked dot plot is provided on the lower left corner to provide a visual view of the distribution of the daily mean temperature in May according to the different years used in the study. Different colored dots are used so that one can differentiate the temperature records belonging to the different years.\nA scatter plot of daily mean temperature vs the daily temperature range is provided in the lower middle section, as it provides a visual view for one to assess visually if there is any relationship between rising daily mean temperature and the daily temperature range. This serves to provide insights into whether the increase in temperature could be due to greater variability in daily temperatures.\nAn error bar plot in the lower right corner shows the 95% confidence interval of the monthly average temperature, which was estimated using the daily mean temperatures in May. The inclusion of the error bar plot is allow one to quickly tell if the standard error associated with using a point estimate had changed over the decades, and how this might have impacted the analysis of the increase in daily mean temperature.\n\n\n\n\n\n\n\n\n\n\n\n INSIGHTS\n\n\n\n\n\nUsing the above animated plot, the following initial insights were derived:\n\nDaily mean temperatures had generally trended higher over the period 1983 to 2023, as seen from the increase in monthly average daily mean temperature, as well as the observation that there were more days in 2023 with relatively higher daily mean temperature than the earlier decades. The increase of daily mean temperature using data for May from 1983-2023 showed an increase of approximately 1.2℃, i.e. an increase of 0.3℃ per decade over the 4 decades used in this study.\nWhile daily mean temperatures had increased, variability in daily mean temperature had remained relatively the same over the 4 decades. This implies that the higher temperatures were not due to higher variability in daily mean temperature.\nFrom the error bar plot, it can be deduced that the standard error had some variability over the 4 decades, though the variation did not appear to be large. However, suitable interactivity needs to be added to the plot for it to be more useful for analysis purposes.\n\n\n\n\n\n\n\n\n\n\n\n DRAWBACKS\n\n\n\n\n\nSome drawbacks of using a static data visualisation for visual storytelling in this case includes:\n\nLimited amount of details can be shown on the data visualisation, e.g. the cycle plot could only indicate the monthly average value, but the values of the daily mean temperature can only be estimated by looking at the axes.\nUse of different colors for the dot plot and scatter plot may not be the best way to segregate the values associated with different years, especially if there is significant overlap (for the case of the scatter plot). Moreover, a static data visualisation does not allow the user to obtain accurate details from the visualisation apart from estimation.\nUnable to easily tell how the data points changes over time. Though the facet grid allows for such a comparison, it may not be so effective for one to have to visually compare across sub-plots that are placed besides one another.\nSimilar to other plots, a static error bar plot does not allow more precise details, e.g. the confidence interval and the monthly average value, to be provided to the user.\n\nNothwithstanding the above drawbacks, a static data visualisation can be a quick and effective method for visualisation if the questions that needed to be answered is straightforward, and thus user interaction is not critical.\nWe will next set out to perform makeover on the static plot, so as to improve upon the user interactivity and allow the user to use the data visualisation to form his/her own insights and assessment."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#interactivity-makeover-of-data-visualisation",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#interactivity-makeover-of-data-visualisation",
    "title": "Be Weatherwise or Otherwise",
    "section": "4.2 Interactivity Makeover of Data Visualisation",
    "text": "4.2 Interactivity Makeover of Data Visualisation\nThe following code chunks are used to create an interactive data visualisation makeover to improve upon the user interactivity:\n\nDaily mean temperature and daily temperature range over the 4 decades\n\nUse of animation to provide a visual representation of how the daily mean temperature changes over the 4 decades\nTooltip also used to display information on the selected day’s temperature\nSupports brushing, allowing the user to filter and zoom in on selected data points\n\nDistribution of daily mean temperature\n\nUse of data-ID that allows user to hover over and view all temperature record of the same year\n\nChanges in monthly average of daily mean temperature over the 4 decades\n\nUse of tooltips to display the daily mean temperature on the line chart, as well as the monthly average (geom_hline)\nSupports brushing, allowing the user to filter and zoom in on selected data points\n\nUncertainty in using a point estimate, i.e. the monthly average, for analysis\n\nUse of tooltip to show information on monthly average and the standard error at 95% confidence interval\n\n\n\n4.2.1 Interactive Makeover of First sub-plot\nThe code chunk below produces the interactive plot for the plot of daily mean temperature and daily temperature range over the 5 years.\n\n\nShow code\np1i &lt;- ggplot(data=weather_data,\n             aes(x=Mean_Temp_celcius,\n                 y=Max_Temp_celcius - Min_Temp_celcius,\n                 colour=Year,\n                 text = paste0('Date: ', Date, '\\n',\n                               'Daily Mean Temp: ', Mean_Temp_celcius, '℃\\n',\n                               'Daily Temp Range: ', Max_Temp_celcius - Min_Temp_celcius, \"℃\"))) +\n  geom_point(aes(frame = Year),\n             alpha=0.8,\n             show.legend = F) +\n  labs(x=\"Daily Mean Temp (℃)\",\n       y=\"Daily Temp Range (℃)\") + \n  theme_bw() +\n  theme(legend.position = \"none\",\n        axis.title = element_text(size = 6),\n        axis.text = element_text(size=5))\n  \np1i &lt;- ggplotly(p1i, tooltip = \"text\") %&gt;% \n  layout(title = list(text = \"Daily Mean vs Daily Range\"),\n         titlefont = list(size = 10)) %&gt;% \n  animation_slider(\n    font = list(size=6),\n    currentvalue = list(visible = FALSE)\n  ) %&gt;% \n  animation_button(\n    font = list(size=6),\n    button = list(height=10)\n  ) %&gt;% \n  animation_opts(frame=2000,\n                 transition = 1000)\n\n\n\n\n4.2.2 Interactive Makeover of Second sub-plot\nThe code chunk below produces the interactive plot for the plot of distribution of daily mean temperature.\n\n\nShow code\np2i &lt;- ggplot(data = weather_data,\n             aes(x = Mean_Temp_celcius)) +\n  geom_dotplot_interactive(aes(data_id=Year,\n                               tooltip=paste0(\"Year: \", Year)),\n                           stackgroups=T,\n                           binwidth=0.15,\n                           method=\"histodot\",\n                           fill = \"blue\",\n                           color = NA) +\n  scale_y_continuous(NULL, breaks = NULL) +\n  labs(x = \"Daily Mean Temp (℃) \",\n       y = \"\") +\n  ggtitle(\"Stacked Plot of Daily Mean Temp\") +\n  theme_bw() +\n  theme(legend.position = \"none\",\n        plot.title = element_text(size = 16),\n        axis.title = element_text(size = 12),\n        axis.text = element_text(size=5))\n\np2i &lt;- girafe(ggobj = p2i,\n       width_svg = 5,\n       height_svg = 4,\n       options=list(\n         opts_hover(css = \"fill: #202020;\"),\n         opts_hover_inv(css = \"opacity:0.2\")\n       )\n)\n\n\n\n\n4.2.3 Interactive Makeover of Third sub-plot\nThe code chunk below produces the interactive plot of changes in monthly average of daily mean temperature over the 5 years.\n\n\nShow code\np3i &lt;- ggplot(data = weather_data) +\n  geom_hline(data = weather_by_month,\n             aes(yintercept = `Monthly Average`),\n             color = \"black\",\n             alpha = 0.8,\n             size = 0.4) +\n  geom_line(aes(group = Year,\n                x=Day,\n                y=Mean_Temp_celcius,\n                color = Year)) +\n  facet_grid(~Year) + \n  labs(x = \"Month in Year\",\n       y = \"Daily Mean Temp (℃ )\") +\n  ggtitle(\"Temparature change over 4 decades\") +\n  theme_bw() +\n  theme(legend.position=\"none\",\n        axis.text.x = element_blank(),\n        axis.ticks.x = element_blank(),\n        axis.title = element_text(size = 6),\n        title = element_text(size=10),\n        axis.text.y = element_text(size=5))\n\np3i &lt;- ggplotly(p3i)\n\n\n\n\n4.2.4 Interactive Makeover of Fourth sub-plot\nThe code chunk below produces the interactive plot for the plot showing uncertainty in using a point estimate by displaying the 95% confidence interval of the records in May.\n\n\nShow code\np4i &lt;- ggplot(weather_se) +\n  geom_errorbar(aes(x=factor(Year),\n                ymin=mean-1.96*se,\n                ymax=mean+1.96*se),\n                width=0.05,\n                colour=\"black\",\n                alpha=0.9,\n                size=1.4) + \n  geom_point(aes(x=Year,\n                 y=mean,\n                 text=paste(\"Year:\", `Year`, \"&lt;br&gt;N:\", `n`,\n                            \"&lt;br&gt;Avg. Daily Mean Temp (℃):\", round (mean, digits=2),\n                            \"&lt;br&gt;95% CI:[\", round((mean-1.96*se), digits=2), \n                            \",\", round((mean+1.96*se), digits=2), \"]\")),\n             stat = \"identity\",\n             color=\"red\",\n             size=3.0,\n             alpha=1) +\n  xlab(\"Year\") +\n  ylab(\"Average Daily Mean Temp (℃)\") +\n  ggtitle(\"95% Confidence Interval \\nof Daily Mean Temp\") +\n  coord_flip() +\n  theme_bw() +\n  theme(axis.title = element_text(size=6),\n        plot.title = element_text(size=8),\n        axis.text = element_text(size=5))\n\np4i &lt;- ggplotly(p4i, tooltip = \"text\")\n\n\n4.2.5 Combining all Interactive sub-plots\nThe code chunk below combines all the above plots into an interactive data visualisation.\n\n\nShow code\ncombineWidgets(p3i,\n               combineWidgets(p2i,\n                              p1i,\n                              p4i,\n                              nrow = 1,\n                              ncol = 3,\n                              width = 600,\n                              height = 180),\n               nrow=2,\n               ncol=1,\n               title = \"Has Daily Temperature Increased from 1983 - 2023?\",\n               width=600,\n               height=450)\n\n\n\n\n\n\n\n\n\n\n\n\n\n DISCUSSIONS ON IMPROVEMENTS MADE\n\n\n\n\n\nThe folllowing improvements were made to the static data visualisation in 4.1.\n\nA cycle plot showing the daily mean temperature by year was used to visualise how the daily averages change over the decades.\n\nThe interactivity of the plot allows the user to conveniently obtain the daily average by hovering over the line chart.\n\nA horizontal y-intercept line with the monthly average of daily mean temperature as its value was used to compare the monthly mean temperatures over the 4 decades.\n\nThis allows the user to, at one glance, see how the monthly averages had changed over the decades, and be able to quickly tell which year is the highest and which is the lowest.\nInteractivity is added as the monthly average value will be provided to the user when hovered over, instead of statically ‘hardcoding’ the value on the plots.\n\nAn interactive stacked dotplot was used to display the distribution of daily mean temperature of all days in the 5 years used for this analysis.\n\nProvides a simple and easy-to-interact-with plot for the user to have a visual overview of the distribution of daily mean temperature over all 5 years used in the study, while also allowing for a detailed look at each year’s distribution by hovering over the “dots”. When hovered over, the plot will highlight all the data points within the same year, allowing the user to have a good visual view of how the daily mean temperature of that year is distributed as compared to other years.\n\nAn animated scatter plot showing the daily mean temperatures against daily temperature range allows the user to have a good visual overview of the spread of the daily mean temperatures and the daily temperature range over the 4 decades and interact with it.\n\nThe animated plot used the “Year” to run the frames so that the points will not be overly-cluttered, while allowing the user to visually observe the movement of the points on the plot over the 4 decades, i.e. he would be able to have an sense of whether the daily mean temperature had generally increased or decreased over the years, while having the flexibility to stop at any of the years if he wish to take a more in-depth look.\nThe tooltip provides useful information of the date, daily mean temperature and daily temperature range when hovered over, allowing the user to have good access to the actual records.\nThe animated plot also supports brushing, thus allowing the user to narrow down and play the animation on specific temperature ranges , e.g. looking at high temperatures only.\n\nAn error bar plot was used to visualise the uncertainty involved in point estimates, i.e. monthly average of daily mean temperature, which will be useful in deriving a range of temperature increase at a certain confidence level (we used 95% here)\n\nProvides a simple view of the confidence interval of the point estimate for each year’s temperature data, and also allows the user to do a quick comparison of the point estimate (i.e. monthly average of daily mean temperature)\nTooltip to provide useful information on mean value and confidence interval range.\n\n\n\n\n\n\n\n\n\n\n\n\n INSIGHTS\n\n\n\n\n\nUsing the above animated plot, the following insights were derived:\n\nDaily mean temperatures had generally trended higher over the period 1983 to 2023, as there are more data points with daily mean temperature higher than 29℃ in 2023, while the variation in daily temperatures had remained largely the same.\nUsing May’s average of daily mean temperature as an estimate for the change in daily temperature, May’s average had risen by 1.2℃ from 1983 to 2023, which works out to be an increase of 0.3℃ per decade over 4 decades, which is quite close to what was claimed in the report. A caveat to this is that this study had only used data for May, and the actual increase in annual mean temperature could be affected by other months if they are different from that in May.\n2023 saw more months with higher monthly average of daily mean temperature as compared to the earlier decades, which possibly explains for the higher annual average. Specifically, there were more days with mean temperature above 29℃ in 2023 as compared to the earlier 4 decades. Similarly, 2023 had lesser days with low daily mean temperatures (below 27℃) as well. Also, 1993 saw the lowest annual average of daily mean temperature, while the highest was seen in 2023.\nHowever, as daily temperatures varies quite widely in all of the 5 years, it would not be possible to conclude that temperatures had risen just by looking at the distribution plot. Specifically, the analyst will also need to consider the uncertainty and variability of the daily mean temperature.\nUsing the 95% confidence interval ranges obtained for May’s average daily mean temperature over the 4 decades, the range of increase in May’s average temperature was [0.64℃, 1.75℃], which works out to be a range of [0.16℃, 0.44℃] per decade.\n\nUsing this range to do a simple extrapolation until the end of this century, i.e. approx 8 decades away, the range of temperature increase at 95% confidence interval (based on May’s weather records) is [1.28℃, 3.52℃], which is quite close to, but lower than, the projected rise in daily mean temperature mentioned in the report."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#setting-the-scene",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#setting-the-scene",
    "title": "A Look into Singapore Students’ Performance Using PISA 2022",
    "section": "1.1 Setting the scene",
    "text": "1.1 Setting the scene\nOECD education director Andreas Schleicher shared in a BBC article that “Singapore managed to achieve excellence without wide differences between children from wealthy and disadvantaged families.” (2016) Furthermore, several Singapore’s Minister for Education also started an “every school a good school” slogan. In fact, according to a recent Straits Times article (2023), Singapore students ranked the best of all countries in all 3 domains in PISA 2022.\nThe general public, however, strongly belief that there are still disparities that exist, especially between the elite schools and neighborhood school, between students from families with higher socioeconomic status and those with relatively lower socioeconomic status and immigration and non-immigration families."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#our-task",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#our-task",
    "title": "A Look into Singapore Students’ Performance Using PISA 2022",
    "section": "1.2 Our task",
    "text": "1.2 Our task\nThe 2022 Programme for International Student Assessment (PISA) data was released on December 5, 2022. PISA global education survey every three years to assess the education systems worldwide through testing 15 year old students in the subjects of mathematics, reading, and science.\nIn this exercise, we are required to use Exploratory Data Analysis (EDA) methods and ggplot2 data visualisation functions to reveal:\n\nthe distribution of Singapore students’ performance in mathematics, reading, and science, and\nthe relationship between these performances with schools, gender and socioeconomic status of the students."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#the-data",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#the-data",
    "title": "A Look into Singapore Students’ Performance Using PISA 2022",
    "section": "1.3 The Data",
    "text": "1.3 The Data\nThe PISA 2022 database contains the full set of responses from individual students, school principals and parents. There are a total of five data files and their contents are as follows:\n\nStudent questionnaire data file\nSchool questionnaire data file\nTeacher questionnaire data file\nCognitive item data file\nQuestionnaire timing data file\n\nIn this exercise, we will use the Student questionnaire data file only."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#loading-r-packages",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#loading-r-packages",
    "title": "A Look into Singapore Students’ Performance Using PISA 2022",
    "section": "2.1 Loading R packages",
    "text": "2.1 Loading R packages\nThe pacman::p_load() function is used to install and load the required R packages into the R environment, as below.\n\ntidyverse: collection of R packages designed for data science\nhaven: an R package to read and write data formats used by other statistical packages, e.g. SAS, SPSS\nggrepel: an R package provides geoms for ggplot2 to repel overlapping text labels.\nggthemes: an R package provides some extra themes, geoms, and scales for ‘ggplot2’.\nhrbrthemes: an R package provides typography-centric themes and theme components for ggplot2.\npatchwork: an R package for preparing composite figure created using ggplot2.\nDT: an R package to render interactive DataTables\nknitr: an R package for dynamic report generation\nkableExtra: an R package to build complex HTML tables using kable()\nggridges: an R package for plotting Ridgeline plots\nqqplotr: an R package which extends ggplot2 Q-Q plot functionalities\nrstatix: an R package for performaing basic statistical tests\nggdist: an R package that provides a flexible set of ggplot2 geoms and stats for visualising distributions and uncertainties\nggstatsplot: an R package that extends ggplot2 to create graphics with details from statistical tests\n\n\n\nShow code\npacman::p_load(tidyverse, haven, ggrepel, ggthemes, hrbrthemes, patchwork, DT, knitr, kableExtra, ggridges, qqplotr, rstatix, ggdist, ggstatsplot)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#importing-pisa-data",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#importing-pisa-data",
    "title": "A Look into Singapore Students’ Performance Using PISA 2022",
    "section": "2.2 Importing PISA data",
    "text": "2.2 Importing PISA data\nThe code chunk below uses read_sas() of haven to import PISA data into R environment.\n\n\nShow code\nstu_qqq &lt;- read_sas(\"data/cy08msp_stu_qqq.sas7bdat\")\n\n\nFiltering the entire data file for records belonging to Singapore students.\n\n\nShow code\nstu_qqq_SG &lt;- stu_qqq %&gt;%\n  filter(CNT == \"SGP\") \n\n\nSaving the records belonging to Singapore students into “stu_qqq_SG.rds” file for easier loading (no need to extract the records from the entire dataset repeatedly).\n\n\nShow code\nwrite_rds(stu_qqq_SG,\n          \"data/stu_qqq_SG.rds\")\n\n\nLoading the extract records from the saved “stu_qqq_SG.rds” file.\n\n\nShow code\nsfu_qqq_SG &lt;- read_rds(\"data/stu_qqq_SG.rds\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#summary-statistics-of-pisa-data",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#summary-statistics-of-pisa-data",
    "title": "A Look into Singapore Students’ Performance Using PISA 2022",
    "section": "2.3 Summary statistics of PISA data",
    "text": "2.3 Summary statistics of PISA data\nBelow code chunks detail initial observations and summary statistics relating to Singapore students:\n\nData sampleData structureData check\n\n\n\n\n\nShow code\nkable(head(sfu_qqq_SG, 8), \"html\")\n\n\n\n\n\nCNT\nCNTRYID\nCNTSCHID\nCNTSTUID\nCYC\nNatCen\nSTRATUM\nSUBNATIO\nREGION\nOECD\nADMINMODE\nLANGTEST_QQQ\nLANGTEST_COG\nLANGTEST_PAQ\nOption_CT\nOption_FL\nOption_ICTQ\nOption_WBQ\nOption_PQ\nOption_TQ\nOption_UH\nBOOKID\nST001D01T\nST003D02T\nST003D03T\nST004D01T\nST250Q01JA\nST250Q02JA\nST250Q03JA\nST250Q04JA\nST250Q05JA\nST250D06JA\nST250D07JA\nST251Q01JA\nST251Q02JA\nST251Q03JA\nST251Q04JA\nST251Q06JA\nST251Q07JA\nST251D08JA\nST251D09JA\nST253Q01JA\nST254Q01JA\nST254Q02JA\nST254Q03JA\nST254Q04JA\nST254Q05JA\nST254Q06JA\nST255Q01JA\nST256Q01JA\nST256Q02JA\nST256Q03JA\nST256Q06JA\nST256Q07JA\nST256Q08JA\nST256Q09JA\nST256Q10JA\nST230Q01JA\nST005Q01JA\nST006Q01JA\nST006Q02JA\nST006Q03JA\nST006Q04JA\nST006Q05JA\nST007Q01JA\nST008Q01JA\nST008Q02JA\nST008Q03JA\nST008Q04JA\nST008Q05JA\nST258Q01JA\nST259Q01JA\nST259Q02JA\nST019AQ01T\nST019BQ01T\nST019CQ01T\nST021Q01TA\nST022Q01TA\nST226Q01JA\nST125Q01NA\nST126Q01TA\nST127Q01TA\nST127Q02TA\nST127Q03TA\nST260Q01JA\nST260Q02JA\nST260Q03JA\nST261Q01JA\nST261Q02JA\nST261Q03JA\nST261Q04JA\nST261Q05JA\nST261Q06JA\nST261Q07JA\nST261Q08JA\nST261Q09JA\nST261Q10JA\nST261Q11JA\nST062Q01TA\nST062Q02TA\nST062Q03TA\nST267Q01JA\nST267Q02JA\nST267Q03JA\nST267Q04JA\nST267Q05JA\nST267Q06JA\nST267Q07JA\nST267Q08JA\nST034Q01TA\nST034Q02TA\nST034Q03TA\nST034Q04TA\nST034Q05TA\nST034Q06TA\nST038Q03NA\nST038Q04NA\nST038Q05NA\nST038Q06NA\nST038Q07NA\nST038Q08NA\nST038Q09JA\nST038Q10JA\nST038Q11JA\nST265Q01JA\nST265Q02JA\nST265Q03JA\nST265Q04JA\nST266Q01JA\nST266Q02JA\nST266Q03JA\nST266Q04JA\nST266Q05JA\nST294Q01JA\nST294Q02JA\nST294Q03JA\nST294Q04JA\nST294Q05JA\nST295Q01JA\nST295Q02JA\nST295Q03JA\nST295Q04JA\nST295Q05JA\nST326Q01JA\nST326Q02JA\nST326Q03JA\nST326Q04JA\nST326Q05JA\nST326Q06JA\nST326Q07JA\nST326Q08JA\nST326Q09JA\nST326Q10JA\nST326Q11JA\nST326Q12JA\nST322Q01JA\nST322Q02JA\nST322Q03JA\nST322Q04JA\nST322Q06JA\nST322Q07JA\nST307Q01JA\nST307Q02JA\nST307Q03JA\nST307Q04JA\nST307Q05JA\nST307Q06JA\nST307Q07JA\nST307Q08JA\nST307Q09JA\nST307Q10JA\nST309Q01JA\nST309Q02JA\nST309Q03JA\nST309Q04JA\nST309Q05JA\nST309Q06JA\nST309Q07JA\nST309Q08JA\nST309Q09JA\nST309Q10JA\nST301Q01JA\nST301Q02JA\nST301Q03JA\nST301Q04JA\nST301Q05JA\nST301Q06JA\nST301Q07JA\nST301Q08JA\nST301Q09JA\nST301Q10JA\nST343Q01JA\nST343Q02JA\nST343Q03JA\nST343Q04JA\nST343Q05JA\nST343Q06JA\nST343Q07JA\nST343Q08JA\nST343Q09JA\nST343Q10JA\nST311Q01JA\nST311Q02JA\nST311Q03JA\nST311Q04JA\nST311Q05JA\nST311Q06JA\nST311Q07JA\nST311Q08JA\nST311Q09JA\nST311Q10JA\nST315Q01JA\nST315Q02JA\nST315Q03JA\nST315Q04JA\nST315Q05JA\nST315Q06JA\nST315Q07JA\nST315Q08JA\nST315Q09JA\nST315Q10JA\nST303Q01JA\nST303Q02JA\nST303Q03JA\nST303Q04JA\nST303Q05JA\nST303Q06JA\nST303Q07JA\nST303Q08JA\nST305Q01JA\nST305Q02JA\nST305Q03JA\nST305Q04JA\nST305Q05JA\nST305Q06JA\nST305Q07JA\nST305Q08JA\nST305Q09JA\nST305Q10JA\nST345Q01JA\nST345Q02JA\nST345Q03JA\nST345Q04JA\nST345Q05JA\nST345Q06JA\nST345Q07JA\nST345Q08JA\nST345Q09JA\nST345Q10JA\nST313Q01JA\nST313Q02JA\nST313Q03JA\nST313Q04JA\nST313Q05JA\nST313Q06JA\nST313Q07JA\nST313Q08JA\nST313Q09JA\nST313Q10JA\nST263Q02JA\nST263Q04JA\nST263Q06JA\nST263Q08JA\nST016Q01NA\nST059Q01TA\nST059Q02JA\nST296Q01JA\nST296Q02JA\nST296Q03JA\nST296Q04JA\nST272Q01JA\nST273Q01JA\nST273Q02JA\nST273Q03JA\nST273Q04JA\nST273Q05JA\nST273Q06JA\nST273Q07JA\nST270Q01JA\nST270Q02JA\nST270Q03JA\nST270Q04JA\nST285Q01JA\nST285Q02JA\nST285Q03JA\nST285Q04JA\nST285Q05JA\nST285Q06JA\nST285Q07JA\nST285Q08JA\nST285Q09JA\nST283Q01JA\nST283Q02JA\nST283Q03JA\nST283Q04JA\nST283Q05JA\nST283Q06JA\nST283Q07JA\nST283Q08JA\nST283Q09JA\nST275Q01WA\nST275Q02WA\nST275Q03WA\nST275Q04WA\nST275Q05WA\nST275Q06WA\nST275Q07WA\nST275Q08WA\nST275Q09WA\nST276Q01JA\nST276Q02JA\nST276Q03JA\nST276Q04JA\nST276Q05JA\nST276Q06JA\nST276Q07JA\nST276Q08JA\nST276Q09JA\nST276Q10JA\nST268Q01JA\nST268Q02JA\nST268Q03JA\nST268Q04JA\nST268Q05JA\nST268Q06JA\nST268Q07JA\nST268Q08JA\nST268Q09JA\nST290Q01WA\nST290Q02WA\nST290Q03WA\nST290Q04WA\nST290Q05WA\nST290Q06WA\nST290Q07WA\nST290Q08WA\nST290Q09WA\nST291Q01JA\nST291Q02JA\nST291Q03JA\nST291Q04JA\nST291Q05JA\nST291Q06JA\nST291Q07JA\nST291Q08JA\nST291Q09JA\nST291Q10JA\nST289Q01WA\nST289Q02JA\nST289Q03WA\nST289Q04JA\nST289Q05WA\nST289Q06JA\nST289Q07JA\nST289Q08WA\nST289Q09WA\nST289Q10WA\nST289Q11WA\nST289Q14JA\nST293Q01JA\nST293Q02JA\nST293Q03JA\nST293Q04JA\nST293Q05JA\nST293Q06JA\nST293Q07JA\nST293Q08JA\nST293Q09JA\nST292Q01JA\nST292Q02JA\nST292Q03JA\nST292Q04JA\nST292Q05JA\nST292Q06JA\nST297Q01JA\nST297Q03JA\nST297Q05JA\nST297Q06JA\nST297Q07JA\nST297Q09JA\nST334Q01JA\nST334Q02JA\nST334Q03JA\nST334Q04JA\nST334Q05JA\nST334Q06JA\nST334Q07JA\nST334Q08JA\nST334Q09JA\nST334Q10JA\nST335Q01JA\nST335Q02JA\nST335Q03JA\nST335Q05JA\nST335Q06JA\nST335Q07JA\nST336Q01JA\nST336Q03JA\nST336Q04JA\nST336Q05JA\nST336Q06JA\nST336Q07JA\nST337Q01JA\nST337Q02JA\nST337Q03JA\nST337Q04JA\nST337Q05JA\nST337Q06JA\nST337Q07JA\nST337Q08JA\nST338Q01JA\nST338Q02JA\nST338Q03JA\nST338Q04JA\nST338Q05JA\nST338Q06JA\nST338Q07JA\nST338Q08JA\nST339Q04JA\nST339Q06JA\nST340Q01JA\nST340Q02JA\nST340Q03JA\nST340Q04JA\nST340Q05JA\nST340Q06JA\nST340Q07JA\nST340Q08JA\nST340Q09JA\nST340Q10JA\nST341Q01JA\nST341Q02JA\nST341Q03JA\nST341Q04JA\nST341Q05JA\nST342Q01JA\nST342Q02JA\nST342Q03JA\nST342Q04JA\nST342Q06JA\nST342Q07JA\nST342Q08JA\nST300Q01JA\nST300Q02JA\nST300Q03JA\nST300Q04JA\nST300Q05JA\nST300Q06JA\nST300Q07JA\nST300Q08JA\nST300Q09JA\nST300Q10JA\nST327Q01JA\nST327Q02JA\nST327Q03JA\nST327Q04JA\nST327Q05JA\nST327Q06JA\nST327Q07JA\nST327Q08JA\nST330Q01WA\nST330Q02WA\nST330Q03WA\nST330Q04WA\nST330Q05WA\nST330Q06WA\nST330Q07WA\nST330Q08WA\nST330Q09WA\nST330Q11WA\nST330D10WA\nST324Q02JA\nST324Q04JA\nST324Q05JA\nST324Q07JA\nST324Q10JA\nST324Q11JA\nST324Q12JA\nST324Q13JA\nST324Q14JA\nST347Q01JA\nST347Q02JA\nST348Q01JA\nST348Q02JA\nST348Q03JA\nST348Q04JA\nST348Q05JA\nST348Q06JA\nST348Q07JA\nST348Q08JA\nST349Q01JA\nST350Q01JA\nST351Q01JA\nST351Q02JA\nST351Q03JA\nST351Q04JA\nST351Q05JA\nST351Q06JA\nST351Q07JA\nST351Q08JA\nST352Q01JA\nST352Q02JA\nST352Q03JA\nST352Q04JA\nST352Q05JA\nST352Q06JA\nST352Q07JA\nST352Q08JA\nST353Q01JA\nST353Q02JA\nST353Q03JA\nST353Q04JA\nST353Q05JA\nST353Q06JA\nST353Q07JA\nST353Q08JA\nST354Q01JA\nST354Q02JA\nST354Q03JA\nST354Q04JA\nST354Q05JA\nST354Q06JA\nST354Q07JA\nST354Q08JA\nST354Q09JA\nST354Q10JA\nST355Q01JA\nST355Q02JA\nST355Q03JA\nST355Q04JA\nST355Q05JA\nST355Q06JA\nST355Q07JA\nST355Q08JA\nST356Q01JA\nST331Q01JA\nST331Q02JA\nST331Q03JA\nFL150Q01TA\nFL150Q02TA\nFL150Q03TA\nFL164Q01HA\nFL164Q02HA\nFL164Q03HA\nFL164Q04HA\nFL164Q05HA\nFL164Q06HA\nFL164Q07HA\nFL164Q08HA\nFL164Q09HA\nFL164Q10HA\nFL164Q11HA\nFL164Q12HA\nFL164Q13HA\nFL164Q14HA\nFL164Q15HA\nFL164Q16HA\nFL166Q01HA\nFL166Q02HA\nFL166Q03HA\nFL166Q05HA\nFL166Q06HA\nFL166Q07HA\nFL174Q01JA\nFL174Q02JA\nFL174Q03JA\nFL174Q04JA\nFL174Q05JA\nFL174Q06JA\nFL174Q07JA\nFL167Q01HA\nFL167Q02HA\nFL167Q06JA\nFL167Q03HA\nFL167Q04HA\nFL167Q05HA\nFL167Q07JA\nFL170Q01JA\nFL170Q02JA\nFL170Q03JA\nFL170Q04JA\nFL170Q05JA\nFL170Q06JA\nFL170Q07JA\nFL159Q01HA\nFL159Q02HA\nFL159Q03HA\nFL159Q04HA\nFL160Q01HA\nFL160Q02HA\nFL160Q03HA\nFL160Q04HA\nFL161Q01HA\nFL161Q02HA\nFL161Q03HA\nFL162Q01HA\nFL162Q02HA\nFL162Q03HA\nFL162Q04HA\nFL162Q05HA\nFL162Q06HA\nFL163Q01HA\nFL163Q02HA\nFL163Q03HA\nFL163Q04HA\nFL163Q05HA\nFL171Q01JA\nFL171Q02JA\nFL171Q03JA\nFL171Q04JA\nFL171Q05JA\nFL171Q07JA\nFL171Q08JA\nFL171Q09JA\nFL171Q10JA\nFL171Q11JA\nFL171Q12JA\nFL169Q01HA\nFL169Q05JA\nFL169Q02HA\nFL169Q06JA\nFL169Q07JA\nFL169Q03HA\nFL169Q04HA\nFL169Q08JA\nFL169Q10JA\nFL169Q11JA\nFL172Q01JA\nFL172Q03JA\nFL172Q05JA\nFL172Q06JA\nIC170Q01JA\nIC170Q02JA\nIC170Q03JA\nIC170Q04JA\nIC170Q05JA\nIC170Q06JA\nIC170Q07JA\nIC171Q01JA\nIC171Q02JA\nIC171Q03JA\nIC171Q04JA\nIC171Q05JA\nIC171Q06JA\nIC172Q01JA\nIC172Q02JA\nIC172Q03JA\nIC172Q04JA\nIC172Q05JA\nIC172Q06JA\nIC172Q07JA\nIC172Q08JA\nIC172Q09JA\nIC173Q01JA\nIC173Q02JA\nIC173Q03JA\nIC173Q04JA\nIC174Q01JA\nIC174Q02JA\nIC174Q03JA\nIC174Q04JA\nIC174Q05JA\nIC174Q06JA\nIC174Q07JA\nIC174Q08JA\nIC174Q09JA\nIC174Q10JA\nIC175Q01JA\nIC175Q02JA\nIC175Q03JA\nIC175Q05JA\nIC176Q01JA\nIC176Q02JA\nIC176Q03JA\nIC176Q04JA\nIC176Q05JA\nIC176Q06JA\nIC176Q07JA\nIC176Q08JA\nIC184Q01JA\nIC184Q02JA\nIC184Q03JA\nIC184Q04JA\nIC177Q01JA\nIC177Q02JA\nIC177Q03JA\nIC177Q04JA\nIC177Q05JA\nIC177Q06JA\nIC177Q07JA\nIC178Q01JA\nIC178Q02JA\nIC178Q03JA\nIC178Q04JA\nIC178Q05JA\nIC178Q06JA\nIC178Q07JA\nIC179Q01JA\nIC179Q02JA\nIC179Q03JA\nIC179Q04JA\nIC179Q05JA\nIC179Q06JA\nIC180Q01JA\nIC180Q02JA\nIC180Q03JA\nIC180Q04JA\nIC180Q05JA\nIC180Q06JA\nIC180Q07JA\nIC180Q08JA\nIC181Q01JA\nIC181Q02JA\nIC181Q03JA\nIC181Q04JA\nIC182Q01JA\nIC182Q02JA\nIC182Q03JA\nIC183Q01JA\nIC183Q02JA\nIC183Q03JA\nIC183Q04JA\nIC183Q05JA\nIC183Q07JA\nIC183Q08JA\nIC183Q09JA\nIC183Q10JA\nIC183Q12JA\nIC183Q13JA\nIC183Q14JA\nIC183Q15JA\nIC183Q16JA\nWB150Q01HA\nWB151Q01HA\nWB152Q01HA\nWB153Q01HA\nWB153Q02HA\nWB153Q03HA\nWB153Q04HA\nWB153Q05HA\nWB154Q01HA\nWB154Q02HA\nWB154Q03HA\nWB154Q04HA\nWB154Q05HA\nWB154Q06HA\nWB154Q07HA\nWB154Q08HA\nWB154Q09HA\nWB155Q01HA\nWB155Q02HA\nWB155Q03HA\nWB155Q04HA\nWB155Q05HA\nWB155Q06HA\nWB155Q07HA\nWB155Q08HA\nWB155Q09HA\nWB155Q10HA\nWB156Q01HA\nWB158Q01HA\nWB160Q01HA\nWB161Q01HA\nWB162Q01HA\nWB162Q02HA\nWB162Q03HA\nWB162Q04HA\nWB162Q05HA\nWB162Q06HA\nWB162Q07HA\nWB162Q08HA\nWB162Q09HA\nWB163Q01HA\nWB163Q02HA\nWB163Q03HA\nWB163Q04HA\nWB163Q05HA\nWB163Q06HA\nWB163Q07HA\nWB163Q08HA\nWB164Q01HA\nWB165Q01HA\nWB166Q01HA\nWB166Q02HA\nWB166Q03HA\nWB166Q04HA\nWB167Q01HA\nWB168Q01HA\nWB168Q02HA\nWB168Q03HA\nWB168Q04HA\nWB171Q01HA\nWB171Q02HA\nWB171Q03HA\nWB171Q04HA\nWB172Q01HA\nWB173Q01HA\nWB173Q02HA\nWB173Q03HA\nWB173Q04HA\nWB176Q01HA\nWB177Q01HA\nWB177Q02HA\nWB177Q03HA\nWB177Q04HA\nWB032Q01NA\nWB032Q02NA\nWB031Q01NA\nWB178Q01HA\nWB178Q02HA\nWB178Q03HA\nWB178Q04HA\nWB178Q05HA\nWB178Q06HA\nWB178Q07HA\nPA001Q01TA\nPA001Q02TA\nPA001Q03TA\nPA003Q01TA\nPA003Q02TA\nPA003Q03TA\nPA003Q05IA\nPA003Q18WA\nPA003Q19WA\nPA003Q20WA\nPA003Q11JA\nPA003Q12JA\nPA003Q13JA\nPA003Q14JA\nPA003Q15JA\nPA003Q16JA\nPA003Q17JA\nPA196Q01WA\nPA196Q02WA\nPA196Q03WA\nPA196Q04WA\nPA197Q01WA\nPA197Q02WA\nPA197Q03WA\nPA197Q04WA\nPA197Q05WA\nPA008Q01TA\nPA008Q02TA\nPA008Q03TA\nPA008Q04TA\nPA008Q05TA\nPA008Q06NA\nPA008Q07NA\nPA008Q08NA\nPA008Q09NA\nPA008Q10NA\nPA009Q01NA\nPA009Q02NA\nPA009Q03NA\nPA009Q04NA\nPA009Q05NA\nPA009Q06NA\nPA009Q07NA\nPA009Q08NA\nPA009Q09NA\nPA009Q10NA\nPA009Q11NA\nPA007Q01TA\nPA007Q02TA\nPA007Q03TA\nPA007Q04TA\nPA007Q05TA\nPA007Q06TA\nPA007Q07TA\nPA007Q09NA\nPA007Q11NA\nPA007Q12NA\nPA007Q13NA\nPA007Q14NA\nPA007Q15NA\nPA005Q01TA\nPA006Q01TA\nPA006Q02TA\nPA006Q03TA\nPA006Q04TA\nPA006Q05TA\nPA006Q06TA\nPA006Q07TA\nPA006Q08TA\nPA006Q09TA\nPA006Q10TA\nPA006Q11TA\nPA006Q12HA\nPA006Q13HA\nPA006Q14HA\nPA166Q01HA\nPA167Q02HA\nPA167Q03HA\nPA167Q04HA\nPA167Q05HA\nPA183Q01JA\nPA183Q02JA\nPA183Q03JA\nPA183Q04JA\nPA183Q05JA\nPA183Q06JA\nPA183Q07JA\nPA183Q08JA\nPA018Q01NA\nPA018Q02NA\nPA018Q03NA\nPA177Q01HA\nPA177Q02HA\nPA177Q03HA\nPA177Q04HA\nPA177Q05HA\nPA177Q06HA\nPA177Q07HA\nPA177Q08HA\nPA180Q01HA\nPA182Q01HA\nPA175Q01HA\nPA175Q02HA\nPA175Q03JA\nPA175Q04JA\nPA185Q01JA\nPA185Q02JA\nPA185Q03JA\nPA185Q04JA\nPA185Q05JA\nPA185Q07JA\nPA185Q08JA\nPA185Q09JA\nPA185Q10JA\nPA186Q01JA\nPA186Q02JA\nPA186Q03JA\nPA186Q04JA\nPA186Q05JA\nPA186Q06JA\nPA186Q07JA\nPA186Q08JA\nPA187Q04JA\nPA187Q06JA\nPA188Q01JA\nPA188Q02JA\nPA188Q03JA\nPA188Q04JA\nPA188Q05JA\nPA188Q06JA\nPA188Q08JA\nPA188Q09JA\nPA188Q10JA\nPA189Q01JA\nPA189Q02JA\nPA189Q03JA\nPA189Q04JA\nPA189Q05JA\nPA189Q06JA\nPA189Q09JA\nPA189Q10JA\nPA194Q01JA\nPA195Q01JA\nPA041Q01TA\nPA042Q01TA\nEFFORT1\nEFFORT2\nOCOD1\nOCOD2\nOCOD3\nPROGN\nAGE\nGRADE\nISCEDP\nIMMIG\nCOBN_S\nCOBN_M\nCOBN_F\nLANGN\nREPEAT\nMISSSC\nSKIPPING\nTARDYSD\nEXERPRAC\nSTUDYHMW\nWORKPAY\nWORKHOME\nEXPECEDU\nMATHPREF\nMATHEASE\nMATHMOT\nDURECEC\nBSMJ\nSISCO\nRELATST\nBELONG\nBULLIED\nFEELSAFE\nSCHRISK\nPERSEVAGR\nCURIOAGR\nCOOPAGR\nEMPATAGR\nASSERAGR\nSTRESAGR\nEMOCOAGR\nGROSAGR\nINFOSEEK\nFAMSUP\nDISCLIM\nTEACHSUP\nCOGACRCO\nCOGACMCO\nEXPOFA\nEXPO21ST\nMATHEFF\nMATHEF21\nFAMCON\nANXMAT\nMATHPERS\nCREATEFF\nCREATSCH\nCREATFAM\nCREATAS\nCREATOOS\nCREATOP\nOPENART\nIMAGINE\nSCHSUST\nLEARRES\nPROBSELF\nFAMSUPSL\nFEELLAH\nSDLEFF\nMISCED\nFISCED\nHISCED\nPAREDINT\nBMMJ1\nBFMJ2\nHISEI\nICTRES\nHOMEPOS\nESCS\nFCFMLRTY\nFLSCHOOL\nFLMULTSB\nFLFAMILY\nACCESSFP\nFLCONFIN\nFLCONICT\nACCESSFA\nATTCONFM\nFRINFLFM\nICTSCH\nICTAVSCH\nICTHOME\nICTAVHOM\nICTQUAL\nICTSUBJ\nICTENQ\nICTFEED\nICTOUT\nICTWKDY\nICTWKEND\nICTREG\nICTINFO\nICTDISTR\nICTEFFIC\nSTUBMI\nBODYIMA\nSOCONPA\nLIFESAT\nPSYCHSYM\nSOCCON\nEXPWB\nCURSUPP\nPQMIMP\nPQMCAR\nPARINVOL\nPQSCHOOL\nPASCHPOL\nATTIMMP\nPAREXPT\nCREATHME\nCREATACT\nCREATOPN\nCREATOR\nW_FSTUWT\nW_FSTURWT1\nW_FSTURWT2\nW_FSTURWT3\nW_FSTURWT4\nW_FSTURWT5\nW_FSTURWT6\nW_FSTURWT7\nW_FSTURWT8\nW_FSTURWT9\nW_FSTURWT10\nW_FSTURWT11\nW_FSTURWT12\nW_FSTURWT13\nW_FSTURWT14\nW_FSTURWT15\nW_FSTURWT16\nW_FSTURWT17\nW_FSTURWT18\nW_FSTURWT19\nW_FSTURWT20\nW_FSTURWT21\nW_FSTURWT22\nW_FSTURWT23\nW_FSTURWT24\nW_FSTURWT25\nW_FSTURWT26\nW_FSTURWT27\nW_FSTURWT28\nW_FSTURWT29\nW_FSTURWT30\nW_FSTURWT31\nW_FSTURWT32\nW_FSTURWT33\nW_FSTURWT34\nW_FSTURWT35\nW_FSTURWT36\nW_FSTURWT37\nW_FSTURWT38\nW_FSTURWT39\nW_FSTURWT40\nW_FSTURWT41\nW_FSTURWT42\nW_FSTURWT43\nW_FSTURWT44\nW_FSTURWT45\nW_FSTURWT46\nW_FSTURWT47\nW_FSTURWT48\nW_FSTURWT49\nW_FSTURWT50\nW_FSTURWT51\nW_FSTURWT52\nW_FSTURWT53\nW_FSTURWT54\nW_FSTURWT55\nW_FSTURWT56\nW_FSTURWT57\nW_FSTURWT58\nW_FSTURWT59\nW_FSTURWT60\nW_FSTURWT61\nW_FSTURWT62\nW_FSTURWT63\nW_FSTURWT64\nW_FSTURWT65\nW_FSTURWT66\nW_FSTURWT67\nW_FSTURWT68\nW_FSTURWT69\nW_FSTURWT70\nW_FSTURWT71\nW_FSTURWT72\nW_FSTURWT73\nW_FSTURWT74\nW_FSTURWT75\nW_FSTURWT76\nW_FSTURWT77\nW_FSTURWT78\nW_FSTURWT79\nW_FSTURWT80\nUNIT\nWVARSTRR\nPV1MATH\nPV2MATH\nPV3MATH\nPV4MATH\nPV5MATH\nPV6MATH\nPV7MATH\nPV8MATH\nPV9MATH\nPV10MATH\nPV1READ\nPV2READ\nPV3READ\nPV4READ\nPV5READ\nPV6READ\nPV7READ\nPV8READ\nPV9READ\nPV10READ\nPV1SCIE\nPV2SCIE\nPV3SCIE\nPV4SCIE\nPV5SCIE\nPV6SCIE\nPV7SCIE\nPV8SCIE\nPV9SCIE\nPV10SCIE\nPV1MCCR\nPV2MCCR\nPV3MCCR\nPV4MCCR\nPV5MCCR\nPV6MCCR\nPV7MCCR\nPV8MCCR\nPV9MCCR\nPV10MCCR\nPV1MCQN\nPV2MCQN\nPV3MCQN\nPV4MCQN\nPV5MCQN\nPV6MCQN\nPV7MCQN\nPV8MCQN\nPV9MCQN\nPV10MCQN\nPV1MCSS\nPV2MCSS\nPV3MCSS\nPV4MCSS\nPV5MCSS\nPV6MCSS\nPV7MCSS\nPV8MCSS\nPV9MCSS\nPV10MCSS\nPV1MCUD\nPV2MCUD\nPV3MCUD\nPV4MCUD\nPV5MCUD\nPV6MCUD\nPV7MCUD\nPV8MCUD\nPV9MCUD\nPV10MCUD\nPV1MPEM\nPV2MPEM\nPV3MPEM\nPV4MPEM\nPV5MPEM\nPV6MPEM\nPV7MPEM\nPV8MPEM\nPV9MPEM\nPV10MPEM\nPV1MPFS\nPV2MPFS\nPV3MPFS\nPV4MPFS\nPV5MPFS\nPV6MPFS\nPV7MPFS\nPV8MPFS\nPV9MPFS\nPV10MPFS\nPV1MPIN\nPV2MPIN\nPV3MPIN\nPV4MPIN\nPV5MPIN\nPV6MPIN\nPV7MPIN\nPV8MPIN\nPV9MPIN\nPV10MPIN\nPV1MPRE\nPV2MPRE\nPV3MPRE\nPV4MPRE\nPV5MPRE\nPV6MPRE\nPV7MPRE\nPV8MPRE\nPV9MPRE\nPV10MPRE\nSENWT\nVER_DAT\ni\n\n\n\n\nSGP\n702\n70200052\n70200001\n08MS\n070200\nSGP01\n7020000\n70200\n0\n2\n313\n313\nNA\nNA\nNA\n1\n0\n0\n0\n0\n4\n10\n10\n2006\n1\n2\n1\n1\n1\n1\n7020002\n7020002\n2\n1\n3\n3\n3\n3\n9999997\n9999997\n7\n2\n1\n3\n2\n1\n3\n7\n2\n2\n4\n4\n3\n3\n2\n4\n4\n2\n2\n2\n1\n2\n1\n2\n2\n2\n2\n1\n2\n1\nNA\nNA\n1\n1\n1\nNA\n1\n1\n3\n4\n1\n1\n1\n1\n1\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n1\n1\n1\nNA\n2\nNA\n2\n3\nNA\n3\n2\n4\nNA\n2\n4\n2\n3\n1\n1\n1\n1\n1\n1\n1\n1\n1\n2\n2\n2\n2\n2\n2\n2\n2\n2\n5\n1\n6\n1\n1\n6\n5\n6\n1\n2\n3\n4\n2\n1\nNA\n8\nNA\nNA\nNA\nNA\nNA\nNA\n5\n5\nNA\n2\n1\n1\n4\nNA\n4\n2\nNA\n2\n2\nNA\nNA\nNA\nNA\n3\nNA\n3\nNA\nNA\n3\n4\n2\nNA\n5\nNA\nNA\n5\nNA\n5\n5\nNA\nNA\n5\n4\nNA\nNA\n2\n3\n4\n1\nNA\nNA\nNA\nNA\n5\n5\n5\nNA\nNA\nNA\nNA\n3\n5\nNA\n4\n3\n3\nNA\n3\nNA\nNA\nNA\n4\n5\n5\n5\nNA\nNA\n5\n1\nNA\nNA\nNA\nNA\n3\n4\n3\n4\n2\nNA\nNA\n3\n5\n2\n1\n3\nNA\nNA\nNA\nNA\nNA\nNA\n2\n2\n1\n3\nNA\nNA\nNA\n1\nNA\n1\n2\n2\nNA\nNA\n4\n55\n1\n1\n2\n3\nNA\n3\nNA\nNA\n4\n4\n3\n3\n3\n2\n2\n3\nNA\n3\nNA\nNA\n2\n3\n1\n4\nNA\nNA\nNA\n3\n3\n3\n2\n4\nNA\nNA\nNA\n2\n2\n2\nNA\n1\nNA\n4\nNA\nNA\nNA\n4\nNA\nNA\nNA\n3\n3\n3\n3\n2\n3\n3\n2\n3\n3\n3\n3\n3\nNA\n3\nNA\n3\n4\nNA\nNA\n2\n4\n3\n3\n3\nNA\nNA\nNA\nNA\nNA\n3\n2\n2\n5\nNA\nNA\nNA\nNA\n5\nNA\n4\nNA\n1\nNA\nNA\nNA\n4\nNA\n3\n2\n2\nNA\n4\n2\n2\n3\n2\nNA\n3\n0\n0\n0\n1\n0\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n5\nNA\nNA\n4\n2\n4\nNA\nNA\n4\n1\n1\nNA\n2\n1\n1\n3\n3\n3\n2\nNA\nNA\nNA\nNA\n2\nNA\nNA\n2\n7020003\n3\n3\nNA\n4\nNA\nNA\n3\nNA\n2\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n7\n8\n8\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n4\n4\n1\n4\n2\n2\n4\n4\n5\n1\n5\n2\n4\n3\n3\n3\n3\n3\n3\n3\n3\n3\n3\n1\n2\n6\n2\n4\n3\n2\n1\n1\n2\n2\n2\n2\n2\n2\n2\n1\n3\n3\n4\n4\n4\n3\n4\n4\n3\n4\n1\n1\n3\n2\n3\n2\n2\n2\n1\n3\n2\n3\n2\n2\n3\n1\n1\n1\n3\n2\n2\n1\n3\n3\n3\n2\n3\n3\n3\n1\nNA\nNA\nNA\nNA\n3\n3\n3\n4\n4\n4\n4\n4\n4\n4\n4\n4\n4\n4\n2\n2\n3\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n7\n9\n9701\n83\n2634\n07020002\n15.50\n0\n344\n1\n070200\n070200\n070200\n998\n0\n0\n0\n0\n1\n4\n0\n10\n7\n0\n0\n0\n3\n85.85\n1\n-0.2606\n0.2442\n-1.2280\n-0.7560\n-0.6386\n0.4369\n2.7951\n-0.0319\n1.3979\n-0.2970\n0.9777\n1.2321\nNA\nNA\n-0.3780\n0.3884\n-0.5635\n-0.4092\n0.1666\n0.3356\n-0.7746\n0.1429\n0.4317\n1.3180\n0.3729\n-0.1305\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n8\n7\n8\n16.0\n17.00\n30.34\n30.34\n0.1940\n0.7524\n0.1836\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n0.4062\n7\n0.3346\n6\n0.3623\n-0.1315\n-0.3767\n-0.4038\n0.2260\n-0.4469\n-0.3452\n-0.1855\n0.2929\nNA\n0.5764\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n5.35943\n8.20073\n2.63139\n8.03388\n8.18690\n7.89416\n8.04452\n2.67796\n2.72897\n7.74437\n2.67796\n2.73358\n8.18690\n8.20073\n2.58146\n2.68151\n2.63139\n2.73358\n7.89416\n2.72897\n8.03388\n7.89416\n2.63139\n8.03388\n7.88647\n7.89416\n8.36312\n2.67796\n2.62882\n8.03388\n2.78196\n2.73358\n8.18690\n8.20073\n2.67796\n2.68151\n2.73358\n2.63139\n7.89416\n2.62882\n8.03388\n8.20073\n2.63139\n8.03388\n8.18690\n7.89416\n8.04452\n2.67796\n2.72897\n7.74437\n2.67796\n2.73358\n8.18690\n8.20073\n2.58146\n2.68151\n2.63139\n2.73358\n7.89416\n2.72897\n8.03388\n7.89416\n2.63139\n8.03388\n7.88647\n7.89416\n8.36312\n2.67796\n2.62882\n8.03388\n2.78196\n2.73358\n8.18690\n8.20073\n2.67796\n2.68151\n2.73358\n2.63139\n7.89416\n2.62882\n8.03388\n1\n70\n639.004\n601.251\n621.480\n631.596\n579.276\n591.791\n600.709\n587.322\n618.131\n581.973\n676.298\n692.247\n690.981\n643.067\n627.908\n684.676\n661.380\n674.070\n666.282\n657.387\n710.634\n618.739\n591.623\n659.770\n635.892\n646.901\n603.569\n621.352\n659.674\n649.719\n649.392\n575.372\n603.792\n656.162\n625.136\n582.174\n665.104\n599.694\n616.165\n628.181\n615.137\n538.617\n587.580\n686.280\n589.078\n554.608\n682.886\n574.889\n601.470\n627.403\n686.193\n656.043\n650.782\n643.126\n675.389\n591.001\n684.203\n617.908\n601.076\n645.941\n597.328\n564.341\n655.238\n638.884\n604.706\n576.996\n672.527\n599.424\n604.423\n664.795\n604.382\n575.460\n534.443\n571.301\n675.638\n566.880\n582.805\n558.696\n662.795\n640.998\n518.732\n557.279\n497.254\n615.386\n615.007\n591.702\n595.836\n540.481\n600.664\n613.118\n602.757\n571.184\n646.605\n679.914\n685.582\n637.760\n645.213\n577.579\n661.673\n670.254\n537.068\n614.320\n583.272\n620.093\n634.054\n602.552\n595.217\n603.353\n611.942\n663.352\n0.63867\n01MAY23:14:19:45\n218\n\n\nSGP\n702\n70200134\n70200002\n08MS\n070200\nSGP01\n7020000\n70200\n0\n2\n313\n313\nNA\nNA\nNA\n1\n0\n0\n0\n0\n45\n10\n6\n2006\n2\n1\n1\n1\n1\n1\n7020001\n7020001\n1\n4\n3\n3\n4\n2\n9999997\n9999997\n8\n3\n2\n2\n3\n5\n2\n4\n4\n5\n5\n3\n5\n3\n2\n4\n4\n2\n2\n2\n2\n1\n1\n2\n2\n2\n2\n1\n1\n1\nNA\nNA\n1\n1\n1\nNA\n1\n1\n5\n5\n1\n1\n1\n1\n1\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n1\n1\n1\n4\n3\nNA\n2\n3\nNA\n4\nNA\n4\n2\nNA\n3\n2\n3\n1\n1\n1\n1\n2\n1\n1\n1\n1\n1\n1\n1\n1\n1\n2\n2\n2\n2\n4\n5\n2\n1\n3\n4\n4\n2\n1\n3\n2\n2\n3\n1\n1\n1\nNA\nNA\nNA\nNA\nNA\nNA\n6\n1\n5\n5\n1\nNA\nNA\n5\n4\nNA\n5\nNA\nNA\n3\nNA\n3\nNA\n5\n3\nNA\n4\nNA\nNA\n3\nNA\n5\nNA\nNA\nNA\nNA\n4\n5\nNA\n2\n3\n4\nNA\n2\nNA\nNA\n3\n4\n3\n5\nNA\nNA\n2\n4\nNA\n4\n2\nNA\nNA\nNA\n4\nNA\nNA\n3\nNA\n3\nNA\n3\n2\nNA\n3\nNA\nNA\nNA\nNA\n4\n3\n5\n4\n4\n2\nNA\nNA\nNA\n4\nNA\n4\nNA\n3\n4\n4\nNA\n4\nNA\nNA\n2\n5\nNA\nNA\n4\nNA\nNA\n3\n4\nNA\n4\nNA\n4\nNA\n4\n1\n1\n1\nNA\nNA\n10\n45\n3\n2\n3\n5\nNA\n4\n3\n4\n4\nNA\nNA\n4\n2\n2\n2\n1\n1\nNA\nNA\n2\n2\n2\nNA\nNA\n3\nNA\n3\n3\n3\n3\n2\nNA\nNA\nNA\n3\n4\n4\nNA\nNA\n4\nNA\nNA\n2\nNA\nNA\n3\n2\nNA\n3\n3\nNA\nNA\n4\n4\n3\n3\n3\n2\n3\n4\n4\n4\nNA\n3\nNA\n3\n3\nNA\n3\nNA\n3\nNA\n3\n3\nNA\nNA\n3\nNA\n3\n3\nNA\nNA\nNA\nNA\n5\nNA\nNA\nNA\n5\n5\n5\nNA\n5\nNA\n5\n5\nNA\n5\nNA\nNA\n4\n2\n2\nNA\n3\n3\n1\n1\n0\n1\n0\n0\n0\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n2\nNA\n3\n3\nNA\n3\n5\n1\n1\nNA\n1\n1\n1\n3\n3\nNA\nNA\nNA\n1\n1\n1\nNA\nNA\n1\n1\n9999999\n3\nNA\nNA\nNA\n2\n1\nNA\n1\n3\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n8\n10\n8\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n4\n4\n4\n4\n4\n4\n4\n2\n4\n1\n4\n1\n1\n4\n4\n4\n4\n4\n4\n4\n4\n4\n4\n2\n4\n6\n3\n3\n3\n3\n3\n3\n3\n3\n3\n3\n4\n3\n3\n3\n2\n2\n2\n3\n2\n1\n2\n3\n3\n3\n3\n3\n2\n3\n3\n3\n3\n3\n3\n3\n3\n3\n3\n3\n3\n3\n3\n2\n3\n3\n3\n3\n2\n3\n3\n2\n2\n2\n2\n1\nNA\nNA\nNA\nNA\n3\n2\n3\n4\n4\n4\n4\n4\n4\n4\n4\n2\n4\n4\n4\n4\n4\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n8\n8\n31\n21\n9705\n07020002\n15.83\n0\n344\n1\n070200\n070200\n070200\n998\n0\n0\n0\n0\n4\n7\n0\n2\n7\n1\n0\n0\n2\nNA\n0\n1.2437\n-0.0437\n-0.2016\n1.1246\n0.1810\n0.4540\n0.3058\n0.1187\n0.1290\n-0.1734\n-0.7402\n-0.5609\nNA\nNA\n-0.5969\n1.1687\n0.1475\n-0.7102\n0.0024\n-1.2147\n-0.5240\n-0.2874\n0.7644\n4.7588\n0.6647\n0.6178\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n7\n7\n7\n14.5\n37.83\n77.10\n77.10\n0.6249\n0.7842\n0.8261\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n0.4062\n7\n0.3346\n6\n2.8889\n0.5048\n0.3109\n0.4297\n-0.8080\n0.4182\n0.3311\n0.9444\n-0.4797\nNA\n0.7781\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n6.74318\n9.88533\n10.36607\n10.33466\n3.44489\n3.29511\n3.44489\n3.29830\n10.36607\n3.29511\n9.89489\n3.29830\n9.88533\n10.33466\n10.36607\n9.89489\n3.45536\n3.45536\n9.88533\n3.29830\n3.44489\n9.88533\n10.36607\n10.33466\n3.44489\n3.29511\n3.44489\n3.29830\n10.36607\n3.29511\n9.89489\n3.29830\n9.88533\n10.33466\n10.36607\n9.89489\n3.45536\n3.45536\n9.88533\n3.29830\n3.44489\n9.88533\n10.36607\n10.33466\n3.44489\n3.29511\n3.44489\n3.29830\n10.36607\n3.29511\n9.89489\n3.29830\n9.88533\n10.33466\n10.36607\n9.89489\n3.45536\n3.45536\n9.88533\n3.29830\n3.44489\n9.88533\n10.36607\n10.33466\n3.44489\n3.29511\n3.44489\n3.29830\n10.36607\n3.29511\n9.89489\n3.29830\n9.88533\n10.33466\n10.36607\n9.89489\n3.45536\n3.45536\n9.88533\n3.29830\n3.44489\n1\n53\n697.191\n754.277\n671.940\n657.300\n621.126\n655.729\n747.934\n694.365\n742.732\n656.934\n625.585\n686.716\n663.147\n567.435\n614.500\n604.745\n669.375\n623.735\n649.579\n571.261\n670.646\n748.839\n635.443\n639.735\n608.385\n670.662\n734.807\n639.748\n716.768\n655.670\n636.431\n674.370\n716.787\n616.569\n701.626\n686.793\n665.775\n729.194\n715.697\n688.830\n661.706\n762.401\n712.182\n685.954\n722.402\n677.709\n691.586\n688.120\n704.436\n692.040\n664.374\n660.937\n692.654\n654.111\n644.941\n699.918\n653.602\n629.891\n696.030\n663.634\n655.345\n732.821\n737.658\n651.654\n690.450\n666.422\n673.451\n728.294\n701.038\n650.797\n705.040\n710.217\n713.023\n679.747\n661.754\n718.268\n613.478\n643.541\n640.522\n655.268\n763.661\n729.497\n714.971\n753.899\n719.492\n715.191\n702.035\n704.257\n664.705\n705.987\n733.566\n744.273\n758.913\n695.003\n714.181\n716.221\n663.813\n662.428\n640.743\n768.695\n706.337\n672.767\n651.949\n620.759\n645.072\n677.174\n634.813\n648.907\n641.203\n644.001\n0.80357\n01MAY23:14:19:44\n218\n\n\nSGP\n702\n70200112\n70200003\n08MS\n070200\nSGP01\n7020000\n70200\n0\n2\n313\n313\nNA\nNA\nNA\n1\n0\n0\n0\n0\n8\n10\n7\n2006\n2\n1\n1\n2\n1\n1\n7020001\n7020002\n2\n1\n3\n3\n2\n1\n9999997\n9999997\n7\n2\n2\n2\n2\n1\n3\n4\n5\n2\n2\n3\n5\n3\n4\n5\n2\n2\n2\n2\n2\n2\n2\n2\n2\n2\n2\n2\n2\n1\nNA\nNA\n1\n2\n1\nNA\n2\n1\n8\n5\n1\n1\n1\n1\n1\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n1\n1\n1\n3\n3\n3\nNA\n3\nNA\n4\nNA\n3\n2\nNA\n2\n2\n3\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n2\n2\n2\n2\n2\n2\n2\n6\n2\n1\n1\n1\n6\n3\n1\n1\n3\n3\n2\n2\n2\n5\n7\nNA\nNA\nNA\nNA\nNA\nNA\n3\n3\n2\n2\nNA\n2\nNA\n4\n3\n3\nNA\n2\nNA\nNA\n3\nNA\n5\nNA\n3\nNA\n3\n4\nNA\nNA\n1\nNA\nNA\nNA\n3\nNA\nNA\n3\n3\nNA\n4\n3\n3\nNA\nNA\nNA\n3\n3\nNA\nNA\n4\n2\nNA\n4\nNA\n4\n2\nNA\nNA\n3\n3\nNA\nNA\n3\nNA\n3\nNA\n3\nNA\n2\nNA\n4\nNA\n3\n2\n4\nNA\n4\n3\nNA\nNA\n2\nNA\nNA\n3\n3\nNA\nNA\n2\n3\nNA\n4\nNA\n4\nNA\nNA\n3\n3\n3\nNA\nNA\n2\n3\nNA\n3\n2\nNA\nNA\n2\nNA\n2\n2\n3\nNA\nNA\n8\n56\n2\n3\n3\n5\nNA\n3\n3\nNA\n3\n4\n3\nNA\n3\n2\n2\n3\nNA\n2\n3\nNA\n1\nNA\n3\n2\nNA\nNA\nNA\n1\n3\nNA\n1\nNA\n2\n2\n2\nNA\nNA\n2\n1\nNA\nNA\n2\n1\nNA\nNA\nNA\nNA\n2\n1\nNA\n3\n4\n3\n3\n2\n3\n3\n2\n2\n4\n4\n4\nNA\n3\nNA\n2\n4\n3\n4\nNA\nNA\n2\nNA\n2\n2\nNA\n3\nNA\nNA\n1\nNA\nNA\n5\nNA\n4\nNA\nNA\n3\nNA\nNA\n5\nNA\n2\nNA\n4\n3\n3\nNA\n4\nNA\nNA\n2\n2\n3\n3\n3\n2\nNA\n0\n0\n1\n0\n0\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n5\nNA\n2\nNA\n2\nNA\n3\nNA\n1\n1\n1\nNA\n3\n1\n3\n3\n3\nNA\n1\n3\nNA\nNA\nNA\n1\n3\nNA\nNA\n7020003\nNA\nNA\n2\n3\n2\n2\n3\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n8\n9\n7\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n1\n1\n5\n5\n1\n5\n5\n4\n4\n4\n4\n3\n5\n4\n4\n3\n3\n3\n4\n3\n3\n4\n4\n5\n4\n6\n1\n4\n3\n4\n1\n1\n1\n3\n3\n3\n4\n2\n1\n1\n5\n4\n3\n5\n4\n2\n4\n1\n1\n3\n3\n1\n4\n2\n3\n2\n2\n2\n1\n5\n2\n2\n2\n1\n2\n1\n2\n2\n3\n2\n2\n3\n2\n3\n3\n2\n3\n3\n2\n1\nNA\nNA\nNA\nNA\n2\n3\n3\n3\n5\n2\n4\n3\n3\n2\n1\n1\n4\n2\n1\n1\n3\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n7\n8\n9701\n9704\n9704\n07020002\n15.75\n0\n344\n1\n070200\n970200\n070200\n998\n0\n0\n0\n0\n2\n3\n0\n0\n6\n0\n1\n0\nNA\nNA\n0\n0.7190\n-0.6137\n-1.2280\n0.4417\n-0.6386\n-0.4017\n-0.6563\n-0.6986\n-0.2087\n-0.4816\n-0.2053\n0.5777\nNA\nNA\n-1.0537\n0.2002\n-0.5635\n-0.6541\n-0.5604\n0.6908\n0.0949\n0.2226\n-0.4779\n0.4736\n0.0510\n-0.3993\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n4\n4\n4\n12.0\n17.00\nNA\n17.00\n-0.3987\n0.0666\n-1.0357\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n0.4062\n7\n0.3346\n6\n1.2313\n0.9454\n-0.1658\n-0.4292\n0.1088\n-0.3710\n-0.7926\n0.2941\n0.0811\nNA\n-0.8446\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n6.77500\n10.16250\n10.16250\n10.16250\n3.38750\n3.38750\n3.38750\n3.38750\n10.16250\n3.38750\n10.16250\n3.38750\n10.16250\n10.16250\n10.16250\n10.16250\n3.38750\n3.38750\n10.16250\n3.38750\n3.38750\n3.38750\n3.38750\n3.38750\n10.16250\n10.16250\n10.16250\n10.16250\n3.38750\n10.16250\n3.38750\n10.16250\n3.38750\n3.38750\n3.38750\n3.38750\n10.16250\n10.16250\n3.38750\n10.16250\n10.16250\n3.38750\n3.38750\n3.38750\n10.16250\n10.16250\n10.16250\n10.16250\n3.38750\n10.16250\n3.38750\n10.16250\n3.38750\n3.38750\n3.38750\n3.38750\n10.16250\n10.16250\n3.38750\n10.16250\n10.16250\n10.16250\n10.16250\n10.16250\n3.38750\n3.38750\n3.38750\n3.38750\n10.16250\n3.38750\n10.16250\n3.38750\n10.16250\n10.16250\n10.16250\n10.16250\n3.38750\n3.38750\n10.16250\n3.38750\n3.38750\n1\n2\n693.710\n654.450\n696.938\n646.187\n678.119\n644.019\n720.531\n671.425\n694.085\n668.304\n620.116\n559.078\n554.767\n587.026\n591.806\n570.547\n599.078\n545.610\n610.466\n590.758\n666.095\n604.771\n704.217\n687.659\n690.974\n617.175\n692.886\n630.900\n656.620\n649.087\n645.218\n680.260\n711.792\n633.124\n711.941\n749.576\n692.915\n648.755\n721.097\n657.165\n569.292\n647.507\n660.431\n569.983\n637.599\n652.780\n636.887\n611.227\n685.701\n604.016\n655.070\n612.146\n646.904\n590.767\n727.077\n648.958\n623.166\n677.449\n654.643\n649.460\n658.932\n648.412\n672.524\n614.591\n664.442\n687.078\n708.829\n640.191\n732.526\n619.894\n676.642\n705.385\n585.184\n670.486\n645.880\n760.958\n731.917\n676.092\n684.182\n702.866\n690.547\n728.787\n633.737\n703.501\n654.486\n734.709\n737.481\n685.489\n665.867\n727.280\n682.130\n692.729\n647.770\n629.600\n693.276\n660.979\n684.474\n656.617\n687.070\n648.410\n630.753\n694.543\n604.546\n614.087\n603.798\n644.046\n710.851\n656.938\n690.323\n664.134\n0.80736\n01MAY23:14:19:45\n218\n\n\nSGP\n702\n70200004\n70200004\n08MS\n070200\nSGP01\n7020000\n70200\n0\n2\n313\n313\nNA\nNA\nNA\n1\n0\n0\n0\n0\n40\n10\n2\n2006\n2\n2\n1\n1\n1\n1\n7020002\n7020002\n1\n2\n3\n3\n2\n1\n9999997\n9999997\n6\n2\n1\n2\n1\n1\n3\n3\n2\n1\n1\n2\n2\n1\n2\n2\n4\n2\n2\n2\n2\n2\n1\n4\nNA\nNA\nNA\nNA\n1\n5\nNA\nNA\n1\n1\n1\nNA\n2\n1\n4\n5\n1\n1\n1\n1\n1\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n1\n1\n1\n3\nNA\n2\nNA\n3\n3\nNA\n1\n2\n3\n3\n2\n2\nNA\n1\n1\n1\n1\n1\n1\n1\n1\n1\n2\n2\n2\n2\n2\n2\n2\n2\n2\n1\n1\n6\n4\n6\n6\n6\n6\n4\n1\n2\n3\n2\n1\n1\n1\nNA\nNA\nNA\nNA\nNA\nNA\n5\n5\n5\n1\nNA\n1\nNA\nNA\n4\n2\nNA\n2\n2\n4\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n3\n4\n4\n4\n3\n4\nNA\nNA\n4\nNA\n4\n4\n3\nNA\nNA\nNA\n3\nNA\n2\n2\n4\n2\nNA\nNA\nNA\nNA\n4\nNA\n4\n2\nNA\nNA\nNA\n4\n3\n4\n2\nNA\n4\nNA\nNA\nNA\n1\nNA\n4\nNA\nNA\n3\n4\n2\n4\nNA\n3\nNA\nNA\nNA\nNA\n3\n3\n3\n3\nNA\n3\n3\n3\nNA\nNA\n3\nNA\n3\n3\nNA\nNA\n3\nNA\n3\n3\n3\nNA\nNA\nNA\n3\nNA\n2\n3\n2\nNA\nNA\n10\n11\n3\n1\n2\n2\nNA\n2\nNA\nNA\n3\n2\n4\n4\n2\n2\n2\n2\n3\n3\n3\nNA\nNA\n3\nNA\n3\nNA\nNA\n3\nNA\n3\n3\nNA\n3\n3\nNA\nNA\n2\n4\n2\nNA\n3\n1\nNA\nNA\n2\nNA\nNA\nNA\n2\nNA\n2\n2\n2\nNA\n2\n3\n3\n2\n2\n2\n4\n4\n4\n3\n3\nNA\nNA\nNA\nNA\n2\n2\n2\n2\nNA\n2\nNA\nNA\nNA\nNA\n2\n2\n2\nNA\nNA\nNA\n1\nNA\n4\nNA\nNA\nNA\n5\n4\n4\n4\n5\nNA\nNA\nNA\nNA\n3\n5\n5\n2\n2\n2\nNA\n2\n2\n1\n0\n0\n1\n0\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n3\n3\n3\nNA\nNA\nNA\nNA\n3\n3\n3\n3\nNA\n3\n3\n3\n3\n3\n3\nNA\n3\nNA\nNA\nNA\n3\n3\nNA\n3\n9999999\nNA\nNA\n2\nNA\n2\nNA\n2\n2\n2\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n8\n10\n10\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n2\n4\n1\n1\n1\n1\n1\n1\n5\n1\n5\n1\n1\n4\n4\n4\n4\n4\n4\n4\n4\n4\n1\n1\n1\n1\n3\n3\n3\n3\n3\n3\n3\n3\n3\n3\n1\n2\n1\n2\n1\n1\n1\n2\n2\n1\n1\n3\n5\n4\n1\n1\n2\n2\n2\n2\n2\n2\n2\n1\n1\n1\n1\n1\n1\n1\n1\n1\n4\n1\n1\n2\n2\n2\n2\n2\n2\n2\n2\n2\nNA\nNA\nNA\nNA\n4\n4\n4\n3\n3\n3\n3\n3\n3\n3\n3\n3\n3\n3\n3\n3\n3\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n41\n9705\n2411\n07020002\n16.17\n0\n344\n1\n070200\n070200\n070200\n998\n0\n0\n0\n0\n5\n5\n6\n10\nNA\n0\n0\n0\n3\n76.65\n1\n-0.2194\n-1.1147\n-1.2280\n-0.7560\n-0.6386\n0.5617\n0.1778\n0.0849\n-0.1344\n-0.1538\n0.2201\n-0.0563\nNA\nNA\n-0.8521\n-0.1219\n-0.1002\n-0.0820\n0.1868\n-0.2194\n0.4959\n-0.9344\n-0.5515\n0.0594\n0.6387\n1.8158\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n6\n6\n6\n12.0\n43.33\nNA\n43.33\n-0.9028\n-0.9300\n-0.9606\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n0.4062\n7\n0.3346\n6\n2.8889\n-2.0101\n0.3109\n-0.6744\n-1.2894\n-0.5032\n-3.5000\n-0.6148\n-0.8360\nNA\n-0.5172\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n5.43200\n7.98824\n2.66275\n8.31429\n7.98824\n2.56226\n2.56226\n2.66275\n2.66275\n7.98824\n2.66275\n8.31429\n2.66275\n7.68679\n7.68679\n7.98824\n8.31429\n2.66275\n2.77143\n7.68679\n2.77143\n2.66275\n7.98824\n2.77143\n2.66275\n7.68679\n7.68679\n7.98824\n7.98824\n2.66275\n7.98824\n2.77143\n7.98824\n2.56226\n2.56226\n2.66275\n2.77143\n7.98824\n8.31429\n2.56226\n8.31429\n2.66275\n7.98824\n2.77143\n2.66275\n7.68679\n7.68679\n7.98824\n7.98824\n2.66275\n7.98824\n2.77143\n7.98824\n2.56226\n2.56226\n2.66275\n2.77143\n7.98824\n8.31429\n2.56226\n8.31429\n7.98824\n2.66275\n8.31429\n7.98824\n2.56226\n2.56226\n2.66275\n2.66275\n7.98824\n2.66275\n8.31429\n2.66275\n7.68679\n7.68679\n7.98824\n8.31429\n2.66275\n2.77143\n7.68679\n2.77143\n1\n27\n427.317\n410.376\n423.586\n388.935\n330.962\n379.988\n398.535\n422.127\n375.354\n453.348\n381.495\n400.815\n374.911\n367.484\n336.009\n324.630\n396.242\n374.723\n314.704\n342.956\n340.308\n329.889\n411.353\n327.974\n292.183\n355.423\n400.182\n317.518\n298.893\n362.702\n437.613\n498.958\n402.737\n407.151\n450.975\n487.698\n391.175\n426.641\n366.883\n435.455\n403.429\n419.847\n418.996\n375.158\n433.093\n453.028\n435.661\n441.660\n430.417\n382.344\n397.737\n336.048\n438.551\n347.416\n420.278\n401.609\n413.761\n299.027\n373.784\n363.817\n393.019\n393.366\n384.864\n379.824\n501.245\n453.339\n425.168\n407.016\n421.738\n421.415\n401.548\n389.686\n390.502\n434.343\n366.385\n401.969\n496.875\n353.233\n476.154\n342.948\n421.798\n467.856\n414.444\n445.029\n389.460\n414.555\n489.032\n363.830\n419.104\n394.856\n407.066\n381.339\n364.773\n406.470\n433.901\n406.423\n489.700\n432.277\n512.069\n374.502\n378.730\n400.807\n407.607\n336.451\n317.742\n349.040\n450.198\n392.060\n447.422\n382.088\n0.64732\n01MAY23:14:19:45\n218\n\n\nSGP\n702\n70200152\n70200005\n08MS\n070200\nSGP01\n7020000\n70200\n0\n2\n313\n313\nNA\nNA\nNA\n1\n0\n0\n0\n0\n42\n10\n9\n2006\n1\n2\n1\n1\n1\n1\n7020002\n7020002\n2\n2\n2\n2\n1\n4\n9999997\n9999997\n7\n2\n3\n2\n1\nNA\n4\n2\n4\n1\n1\n2\n2\n1\n2\n4\n4\n2\n2\n2\n2\n1\n2\n2\n2\n2\n2\n1\n2\n1\nNA\nNA\n1\n1\n1\nNA\n1\n1\n8\n5\n1\n1\n1\n1\n1\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n2\n1\n2\nNA\n3\nNA\n3\n3\n4\nNA\n1\n4\n1\n1\n4\nNA\n4\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n2\n2\n2\n2\n2\n1\n4\n1\n1\n6\n6\n5\n6\n1\n5\n6\n5\n4\n5\n5\n2\nNA\nNA\nNA\nNA\nNA\nNA\n4\n5\nNA\n5\n4\n4\n4\nNA\n3\nNA\nNA\n5\nNA\nNA\n4\n5\n4\n5\nNA\nNA\n4\nNA\nNA\n5\nNA\n4\n5\n1\n4\n5\n4\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n4\nNA\n2\n5\nNA\n5\nNA\n2\n2\nNA\nNA\nNA\nNA\n3\nNA\n3\n4\n3\nNA\nNA\nNA\n3\nNA\nNA\n2\n2\n5\n5\nNA\n5\n4\n5\nNA\n5\nNA\n5\n5\nNA\nNA\n5\n2\nNA\nNA\nNA\n3\n3\n5\n3\nNA\nNA\nNA\n3\n5\nNA\n2\nNA\n2\nNA\nNA\n4\nNA\n4\n4\nNA\n4\nNA\n1\n1\n1\nNA\nNA\n5\n30\n4\n3\n4\n4\nNA\n4\nNA\n4\n3\n3\nNA\n2\n1\n1\n1\n1\n3\n4\n2\n5\nNA\n5\nNA\nNA\nNA\nNA\nNA\n5\nNA\n5\n5\n5\nNA\n5\nNA\n2\n2\nNA\n1\n2\nNA\n2\nNA\nNA\n2\n2\n2\nNA\n2\nNA\n2\nNA\nNA\n3\n4\n4\n1\n3\n2\n4\n4\n4\nNA\n2\nNA\n2\n2\nNA\nNA\n2\n4\nNA\n2\n2\nNA\nNA\n2\nNA\nNA\n2\n2\nNA\nNA\n1\nNA\nNA\nNA\n4\n3\nNA\n4\n2\nNA\n5\n5\nNA\nNA\n5\nNA\nNA\n5\n3\n1\n1\nNA\n1\n1\n1\n1\n1\n1\n1\n1\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n5\nNA\n5\n5\n5\n5\nNA\n1\n1\nNA\n1\n1\n2\n3\n3\n3\n3\nNA\n3\nNA\n2\nNA\nNA\n2\nNA\n9999999\n4\n4\nNA\n2\nNA\nNA\nNA\n4\n2\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n10\n10\n10\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n5\n5\n6\n5\n4\n6\n5\n4\n4\n1\n4\n1\n1\n4\n4\n3\n3\n4\n4\n4\n4\n4\n5\n1\n5\n6\n3\n5\n5\n3\n3\n5\n5\n3\n3\n3\n5\n5\n1\n2\n5\n5\n5\n5\n5\n5\n5\n5\n1\n1\n1\n1\n4\n6\n4\n4\n4\n4\n5\n4\n6\n4\n4\n4\n4\n1\n2\n2\n4\n2\n4\n3\n3\n3\n3\n3\n3\n3\n2\n2\nNA\nNA\nNA\nNA\n2\n2\n3\n4\n4\n4\n4\n4\n4\n4\n4\n4\n4\n4\n5\n5\n5\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n10\n10\n23\n83\n21\n07020002\n15.58\n0\n344\n1\n070200\n070200\n070200\n998\n0\n0\n1\n1\n9\n7\n0\n5\n6\n0\n0\n0\nNA\n79.49\n1\n1.0726\n2.1143\n-1.2280\n1.1246\n-0.6386\n-0.5954\n0.3406\n0.8806\n-0.5172\n0.2470\n-0.9940\n-0.8597\nNA\nNA\n1.7459\n0.1166\n1.5558\n0.5051\n2.3426\n0.5478\n0.4121\n-0.9322\n-0.5730\n0.8973\n2.5026\n1.1353\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n7\n7\n7\n14.5\n75.54\n30.34\n75.54\n0.2514\n-0.8949\n0.0856\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n-1.6647\n5\n0.3346\n6\n1.8870\n0.6775\n1.0316\n0.2776\n2.9804\n1.3145\n0.8948\n0.8255\n0.4191\nNA\n1.0613\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n5.82353\n9.00000\n8.48571\n2.82857\n9.00000\n8.48571\n8.48571\n9.00000\n3.00000\n2.82857\n8.48571\n2.82857\n2.82857\n9.00000\n8.48571\n3.00000\n2.82857\n3.00000\n3.00000\n9.00000\n3.00000\n9.00000\n8.48571\n2.82857\n9.00000\n8.48571\n8.48571\n9.00000\n3.00000\n2.82857\n8.48571\n2.82857\n2.82857\n9.00000\n8.48571\n3.00000\n2.82857\n3.00000\n3.00000\n9.00000\n3.00000\n2.82857\n3.00000\n9.00000\n2.82857\n3.00000\n3.00000\n2.82857\n8.48571\n9.00000\n3.00000\n9.00000\n9.00000\n2.82857\n3.00000\n8.48571\n9.00000\n8.48571\n8.48571\n2.82857\n8.48571\n2.82857\n3.00000\n9.00000\n2.82857\n3.00000\n3.00000\n2.82857\n8.48571\n9.00000\n3.00000\n9.00000\n9.00000\n2.82857\n3.00000\n8.48571\n9.00000\n8.48571\n8.48571\n2.82857\n8.48571\n1\n35\n436.462\n453.450\n392.315\n439.986\n443.125\n452.648\n396.970\n459.945\n438.166\n448.084\n448.199\n560.636\n365.478\n469.970\n503.664\n481.215\n436.800\n531.226\n480.997\n478.578\n456.333\n453.400\n498.937\n532.324\n508.231\n504.461\n404.572\n549.457\n411.062\n473.613\n474.516\n521.987\n434.209\n432.725\n392.901\n444.589\n382.733\n497.778\n439.754\n486.126\n432.794\n494.698\n429.147\n464.070\n446.069\n441.193\n417.452\n474.220\n443.916\n476.528\n429.063\n437.136\n451.101\n464.708\n338.774\n453.538\n366.873\n469.776\n438.499\n484.175\n429.756\n491.067\n445.708\n510.568\n403.908\n412.346\n419.173\n576.384\n392.309\n461.595\n437.563\n474.378\n433.958\n442.276\n522.369\n417.482\n444.665\n464.823\n434.014\n458.216\n454.383\n401.375\n453.331\n414.743\n443.411\n391.559\n386.903\n452.824\n478.373\n407.059\n414.746\n399.365\n447.814\n454.758\n442.892\n463.269\n423.967\n464.304\n435.375\n495.469\n364.784\n399.972\n452.831\n394.357\n409.755\n428.787\n375.015\n414.975\n441.178\n421.531\n0.69397\n01MAY23:14:19:44\n218\n\n\nSGP\n702\n70200043\n70200006\n08MS\n070200\nSGP01\n7020000\n70200\n0\n2\n313\n313\nNA\nNA\nNA\n1\n0\n0\n0\n0\n15\n10\n9\n2006\n1\n2\n1\n1\n1\n1\n7020001\n7020002\n2\n1\n2\n3\n2\n1\n9999997\n9999997\n7\n2\n2\n2\n2\n1\n2\n2\n1\n2\n2\n5\n5\n5\n2\n1\n3\n2\n2\n2\n2\n1\n1\n2\n2\n1\n1\n1\n1\n1\nNA\nNA\n2\n2\n2\n1\n2\n1\n3\n5\n1\n1\n1\n1\n1\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n1\n1\n2\n4\n3\n3\nNA\n3\n4\nNA\nNA\n4\n2\n2\nNA\n2\n4\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n2\n2\n2\n1\n2\n2\n2\n2\n1\n6\n3\n1\n1\n6\n6\n4\n1\n2\n3\n2\n1\n1\n2\n5\nNA\nNA\nNA\nNA\nNA\nNA\n6\n5\n4\nNA\n6\n2\nNA\n3\nNA\nNA\nNA\n3\nNA\n4\n5\n4\n4\nNA\nNA\n4\nNA\n4\nNA\nNA\n2\n4\n4\nNA\n4\nNA\n4\nNA\n4\nNA\n4\nNA\nNA\n1\nNA\n1\n1\nNA\nNA\n5\n5\nNA\n1\n1\nNA\n5\n1\nNA\nNA\nNA\nNA\n3\nNA\n3\n5\nNA\nNA\n5\nNA\n3\n5\nNA\nNA\n4\nNA\n5\n1\nNA\n2\n5\nNA\nNA\nNA\n2\n3\n4\nNA\n5\n1\nNA\nNA\nNA\n4\n2\nNA\n5\n5\nNA\nNA\n3\nNA\n1\nNA\nNA\n1\n1\n1\nNA\nNA\n1\n4\n1\n1\nNA\nNA\n7\n26\n1\n1\n1\n2\nNA\n3\n3\nNA\n3\n3\nNA\n3\n3\n1\n1\n2\n1\nNA\n1\nNA\n5\nNA\n5\n5\nNA\n4\nNA\n4\nNA\nNA\n3\n4\nNA\n4\n2\n2\n2\nNA\nNA\nNA\nNA\n2\n1\nNA\n2\nNA\n2\nNA\nNA\n2\n2\n2\nNA\n3\n3\n3\n3\n3\n2\n4\n4\n4\nNA\nNA\n3\nNA\n4\n2\n4\nNA\n4\nNA\nNA\n2\n2\nNA\n2\n3\n2\nNA\nNA\nNA\nNA\nNA\n4\nNA\n5\n5\nNA\n5\n5\nNA\nNA\n4\nNA\n5\nNA\n5\nNA\nNA\n5\n3\n2\n4\nNA\n4\n4\n2\n0\n0\n0\n1\n0\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n5\n5\n5\nNA\nNA\nNA\nNA\nNA\n5\n5\n1\n1\nNA\n1\n1\n1\n3\n3\n3\nNA\n3\n3\nNA\nNA\nNA\nNA\n3\n3\n9999999\nNA\n3\n4\nNA\n3\n2\nNA\n3\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n6\n10\n7\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n3\n6\n3\n3\n3\n3\n3\n5\n5\n5\n5\n1\n5\n4\n4\n4\n4\n4\n4\n3\n3\n3\n5\n3\n3\n6\n2\n4\n1\n3\n2\n2\n2\n3\n3\n3\n4\n5\n3\n3\n3\n4\n4\n4\n4\n4\n4\n3\n4\n4\n3\n3\n4\n4\n4\n4\n4\n1\n1\n4\n4\n4\n4\n4\n1\n1\n4\n2\n4\n4\n4\n4\n4\n2\n4\n1\n3\n3\n4\n1\nNA\nNA\nNA\nNA\n2\n2\n3\n4\n4\n4\n4\n3\n4\n4\n4\n4\n4\n4\n2\n3\n3\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n9701\n34\n22\n07020002\n15.58\n0\n344\n3\n970200\n970200\n970200\n998\n0\n0\n0\n1\n1\n10\n0\n5\n7\n0\n0\n0\n4\n76.98\n1\n1.1296\n0.5159\n-1.2280\n0.1413\n0.1810\n-0.1554\n0.3247\n4.8203\n-0.5881\n-0.8113\n0.2183\nNA\nNA\nNA\n1.7327\n-0.1006\n0.1475\n0.2635\n0.7819\n0.5515\n0.4936\n0.2637\n-0.2489\n2.2322\n-0.7358\n0.9918\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n7\n9\n9\n16.0\n17.00\n57.64\n57.64\n-0.4733\n-0.5988\n0.1268\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n-0.8411\n6\n0.3346\n6\n1.6615\n0.6012\n-0.0477\n0.9257\n0.3464\n0.4565\n0.4976\n1.9301\n0.2147\nNA\n0.3941\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n5.69931\n2.68850\n8.76685\n8.34850\n8.40156\n2.89878\n9.60179\n2.92228\n8.76685\n3.05511\n2.89878\n3.02482\n2.80052\n8.02740\n8.34850\n2.58510\n8.40156\n8.69635\n2.89878\n2.78283\n8.34850\n2.92228\n8.06550\n7.73009\n9.16534\n2.89878\n8.76685\n2.92228\n8.76685\n2.80052\n2.89878\n2.78283\n2.80052\n8.02740\n8.34850\n2.80052\n8.40156\n9.48693\n2.89878\n2.78283\n9.07446\n9.07446\n2.78283\n2.92228\n2.89878\n8.40156\n2.57670\n8.34850\n2.78283\n8.02740\n8.40156\n8.06550\n8.69635\n3.05511\n2.92228\n9.48693\n2.89878\n2.80052\n8.40156\n8.76685\n2.92228\n8.34850\n3.02482\n3.20060\n2.67580\n8.40156\n2.78283\n8.34850\n2.78283\n8.69635\n8.40156\n8.76685\n8.69635\n3.05511\n2.92228\n8.69635\n2.89878\n2.58510\n8.40156\n8.76685\n2.68850\n2\n50\n569.982\n539.609\n531.648\n534.368\n465.815\n528.509\n514.326\n521.029\n472.382\n503.387\n469.441\n500.350\n375.703\n377.452\n470.781\n415.448\n448.547\n434.381\n411.703\n410.846\n475.158\n470.030\n461.218\n504.199\n486.930\n493.011\n469.950\n464.012\n440.113\n495.410\n471.365\n546.743\n581.279\n567.093\n498.145\n519.416\n521.639\n513.726\n519.125\n544.408\n526.659\n580.938\n577.745\n622.873\n557.871\n488.815\n602.295\n578.260\n541.486\n572.958\n466.035\n498.416\n502.442\n517.999\n452.092\n494.653\n463.116\n498.289\n441.962\n411.098\n491.327\n522.747\n486.597\n524.480\n483.108\n505.925\n501.566\n506.734\n499.849\n442.838\n528.852\n604.877\n498.130\n511.479\n555.593\n555.839\n553.932\n571.562\n520.155\n609.277\n493.759\n538.097\n485.088\n465.568\n493.251\n545.850\n504.961\n532.093\n568.115\n485.863\n459.876\n490.634\n386.584\n499.082\n441.024\n544.965\n475.647\n504.819\n459.819\n481.600\n523.219\n536.264\n454.319\n501.514\n498.824\n523.705\n497.360\n508.547\n499.691\n580.387\n0.67917\n01MAY23:14:19:45\n218\n\n\nSGP\n702\n70200049\n70200007\n08MS\n070200\nSGP01\n7020000\n70200\n0\n2\n313\n313\nNA\nNA\nNA\n1\n0\n0\n0\n0\n13\n10\n3\n2006\n2\n1\n1\n1\n1\n1\n7020001\n7020002\n2\n1\n3\n3\n2\n4\n9999997\n9999997\n8\n2\n2\n3\n2\n1\n4\n4\n1\n1\n2\n2\n1\n1\n2\n4\n2\n2\n2\n2\n2\n2\n1\n4\n2\n2\n2\n2\n2\n1\nNA\nNA\n1\n1\n1\nNA\n1\n1\n4\n5\n1\n1\n1\n1\n1\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n1\n1\n1\n3\n1\n1\n1\nNA\nNA\nNA\n1\n2\n2\n3\n3\nNA\n3\n2\n4\n1\n1\n1\n2\n1\n1\n1\n1\n1\n3\n3\n1\n2\n2\n2\n2\n1\n1\n4\n1\n1\n6\n1\n5\n1\n3\n3\n2\n1\n2\n4\n9\nNA\nNA\nNA\nNA\nNA\nNA\n5\n5\n1\nNA\n1\n2\n4\nNA\nNA\nNA\nNA\n1\n5\n5\nNA\n2\n5\nNA\n2\n5\nNA\nNA\n2\nNA\nNA\n4\n4\nNA\n1\nNA\nNA\nNA\nNA\n4\n5\n4\n5\nNA\n3\n3\nNA\nNA\nNA\nNA\n2\n2\n5\nNA\nNA\nNA\n3\n3\n1\n2\nNA\nNA\n5\n1\nNA\nNA\nNA\n2\n4\nNA\n1\nNA\n4\nNA\nNA\nNA\n3\n4\n2\n4\n2\n4\n3\nNA\nNA\nNA\nNA\n2\n4\nNA\n3\n5\nNA\n3\nNA\nNA\nNA\nNA\n5\n2\n5\n2\nNA\n1\nNA\n2\nNA\nNA\n3\nNA\n2\n1\n1\nNA\nNA\n20\n75\n1\n1\n1\n2\nNA\n2\n2\nNA\n1\n2\nNA\n4\n2\n2\n2\n3\n1\nNA\nNA\n3\nNA\n4\nNA\n4\n4\n1\n1\nNA\nNA\n3\n1\n3\nNA\nNA\n3\nNA\nNA\n1\n3\nNA\nNA\n2\n4\nNA\n2\n2\n2\n2\nNA\nNA\n4\nNA\nNA\n4\n3\n4\n4\n4\n3\n4\n4\n4\nNA\nNA\n4\nNA\nNA\n4\n4\n3\n4\n3\n3\nNA\nNA\n4\n4\nNA\nNA\n3\nNA\nNA\nNA\nNA\n5\n5\nNA\n5\nNA\n5\n5\nNA\nNA\n3\nNA\nNA\nNA\n1\nNA\n3\n1\n2\n4\n4\n4\n4\n1\nNA\n0\n0\n0\n0\n0\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n5\nNA\nNA\n4\nNA\n3\nNA\n2\n1\n1\n1\nNA\n1\n1\n1\n1\n1\nNA\n3\n3\nNA\n3\n2\n2\nNA\nNA\nNA\n9999999\n3\nNA\nNA\n3\nNA\nNA\n2\n1\n2\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n7\n8\n8\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n5\n5\n1\n5\n1\n3\n3\n5\n5\n1\n5\n4\n5\n3\n3\n1\n3\n3\n2\n3\n2\n4\n3\n5\n3\n6\n1\n3\n1\n3\n1\n1\n5\n4\n3\n1\n3\n3\n1\n1\n3\n1\n1\n3\n3\n4\n5\n4\n1\n1\n3\n6\n4\n1\n3\n3\n2\n2\n1\n6\n1\n2\n2\n1\n1\n1\n2\n2\n4\n2\n2\n3\n2\n3\n4\n2\n3\n3\n1\n1\nNA\nNA\nNA\nNA\n3\n4\n4\n4\n3\n3\n2\n3\n3\n4\n2\n2\n4\n4\n2\n1\n2\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n7\n8\n11\n31\n2512\n07020002\n16.08\n0\n344\n1\n070200\n070200\n070200\n998\n0\n0\n0\n0\n2\n0\n0\n7\n9\n0\n0\n0\n3\n74.66\n1\n-1.0841\n-0.7185\n1.0692\n0.0936\n0.1810\n0.4375\n0.0134\n-0.7118\n-1.2602\n-0.1040\n0.4922\n0.8646\nNA\nNA\n-0.8815\n-0.8709\n-0.3322\n0.1421\n-0.5560\n-0.1287\n0.2869\n1.2000\n1.4010\n3.6192\n-0.9755\n-1.5183\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n6\n2\n6\n12.0\n70.34\n40.54\n70.34\n0.9904\n0.0975\n-0.0154\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n0.4062\n7\n0.3346\n6\n-0.2086\n0.5918\n-0.0210\n-0.3548\n-0.4834\n-0.2504\n-1.0853\n0.3353\n0.1939\nNA\n-0.5344\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n4.94118\n2.43429\n2.50909\n2.50588\n7.30286\n7.51765\n2.43429\n7.52727\n7.30588\n2.43429\n2.43529\n7.30588\n7.51765\n7.51765\n7.30588\n2.50909\n7.52727\n2.43529\n7.30286\n2.50909\n2.50588\n2.43429\n2.50909\n2.50588\n7.30286\n7.51765\n2.43429\n7.52727\n7.30588\n2.43429\n2.43529\n7.30588\n7.51765\n7.51765\n7.30588\n2.50909\n7.52727\n2.43529\n7.30286\n2.50909\n2.50588\n7.52727\n7.30286\n7.30588\n2.50909\n2.43529\n7.52727\n2.43429\n2.50588\n7.52727\n7.51765\n2.50588\n2.43529\n2.43529\n2.50588\n7.30286\n2.43429\n7.51765\n2.50909\n7.30286\n7.30588\n7.52727\n7.30286\n7.30588\n2.50909\n2.43529\n7.52727\n2.43429\n2.50588\n7.52727\n7.51765\n2.50588\n2.43529\n2.43529\n2.50588\n7.30286\n2.43429\n7.51765\n2.50909\n7.30286\n7.30588\n2\n65\n771.624\n672.817\n653.746\n734.817\n727.529\n729.831\n597.222\n772.277\n694.391\n725.298\n744.539\n679.852\n635.126\n725.555\n731.162\n684.683\n646.022\n756.805\n653.765\n784.710\n693.800\n626.981\n627.388\n676.792\n661.846\n618.396\n602.072\n653.976\n645.474\n662.553\n718.528\n708.196\n707.955\n720.423\n736.853\n670.624\n749.410\n729.058\n696.433\n779.263\n703.817\n707.636\n703.294\n631.382\n673.710\n645.381\n740.089\n757.451\n721.617\n715.842\n637.843\n712.634\n702.262\n702.844\n663.192\n632.845\n727.207\n719.259\n635.915\n774.625\n650.786\n721.049\n663.995\n680.657\n753.988\n667.512\n746.336\n801.521\n638.295\n734.227\n692.250\n678.493\n711.292\n711.104\n706.254\n749.436\n690.873\n708.684\n719.640\n671.520\n702.292\n662.039\n670.400\n658.479\n653.682\n699.759\n697.650\n692.704\n656.502\n698.151\n691.438\n671.611\n737.979\n731.602\n737.844\n763.672\n782.202\n769.825\n686.190\n708.430\n756.812\n700.122\n687.556\n701.049\n724.612\n680.763\n697.147\n736.499\n734.282\n727.392\n0.58883\n01MAY23:14:19:45\n218\n\n\nSGP\n702\n70200107\n70200008\n08MS\n070200\nSGP01\n7020000\n70200\n0\n2\n313\n313\nNA\nNA\nNA\n1\n0\n0\n0\n0\n39\n10\n4\n2006\n2\n1\n1\n1\n1\n1\n7020001\n7020002\n1\n1\n3\n3\n3\n1\n9999997\n9999997\n8\n2\n5\n3\n3\n5\n3\n5\n3\n5\n5\n4\n4\n5\n2\n4\n2\n2\nNA\n1\n1\n1\n1\n2\nNA\nNA\n1\n1\n1\n1\nNA\nNA\n2\n2\n2\n1\n2\n4\n8\n5\n1\n1\n1\n1\n1\n1\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n1\n1\n1\nNA\nNA\n3\n3\n3\n3\nNA\n3\n1\nNA\n3\n2\n3\n4\n3\n3\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n2\n2\n2\n2\n2\n6\n6\n1\n1\n1\n6\n6\n1\n1\n1\n8\n5\nNA\n3\n5\n7\nNA\nNA\nNA\nNA\nNA\nNA\n5\n5\n5\n5\nNA\n1\n5\nNA\n4\n3\nNA\n3\nNA\nNA\nNA\n1\n4\nNA\n4\nNA\nNA\nNA\n1\n4\n2\nNA\nNA\nNA\nNA\n5\nNA\nNA\n5\n2\n5\n5\nNA\n4\nNA\n1\nNA\n1\n1\n2\nNA\nNA\n2\nNA\n5\nNA\nNA\nNA\n5\n5\nNA\n5\n4\nNA\nNA\n1\nNA\n1\n5\n1\nNA\nNA\nNA\n5\n5\n5\nNA\n5\nNA\n5\nNA\n3\n2\nNA\nNA\nNA\n4\nNA\n1\n1\n5\nNA\n4\nNA\n4\nNA\n3\nNA\nNA\n4\nNA\n1\nNA\n2\nNA\n2\n4\n2\nNA\nNA\n3\n3\n3\nNA\nNA\n18\n75\n2\n2\n2\n4\nNA\n3\n2\n3\n3\nNA\n3\nNA\n2\n2\n2\n2\n1\n5\nNA\nNA\nNA\n5\nNA\n5\n5\nNA\nNA\n4\n5\nNA\n4\n5\n5\nNA\nNA\nNA\nNA\n1\n1\n1\n1\nNA\n1\nNA\n1\nNA\n1\n1\nNA\nNA\n4\n4\nNA\n4\n2\n3\n4\n2\n2\n4\n3\n3\n3\nNA\n3\nNA\nNA\nNA\n4\n4\n4\nNA\n4\n4\nNA\n4\n4\n4\nNA\nNA\nNA\nNA\nNA\nNA\n5\nNA\n5\n5\n5\nNA\nNA\nNA\n5\nNA\n3\nNA\n1\n1\nNA\n3\nNA\n5\n4\nNA\n4\n4\n4\n4\n0\n0\n1\n0\n1\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n5\nNA\nNA\nNA\n5\n5\n4\n5\nNA\nNA\n1\n1\nNA\n1\n1\n1\n1\n1\n3\nNA\nNA\n2\nNA\nNA\n2\nNA\n2\nNA\n7020003\n2\nNA\n2\nNA\n2\nNA\nNA\n2\n3\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n10\n10\n10\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n3\n6\n5\n5\n5\n5\n5\n5\n5\n5\n5\n5\n5\n3\n3\n3\n3\n3\n3\n3\n3\n3\n4\n4\n4\n4\n1\n4\n4\n4\n4\n1\n4\n4\n1\n4\n5\n5\n5\n5\n5\n5\n5\n5\n5\n5\n5\n5\n1\n1\n1\n1\n3\n3\n3\n1\n1\n1\n3\n3\n3\n3\n1\n1\n1\n3\n2\n2\n3\n2\n2\n3\n2\n3\n3\n3\n3\n3\n3\n1\nNA\nNA\nNA\nNA\n2\n2\n3\n4\n4\n4\n4\n1\n4\n4\n4\n4\n4\n1\n1\n4\n4\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n10\n10\n23\n21\n2310\n07020002\n16.00\n0\n344\n3\n970200\n970200\n970200\n998\n0\n0\n0\n0\n0\n10\n0\n0\n9\n1\n1\n1\nNA\n85.41\n1\n-0.3538\n-0.9290\n0.8814\n1.1246\n-0.6386\n0.8254\n2.0864\n-1.3496\n1.2934\n-1.0742\n-0.4546\n1.0424\nNA\nNA\n1.0172\n-0.2865\n-0.1002\n1.6989\n1.5350\n2.1323\n1.0454\n0.6614\n2.2551\n4.8471\n-2.3868\n-0.6406\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n9\n8\n9\n16.0\n75.54\n80.78\n80.78\n1.1035\n0.7991\n1.1558\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n-0.8411\n6\n0.3346\n6\n0.3623\n0.7732\n0.3744\n2.9420\n2.9804\n-0.5555\n-0.7088\n0.2941\n0.6984\nNA\n-0.1735\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n7.45313\n11.26250\n3.72656\n12.06696\n11.17969\n4.02232\n3.51953\n4.02232\n3.75417\n11.92500\n3.72656\n10.55859\n3.50735\n11.17969\n11.26250\n11.26250\n11.17969\n3.97500\n3.72656\n10.52206\n3.51953\n3.72656\n11.26250\n3.50735\n3.75417\n10.52206\n11.92500\n10.52206\n11.17969\n3.51953\n11.26250\n3.97500\n12.06696\n3.75417\n3.72656\n3.72656\n3.75417\n10.55859\n11.26250\n4.02232\n11.92500\n11.17969\n3.70221\n11.92500\n11.10662\n3.97500\n3.50735\n3.97500\n3.72656\n11.80078\n3.70221\n10.52206\n3.49653\n11.10662\n11.17969\n11.17969\n11.10662\n3.93359\n3.70221\n10.48958\n3.50735\n3.70221\n11.17969\n3.49653\n3.72656\n10.48958\n11.80078\n10.48958\n11.10662\n3.50735\n11.17969\n3.93359\n11.92500\n3.72656\n3.70221\n3.70221\n3.72656\n10.52206\n11.17969\n3.97500\n11.80078\n1\n1\n567.724\n630.957\n601.015\n628.501\n666.768\n661.167\n596.705\n611.592\n620.112\n619.595\n526.947\n562.617\n492.219\n509.621\n556.488\n533.708\n487.191\n527.884\n501.552\n545.783\n583.164\n635.482\n504.824\n627.459\n584.111\n567.106\n556.817\n532.212\n586.551\n554.037\n628.317\n690.041\n583.671\n651.162\n681.114\n656.790\n630.309\n603.415\n616.384\n744.633\n628.330\n645.092\n545.678\n597.876\n687.305\n628.140\n566.607\n590.176\n539.028\n701.336\n532.071\n623.793\n593.161\n559.257\n661.017\n530.236\n597.293\n581.571\n610.877\n583.064\n461.765\n638.860\n552.672\n592.829\n670.762\n638.462\n617.124\n561.769\n538.557\n716.829\n596.677\n697.988\n670.218\n595.541\n667.307\n687.567\n624.655\n645.881\n622.716\n639.228\n588.867\n663.858\n634.698\n612.223\n655.242\n671.400\n647.752\n680.585\n603.823\n642.875\n546.587\n663.982\n653.562\n553.418\n587.555\n713.430\n607.447\n686.587\n639.914\n647.539\n586.140\n659.576\n653.323\n572.491\n613.450\n672.383\n588.179\n628.349\n627.019\n599.225\n0.88817\n01MAY23:14:19:45\n218\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow code\nglimpse(sfu_qqq_SG)\n\n\nRows: 6,606\nColumns: 1,279\n$ CNT          &lt;chr&gt; \"SGP\", \"SGP\", \"SGP\", \"SGP\", \"SGP\", \"SGP\", \"SGP\", \"SGP\", \"…\n$ CNTRYID      &lt;dbl&gt; 702, 702, 702, 702, 702, 702, 702, 702, 702, 702, 702, 70…\n$ CNTSCHID     &lt;dbl&gt; 70200052, 70200134, 70200112, 70200004, 70200152, 7020004…\n$ CNTSTUID     &lt;dbl&gt; 70200001, 70200002, 70200003, 70200004, 70200005, 7020000…\n$ CYC          &lt;chr&gt; \"08MS\", \"08MS\", \"08MS\", \"08MS\", \"08MS\", \"08MS\", \"08MS\", \"…\n$ NatCen       &lt;chr&gt; \"070200\", \"070200\", \"070200\", \"070200\", \"070200\", \"070200…\n$ STRATUM      &lt;chr&gt; \"SGP01\", \"SGP01\", \"SGP01\", \"SGP01\", \"SGP01\", \"SGP01\", \"SG…\n$ SUBNATIO     &lt;chr&gt; \"7020000\", \"7020000\", \"7020000\", \"7020000\", \"7020000\", \"7…\n$ REGION       &lt;dbl&gt; 70200, 70200, 70200, 70200, 70200, 70200, 70200, 70200, 7…\n$ OECD         &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ ADMINMODE    &lt;dbl&gt; 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, …\n$ LANGTEST_QQQ &lt;dbl&gt; 313, 313, 313, 313, 313, 313, 313, 313, 313, 313, 313, 31…\n$ LANGTEST_COG &lt;dbl&gt; 313, 313, 313, 313, 313, 313, 313, 313, 313, 313, 313, 31…\n$ LANGTEST_PAQ &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ Option_CT    &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ Option_FL    &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ Option_ICTQ  &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n$ Option_WBQ   &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ Option_PQ    &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ Option_TQ    &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ Option_UH    &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ BOOKID       &lt;dbl&gt; 4, 45, 8, 40, 42, 15, 13, 39, 14, 7, 20, 17, 38, 24, 19, …\n$ ST001D01T    &lt;dbl&gt; 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 1…\n$ ST003D02T    &lt;dbl&gt; 10, 6, 7, 2, 9, 9, 3, 4, 8, 6, 10, 7, 9, 11, 5, 10, 11, 4…\n$ ST003D03T    &lt;dbl&gt; 2006, 2006, 2006, 2006, 2006, 2006, 2006, 2006, 2006, 200…\n$ ST004D01T    &lt;dbl&gt; 1, 2, 2, 2, 1, 1, 2, 2, 1, 2, 2, 1, 1, 2, 1, 2, 1, 2, 1, …\n$ ST250Q01JA   &lt;dbl&gt; 2, 1, 1, 2, 2, 2, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, …\n$ ST250Q02JA   &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n$ ST250Q03JA   &lt;dbl&gt; 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n$ ST250Q04JA   &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n$ ST250Q05JA   &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n$ ST250D06JA   &lt;chr&gt; \"7020002\", \"7020001\", \"7020001\", \"7020002\", \"7020002\", \"7…\n$ ST250D07JA   &lt;chr&gt; \"7020002\", \"7020001\", \"7020002\", \"7020002\", \"7020002\", \"7…\n$ ST251Q01JA   &lt;dbl&gt; 2, 1, 2, 1, 2, 2, 2, 1, 3, 3, 1, 2, 2, 1, 2, 2, 1, 2, 3, …\n$ ST251Q02JA   &lt;dbl&gt; 1, 4, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, …\n$ ST251Q03JA   &lt;dbl&gt; 3, 3, 3, 3, 2, 2, 3, 3, 4, 3, 2, 2, 3, 2, 3, 3, 2, 3, 4, …\n$ ST251Q04JA   &lt;dbl&gt; 3, 3, 3, 3, 2, 3, 3, 3, 4, 3, 2, 2, 3, 2, 3, 3, 2, 3, 4, …\n$ ST251Q06JA   &lt;dbl&gt; 3, 4, 2, 2, 1, 2, 2, 3, 4, 1, 3, 3, 1, 2, 2, 4, 4, 1, 2, …\n$ ST251Q07JA   &lt;dbl&gt; 3, 2, 1, 1, 4, 1, 4, 1, 4, 3, 1, 4, 1, 1, 4, 4, 1, 4, 1, …\n$ ST251D08JA   &lt;chr&gt; \"9999997\", \"9999997\", \"9999997\", \"9999997\", \"9999997\", \"9…\n$ ST251D09JA   &lt;chr&gt; \"9999997\", \"9999997\", \"9999997\", \"9999997\", \"9999997\", \"9…\n$ ST253Q01JA   &lt;dbl&gt; 7, 8, 7, 6, 7, 7, 8, 8, 8, 7, 7, 8, 5, 7, 7, 8, 5, 7, 7, …\n$ ST254Q01JA   &lt;dbl&gt; 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 1, 3, 2, 2, 2, 2, …\n$ ST254Q02JA   &lt;dbl&gt; 1, 2, 2, 1, 3, 2, 2, 5, 2, 2, 1, 3, 2, 1, 2, 2, 2, 2, 2, …\n$ ST254Q03JA   &lt;dbl&gt; 3, 2, 2, 2, 2, 2, 3, 3, 3, 4, 2, 3, 2, 2, 3, 3, 2, 3, 2, …\n$ ST254Q04JA   &lt;dbl&gt; 2, 3, 2, 1, 1, 2, 2, 3, 3, 2, 1, 3, 2, 2, 3, 3, 2, 3, 2, …\n$ ST254Q05JA   &lt;dbl&gt; 1, 5, 1, 1, NA, 1, 1, 5, 2, 2, 1, 1, 1, 1, 2, 1, 2, 1, 1,…\n$ ST254Q06JA   &lt;dbl&gt; 3, 2, 3, 3, 4, 2, 4, 3, 4, 4, 3, 3, 2, 3, 3, 4, 3, 4, 3, …\n$ ST255Q01JA   &lt;dbl&gt; 7, 4, 4, 3, 2, 2, 4, 5, 7, 4, 3, 7, 4, 4, 2, 4, 5, 4, 4, …\n$ ST256Q01JA   &lt;dbl&gt; 2, 4, 5, 2, 4, 1, 1, 3, 4, 4, 1, 4, 2, 2, 2, 3, 2, 2, 1, …\n$ ST256Q02JA   &lt;dbl&gt; 2, 5, 2, 1, 1, 2, 1, 5, 4, 2, 2, 4, 1, 2, 2, 2, 3, 5, 1, …\n$ ST256Q03JA   &lt;dbl&gt; 4, 5, 2, 1, 1, 2, 2, 5, 5, 1, 2, 4, 1, 3, 1, 4, 4, 5, 1, …\n$ ST256Q06JA   &lt;dbl&gt; 4, 3, 3, 2, 2, 5, 2, 4, 4, 1, 2, 4, 2, 2, 2, 3, 2, 2, 3, …\n$ ST256Q07JA   &lt;dbl&gt; 3, 5, 5, 2, 2, 5, 1, 4, 3, 1, 2, 4, 1, 2, 2, 2, 1, 5, 1, …\n$ ST256Q08JA   &lt;dbl&gt; 3, 3, 3, 1, 1, 5, 1, 5, 5, 2, 2, 4, 1, 1, 1, 3, 1, 5, 2, …\n$ ST256Q09JA   &lt;dbl&gt; 2, 2, 4, 2, 2, 2, 2, 2, 2, 3, 2, 4, 2, 2, 2, 2, 2, 2, NA,…\n$ ST256Q10JA   &lt;dbl&gt; 4, 4, 5, 2, 4, 1, 4, 4, 4, 3, 2, 4, 4, 1, 2, 4, 3, 3, 3, …\n$ ST230Q01JA   &lt;dbl&gt; 4, 4, 2, 4, 4, 3, 2, 2, 3, 4, 1, 3, 4, 1, 4, 3, 2, 3, 2, …\n$ ST005Q01JA   &lt;dbl&gt; 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, …\n$ ST006Q01JA   &lt;dbl&gt; 2, 2, 2, 2, 2, 2, 2, NA, 2, 2, NA, 2, 1, 2, 2, 2, 2, 2, 2…\n$ ST006Q02JA   &lt;dbl&gt; 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, NA, 1, 1, 2, 2, 1, 2, 2, 2,…\n$ ST006Q03JA   &lt;dbl&gt; 1, 2, 2, 2, 2, 2, 2, 1, 1, 1, NA, 1, 1, 2, 2, 1, 1, 1, 2,…\n$ ST006Q04JA   &lt;dbl&gt; 2, 1, 2, 2, 1, 1, 2, 1, 1, 2, NA, 2, 1, 2, 2, 2, 1, 2, 2,…\n$ ST006Q05JA   &lt;dbl&gt; 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, NA, 1, 2, 1, 2, 1, 1, 2, 1,…\n$ ST007Q01JA   &lt;dbl&gt; 2, 2, 2, 4, 2, 2, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, …\n$ ST008Q01JA   &lt;dbl&gt; 2, 2, 2, NA, 2, 2, 2, NA, 2, 2, NA, 2, 1, 2, 2, 2, 2, 2, …\n$ ST008Q02JA   &lt;dbl&gt; 2, 2, 2, NA, 2, 1, 2, NA, 2, 2, NA, 1, 1, 1, 2, 2, 1, 2, …\n$ ST008Q03JA   &lt;dbl&gt; 2, 2, 2, NA, 2, 1, 2, 1, 1, 2, NA, 1, 1, 2, 2, 2, 1, 1, 2…\n$ ST008Q04JA   &lt;dbl&gt; 1, 1, 2, NA, 1, 1, 2, 1, 1, 1, NA, 2, 1, 2, 2, 2, 1, 2, 2…\n$ ST008Q05JA   &lt;dbl&gt; 2, 1, 2, 1, 2, 1, 2, 1, 1, 2, NA, 1, 2, 2, 1, 2, 1, 2, 1,…\n$ ST258Q01JA   &lt;dbl&gt; 1, 1, 1, 5, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 2, 1, 1, …\n$ ST259Q01JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ ST259Q02JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ ST019AQ01T   &lt;dbl&gt; 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 2, 2, 1, …\n$ ST019BQ01T   &lt;dbl&gt; 1, 1, 2, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 2, 1, 2, 2, 2, 1, …\n$ ST019CQ01T   &lt;dbl&gt; 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 2, 1, 2, 2, 2, 1, …\n$ ST021Q01TA   &lt;dbl&gt; NA, NA, NA, NA, NA, 1, NA, 1, NA, NA, NA, NA, NA, 7, NA, …\n$ ST022Q01TA   &lt;dbl&gt; 1, 1, 2, 2, 1, 2, 1, 2, 1, 2, 1, 1, 1, 2, 2, 2, 2, 1, 1, …\n$ ST226Q01JA   &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n$ ST125Q01NA   &lt;dbl&gt; 3, 5, 8, 4, 8, 3, 4, 8, 8, 4, 8, 2, 7, 2, 3, 5, 8, 8, 3, …\n$ ST126Q01TA   &lt;dbl&gt; 4, 5, 5, 5, 5, 5, 5, 5, 4, 5, 5, 5, 5, 5, 4, 5, 5, 4, 5, …\n$ ST127Q01TA   &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n$ ST127Q02TA   &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n$ ST127Q03TA   &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n$ ST260Q01JA   &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, …\n$ ST260Q02JA   &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n$ ST260Q03JA   &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n$ ST261Q01JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 2, NA, NA…\n$ ST261Q02JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 2, NA, NA…\n$ ST261Q03JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 2, NA, NA…\n$ ST261Q04JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 2, NA, NA…\n$ ST261Q05JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 1, NA, NA…\n$ ST261Q06JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 2, NA, NA…\n$ ST261Q07JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 2, NA, NA…\n$ ST261Q08JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 1, NA, NA…\n$ ST261Q09JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 2, NA, NA…\n$ ST261Q10JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 2, NA, NA…\n$ ST261Q11JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 2, NA, NA…\n$ ST062Q01TA   &lt;dbl&gt; 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n$ ST062Q02TA   &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, …\n$ ST062Q03TA   &lt;dbl&gt; 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n$ ST267Q01JA   &lt;dbl&gt; NA, 4, 3, 3, NA, 4, 3, NA, 4, NA, NA, 4, 3, 3, 3, NA, 3, …\n$ ST267Q02JA   &lt;dbl&gt; 2, 3, 3, NA, 3, 3, 1, NA, 4, NA, 3, 4, 1, NA, 4, 2, 1, 4,…\n$ ST267Q03JA   &lt;dbl&gt; NA, NA, 3, 2, NA, 3, 1, 3, NA, 3, NA, 4, NA, 3, NA, 3, NA…\n$ ST267Q04JA   &lt;dbl&gt; 2, 2, NA, NA, 3, NA, 1, 3, 2, 2, 2, NA, 3, 1, 4, 1, 2, NA…\n$ ST267Q05JA   &lt;dbl&gt; 3, 3, 3, 3, 3, 3, NA, 3, NA, NA, 3, 4, NA, NA, NA, 4, 3, …\n$ ST267Q06JA   &lt;dbl&gt; NA, NA, NA, 3, 4, 4, NA, 3, 4, 3, NA, NA, 2, 3, 3, 4, 4, …\n$ ST267Q07JA   &lt;dbl&gt; 3, 4, 4, NA, NA, NA, NA, NA, 4, 3, 3, 4, 1, 3, 4, NA, NA,…\n$ ST267Q08JA   &lt;dbl&gt; 2, NA, NA, 1, 1, NA, 1, 3, NA, 2, 2, NA, NA, NA, NA, NA, …\n$ ST034Q01TA   &lt;dbl&gt; 4, 4, 3, 2, 4, 4, 2, 1, 3, 3, 3, 4, 2, 4, 3, 4, 3, 4, 3, …\n$ ST034Q02TA   &lt;dbl&gt; NA, 2, 2, 3, 1, 2, 2, NA, 1, 2, NA, 1, 3, 1, 4, 2, 3, 2, …\n$ ST034Q03TA   &lt;dbl&gt; 2, NA, NA, 3, 1, 2, 3, 3, 2, NA, 2, 1, 3, 1, 2, NA, 2, NA…\n$ ST034Q04TA   &lt;dbl&gt; 4, 3, 2, 2, 4, NA, 3, 2, NA, 3, 3, 4, 2, 4, 2, 4, NA, 4, …\n$ ST034Q05TA   &lt;dbl&gt; 2, 2, 2, 2, NA, 2, NA, 3, 2, 2, 2, NA, 3, 1, NA, 2, 2, 3,…\n$ ST034Q06TA   &lt;dbl&gt; 3, 3, 3, NA, 4, 4, 3, 4, 3, 3, 3, 4, NA, NA, 3, 4, 3, 4, …\n$ ST038Q03NA   &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 2, 3, 1, 1, 1, 1, 2, 1, 2, 2, 1, 1, 1, …\n$ ST038Q04NA   &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 4, 3, 2, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, …\n$ ST038Q05NA   &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n$ ST038Q06NA   &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, …\n$ ST038Q07NA   &lt;dbl&gt; 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, …\n$ ST038Q08NA   &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, …\n$ ST038Q09JA   &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n$ ST038Q10JA   &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, …\n$ ST038Q11JA   &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n$ ST265Q01JA   &lt;dbl&gt; 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 3, 1, 2, 1, 2, 1, 2, …\n$ ST265Q02JA   &lt;dbl&gt; 2, 1, 1, 2, 1, 2, 1, 1, 1, 1, 2, 1, 3, 1, 2, 1, 2, 1, 2, …\n$ ST265Q03JA   &lt;dbl&gt; 2, 1, 2, 2, 1, 2, 3, 1, 1, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, …\n$ ST265Q04JA   &lt;dbl&gt; 2, 1, 2, 2, 1, 2, 3, 1, 1, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, …\n$ ST266Q01JA   &lt;dbl&gt; 2, 1, 2, 2, 2, 1, 1, 2, 2, 1, 2, 2, 2, 1, 1, 2, 2, 2, 2, …\n$ ST266Q02JA   &lt;dbl&gt; 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, …\n$ ST266Q03JA   &lt;dbl&gt; 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, …\n$ ST266Q04JA   &lt;dbl&gt; 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, …\n$ ST266Q05JA   &lt;dbl&gt; 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, …\n$ ST294Q01JA   &lt;dbl&gt; 5, 4, 6, 1, 1, 1, 1, 6, 6, 1, 5, 1, 1, 1, 4, 3, 6, 6, 1, …\n$ ST294Q02JA   &lt;dbl&gt; 1, 5, 2, 1, 4, 6, 1, 6, 1, 1, 1, 1, 6, 1, 5, 1, 1, 1, 6, …\n$ ST294Q03JA   &lt;dbl&gt; 6, 2, 1, 6, 1, 3, 4, 1, 1, 1, 1, 1, 6, 1, 6, 1, 3, 1, 1, …\n$ ST294Q04JA   &lt;dbl&gt; 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n$ ST294Q05JA   &lt;dbl&gt; 1, 3, 1, 6, 6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 3, …\n$ ST295Q01JA   &lt;dbl&gt; 6, 4, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 1, 6, 6, 6, 3, 6, 6, …\n$ ST295Q02JA   &lt;dbl&gt; 5, 4, 3, 6, 5, 6, 1, 6, 6, 4, 6, 6, 6, 1, 5, 6, 6, 6, 6, …\n$ ST295Q03JA   &lt;dbl&gt; 6, 2, 1, 6, 6, 4, 5, 1, 1, 5, 3, 3, 6, 1, 6, 1, 4, 6, 1, …\n$ ST295Q04JA   &lt;dbl&gt; 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n$ ST295Q05JA   &lt;dbl&gt; 2, 3, 3, 1, 5, 2, 3, 1, 4, 6, 2, 3, 6, 3, 3, 1, 3, 4, 1, …\n$ ST326Q01JA   &lt;dbl&gt; 3, 2, 3, 2, 6, 3, 3, 8, 4, 3, 4, 4, 3, 7, 5, 3, 7, 6, 2, …\n$ ST326Q02JA   &lt;dbl&gt; 4, 2, 2, 3, 5, 2, 2, 5, 5, 5, 5, 3, 5, 2, 3, 3, 6, 4, 4, …\n$ ST326Q03JA   &lt;dbl&gt; 2, 3, 2, 2, 4, 1, 1, NA, 4, 4, 6, 5, 8, 1, 4, 3, 9, 4, 2,…\n$ ST326Q04JA   &lt;dbl&gt; 1, 1, 2, 1, 5, 1, 2, 3, 1, 2, 1, 2, 1, 2, 3, 2, 3, 2, 1, …\n$ ST326Q05JA   &lt;dbl&gt; NA, 1, 5, 1, 5, 2, 4, 5, 3, 5, 5, 5, 1, 9, 3, 1, 4, 6, 5,…\n$ ST326Q06JA   &lt;dbl&gt; 8, 1, 7, 1, 2, 5, 9, 7, 4, 5, 4, 7, 2, 9, 5, 1, 7, 7, 6, …\n$ ST326Q07JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ ST326Q08JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ ST326Q09JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ ST326Q10JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ ST326Q11JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ ST326Q12JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ ST322Q01JA   &lt;dbl&gt; 5, 6, 3, 5, 4, 6, 5, 5, 4, NA, 4, 5, 5, 1, 2, 5, NA, 4, 5…\n$ ST322Q02JA   &lt;dbl&gt; 5, 1, 3, 5, 5, 5, 5, 5, NA, 4, 2, 5, 5, NA, NA, 5, 4, 3, …\n$ ST322Q03JA   &lt;dbl&gt; NA, 5, 2, 5, NA, 4, 1, 5, 3, 5, NA, 4, 3, 4, 4, NA, 4, 4,…\n$ ST322Q04JA   &lt;dbl&gt; 2, 5, 2, 1, 5, NA, NA, 5, 3, 3, 4, 5, NA, 5, 5, 2, 2, NA,…\n$ ST322Q06JA   &lt;dbl&gt; 1, 1, NA, NA, 4, 6, 1, NA, 6, 4, 1, NA, 1, 1, 4, 1, 3, 4,…\n$ ST322Q07JA   &lt;dbl&gt; 1, NA, 2, 1, 4, 2, 2, 1, 1, 5, 2, 3, 1, 1, 1, 1, 5, 3, 1,…\n$ ST307Q01JA   &lt;dbl&gt; 4, NA, NA, NA, 4, NA, 4, 5, NA, NA, 5, NA, 4, NA, NA, 4, …\n$ ST307Q02JA   &lt;dbl&gt; NA, 5, 4, NA, NA, 3, NA, NA, 5, NA, NA, 5, NA, 4, NA, NA,…\n$ ST307Q03JA   &lt;dbl&gt; 4, 4, 3, 4, 3, NA, NA, 4, 2, 3, 4, 5, NA, NA, 4, 5, NA, N…\n$ ST307Q04JA   &lt;dbl&gt; 2, NA, 3, 2, NA, NA, NA, 3, 4, 4, NA, NA, NA, 1, 4, 2, 3,…\n$ ST307Q05JA   &lt;dbl&gt; NA, 5, NA, NA, NA, NA, NA, NA, NA, NA, 3, 4, NA, 4, 4, NA…\n$ ST307Q06JA   &lt;dbl&gt; 2, NA, 2, 2, 5, 3, 1, 3, NA, NA, NA, NA, 2, NA, 3, NA, NA…\n$ ST307Q07JA   &lt;dbl&gt; 2, NA, NA, 2, NA, NA, 5, NA, 4, 4, 2, 1, 2, 1, NA, 2, NA,…\n$ ST307Q08JA   &lt;dbl&gt; NA, 3, NA, 4, NA, 4, 5, NA, NA, 4, NA, NA, NA, NA, NA, 4,…\n$ ST307Q09JA   &lt;dbl&gt; NA, NA, 3, NA, 4, 5, NA, NA, 4, NA, 4, 4, 4, 5, 3, NA, 3,…\n$ ST307Q10JA   &lt;dbl&gt; NA, 3, NA, NA, 5, 4, 2, 1, NA, 3, NA, NA, 3, NA, NA, NA, …\n$ ST309Q01JA   &lt;dbl&gt; NA, NA, 5, NA, 4, 4, 5, 4, 5, NA, 4, NA, 5, NA, 5, NA, 4,…\n$ ST309Q02JA   &lt;dbl&gt; 3, 5, NA, NA, 5, NA, NA, NA, 4, NA, NA, 2, 5, NA, NA, NA,…\n$ ST309Q03JA   &lt;dbl&gt; NA, 3, 3, NA, NA, NA, 2, 4, 1, 4, 2, 1, 1, 5, 2, NA, NA, …\n$ ST309Q04JA   &lt;dbl&gt; 3, NA, NA, NA, NA, 4, 5, NA, NA, NA, NA, NA, NA, 4, NA, N…\n$ ST309Q05JA   &lt;dbl&gt; NA, 4, 3, NA, 4, NA, NA, NA, 5, 4, NA, NA, NA, NA, 4, 1, …\n$ ST309Q06JA   &lt;dbl&gt; NA, NA, 4, 3, NA, 4, NA, NA, 4, NA, NA, 1, 3, NA, NA, 3, …\n$ ST309Q07JA   &lt;dbl&gt; 3, NA, NA, 4, NA, NA, 2, 1, NA, 4, 3, 1, NA, 4, 4, 3, NA,…\n$ ST309Q08JA   &lt;dbl&gt; 4, 3, NA, 4, 5, NA, NA, 4, NA, 4, 4, NA, NA, 2, 5, NA, 3,…\n$ ST309Q09JA   &lt;dbl&gt; 2, NA, 1, 4, NA, 2, NA, 2, NA, NA, 3, NA, 2, 4, NA, 4, NA…\n$ ST309Q10JA   &lt;dbl&gt; NA, 5, NA, 3, 4, 4, 4, NA, NA, 3, NA, 5, NA, NA, NA, 3, 4…\n$ ST301Q01JA   &lt;dbl&gt; 5, NA, NA, 4, 5, 4, 4, NA, 3, 5, NA, NA, 3, NA, NA, NA, N…\n$ ST301Q02JA   &lt;dbl&gt; NA, NA, NA, NA, 1, NA, NA, NA, NA, 4, 4, 5, NA, NA, NA, 5…\n$ ST301Q03JA   &lt;dbl&gt; NA, NA, 3, NA, 4, 4, 1, NA, 2, NA, 2, 4, NA, NA, 4, 2, 3,…\n$ ST301Q04JA   &lt;dbl&gt; 5, NA, NA, 4, 5, NA, NA, 5, NA, 4, NA, 5, NA, 4, NA, 4, N…\n$ ST301Q05JA   &lt;dbl&gt; NA, 4, NA, NA, 4, 4, NA, NA, 5, NA, 4, 4, 3, NA, NA, 4, 3…\n$ ST301Q06JA   &lt;dbl&gt; 5, 5, 3, 4, NA, NA, NA, NA, 3, 4, 4, 5, 2, 4, 5, NA, 3, 4…\n$ ST301Q07JA   &lt;dbl&gt; 5, NA, 3, 4, NA, 4, NA, 5, NA, NA, NA, NA, 2, 4, NA, 4, N…\n$ ST301Q08JA   &lt;dbl&gt; NA, 2, NA, 3, NA, NA, 4, 2, 3, 2, NA, NA, NA, 2, 2, NA, 3…\n$ ST301Q09JA   &lt;dbl&gt; NA, 3, 4, NA, NA, 4, 5, 5, NA, NA, 5, NA, NA, 4, 5, NA, N…\n$ ST301Q10JA   &lt;dbl&gt; 5, 4, 3, NA, NA, NA, 4, 5, NA, NA, NA, NA, 3, NA, 4, NA, …\n$ ST343Q01JA   &lt;dbl&gt; 4, NA, 3, NA, NA, NA, 5, NA, 5, NA, NA, 5, 4, NA, NA, NA,…\n$ ST343Q02JA   &lt;dbl&gt; NA, 2, NA, 3, NA, 1, NA, 4, NA, 3, NA, 2, NA, 4, NA, NA, …\n$ ST343Q03JA   &lt;dbl&gt; NA, NA, NA, NA, 4, NA, 3, NA, NA, NA, 4, 5, NA, NA, NA, N…\n$ ST343Q04JA   &lt;dbl&gt; 2, NA, NA, 2, NA, 1, 3, 1, NA, 2, NA, NA, 3, NA, 3, 2, 2,…\n$ ST343Q05JA   &lt;dbl&gt; 3, 3, 3, 2, 2, 1, NA, NA, 1, NA, 2, NA, NA, NA, 5, 2, 4, …\n$ ST343Q06JA   &lt;dbl&gt; 4, 4, 3, 4, 5, NA, NA, 1, 5, 5, 4, 5, 4, 5, NA, 5, 3, NA,…\n$ ST343Q07JA   &lt;dbl&gt; 1, 3, NA, 2, NA, NA, NA, 1, NA, 3, 3, NA, NA, 3, 1, 3, NA…\n$ ST343Q08JA   &lt;dbl&gt; NA, 5, NA, NA, 5, 5, NA, 2, 5, NA, NA, NA, NA, 2, 3, NA, …\n$ ST343Q09JA   &lt;dbl&gt; NA, NA, 4, NA, NA, 5, 2, NA, 5, NA, NA, 5, 3, 3, 3, NA, N…\n$ ST343Q10JA   &lt;dbl&gt; NA, NA, 2, NA, 2, NA, 2, NA, NA, 2, 3, NA, 3, NA, NA, 4, …\n$ ST311Q01JA   &lt;dbl&gt; NA, 2, NA, NA, 2, 1, 5, 2, NA, NA, 2, 1, 2, 2, NA, 2, NA,…\n$ ST311Q02JA   &lt;dbl&gt; 5, 4, 4, 4, NA, 1, NA, NA, NA, NA, NA, NA, NA, NA, 4, NA,…\n$ ST311Q03JA   &lt;dbl&gt; 5, NA, NA, NA, NA, NA, NA, 5, 5, 5, NA, NA, NA, NA, 5, NA…\n$ ST311Q04JA   &lt;dbl&gt; 5, 4, 4, 4, NA, 5, NA, NA, NA, NA, 4, 5, 4, NA, 4, NA, 3,…\n$ ST311Q05JA   &lt;dbl&gt; NA, 2, 2, 2, NA, 1, 3, NA, NA, 1, NA, NA, NA, 2, 1, 2, NA…\n$ ST311Q06JA   &lt;dbl&gt; NA, NA, NA, NA, 3, NA, 3, NA, 5, NA, 3, 5, NA, NA, NA, NA…\n$ ST311Q07JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, 1, 5, NA, NA, NA, 3, 3, 2, NA, 1,…\n$ ST311Q08JA   &lt;dbl&gt; NA, NA, 3, NA, 3, NA, 2, 5, 5, 4, 3, 5, 3, 4, 4, 5, NA, N…\n$ ST311Q09JA   &lt;dbl&gt; 3, 4, 3, 4, 4, NA, NA, NA, 5, 4, NA, NA, 4, NA, NA, 4, NA…\n$ ST311Q10JA   &lt;dbl&gt; 5, NA, NA, 3, 3, 3, NA, 5, 5, 4, 3, NA, NA, 4, NA, NA, 3,…\n$ ST315Q01JA   &lt;dbl&gt; NA, NA, NA, 4, NA, NA, 5, 4, NA, NA, 3, 4, 4, NA, NA, NA,…\n$ ST315Q02JA   &lt;dbl&gt; 4, 3, 3, 2, NA, 3, 1, NA, 5, NA, NA, 5, NA, NA, NA, 5, NA…\n$ ST315Q03JA   &lt;dbl&gt; 3, NA, NA, NA, NA, 5, NA, NA, NA, 4, NA, NA, NA, 2, 2, NA…\n$ ST315Q04JA   &lt;dbl&gt; 3, 3, 3, 4, 3, NA, NA, 1, NA, 4, 4, NA, 3, 2, NA, NA, NA,…\n$ ST315Q05JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, 1, 2, NA, 1, 2, 3, 4, NA,…\n$ ST315Q06JA   &lt;dbl&gt; 3, 3, 3, NA, NA, 5, 2, 1, NA, NA, 3, NA, NA, NA, NA, 5, N…\n$ ST315Q07JA   &lt;dbl&gt; NA, 2, NA, NA, 2, NA, 4, 5, 1, NA, 3, NA, NA, 3, NA, 1, N…\n$ ST315Q08JA   &lt;dbl&gt; NA, NA, 2, 1, 2, 3, NA, 1, 3, 4, NA, NA, 3, NA, 4, 5, 2, …\n$ ST315Q09JA   &lt;dbl&gt; NA, 3, NA, NA, 5, 5, 1, NA, 4, 4, 3, 5, NA, 3, 3, 5, 4, 3…\n$ ST315Q10JA   &lt;dbl&gt; 4, NA, 4, 4, 5, NA, NA, NA, NA, NA, NA, 5, 4, NA, 3, NA, …\n$ ST303Q01JA   &lt;dbl&gt; 5, NA, NA, NA, NA, NA, 4, NA, 5, 4, 4, 5, NA, NA, NA, NA,…\n$ ST303Q02JA   &lt;dbl&gt; 5, NA, 3, NA, 5, 4, NA, 5, NA, NA, 4, 5, NA, 4, NA, NA, 3…\n$ ST303Q03JA   &lt;dbl&gt; 5, NA, 2, 3, 4, NA, NA, 5, 5, 4, NA, NA, 3, 4, 3, 5, 3, N…\n$ ST303Q04JA   &lt;dbl&gt; NA, 4, 4, 4, 5, 5, NA, 5, 5, NA, 4, 5, 3, 4, 5, 5, NA, NA…\n$ ST303Q05JA   &lt;dbl&gt; NA, 3, NA, 2, NA, 1, 3, NA, NA, 4, NA, 1, NA, 2, 4, 1, NA…\n$ ST303Q06JA   &lt;dbl&gt; 5, 5, 4, 4, 5, NA, 4, 5, 5, 4, 4, NA, 3, NA, 5, 5, 3, 4, …\n$ ST303Q07JA   &lt;dbl&gt; 1, 4, 3, NA, NA, 2, 2, NA, 3, 3, 3, NA, 3, NA, NA, 1, NA,…\n$ ST303Q08JA   &lt;dbl&gt; NA, 4, NA, 3, 5, 5, 4, 5, NA, NA, NA, 5, 3, 4, 4, NA, 3, …\n$ ST305Q01JA   &lt;dbl&gt; NA, 2, NA, NA, 5, NA, 2, NA, 5, NA, NA, 5, NA, 5, 2, 5, 2…\n$ ST305Q02JA   &lt;dbl&gt; NA, NA, 2, NA, NA, NA, 4, 3, NA, 3, 4, 3, 2, NA, NA, 5, N…\n$ ST305Q03JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, 3, 2, 5, 4, 4, NA, 3, NA, 2, NA, …\n$ ST305Q04JA   &lt;dbl&gt; 3, NA, NA, NA, 5, 2, NA, NA, NA, NA, NA, 5, NA, NA, NA, 1…\n$ ST305Q05JA   &lt;dbl&gt; 4, 4, 3, 3, 2, 3, NA, NA, NA, 4, NA, NA, 2, 5, 2, NA, 3, …\n$ ST305Q06JA   &lt;dbl&gt; 3, NA, 3, 3, NA, 4, NA, NA, 5, NA, 4, NA, NA, 4, NA, 5, 3…\n$ ST305Q07JA   &lt;dbl&gt; 4, 4, NA, 3, NA, NA, NA, 4, 3, 4, 3, 1, NA, NA, 4, NA, 3,…\n$ ST305Q08JA   &lt;dbl&gt; 2, NA, NA, 3, NA, 5, 2, NA, NA, NA, NA, NA, 3, 3, NA, NA,…\n$ ST305Q09JA   &lt;dbl&gt; NA, 3, 2, NA, 3, 1, 4, 1, 3, NA, 3, 4, NA, NA, 2, 3, NA, …\n$ ST305Q10JA   &lt;dbl&gt; NA, 4, 3, 3, 3, NA, NA, 1, NA, 4, NA, NA, 3, 4, NA, NA, N…\n$ ST345Q01JA   &lt;dbl&gt; 3, 4, NA, 3, 5, NA, 3, 5, 4, 4, NA, 3, 5, NA, NA, NA, 4, …\n$ ST345Q02JA   &lt;dbl&gt; 5, NA, 4, 3, 3, NA, 5, NA, NA, NA, NA, 3, 2, NA, 4, NA, 3…\n$ ST345Q03JA   &lt;dbl&gt; 2, 4, NA, NA, NA, 4, NA, 4, NA, NA, NA, NA, 5, 2, NA, NA,…\n$ ST345Q04JA   &lt;dbl&gt; 1, NA, 4, NA, NA, 2, 3, NA, 4, 3, 4, 3, NA, NA, NA, 2, 3,…\n$ ST345Q05JA   &lt;dbl&gt; 3, NA, NA, 3, NA, NA, NA, 4, 4, NA, NA, 3, 1, NA, 3, NA, …\n$ ST345Q06JA   &lt;dbl&gt; NA, 2, NA, NA, 3, 5, NA, NA, 5, 4, NA, NA, NA, 5, 3, 4, N…\n$ ST345Q07JA   &lt;dbl&gt; NA, 5, 3, 3, 5, 5, NA, 3, NA, 5, 5, NA, NA, 1, 5, NA, 5, …\n$ ST345Q08JA   &lt;dbl&gt; NA, NA, 3, 3, NA, NA, NA, NA, NA, 3, 4, 5, NA, NA, NA, 5,…\n$ ST345Q09JA   &lt;dbl&gt; NA, NA, 3, NA, 2, NA, 5, NA, 5, NA, 4, NA, 1, 5, 2, 5, NA…\n$ ST345Q10JA   &lt;dbl&gt; NA, 4, NA, NA, NA, 3, 2, 4, NA, NA, 4, NA, NA, 2, NA, 1, …\n$ ST313Q01JA   &lt;dbl&gt; NA, NA, NA, 3, 2, NA, 5, NA, NA, 4, NA, 5, NA, 4, NA, 3, …\n$ ST313Q02JA   &lt;dbl&gt; 2, NA, 2, NA, NA, 1, 2, 1, 4, NA, NA, 1, 3, NA, NA, 3, NA…\n$ ST313Q03JA   &lt;dbl&gt; 2, 3, 3, 3, NA, NA, NA, NA, 3, NA, NA, NA, 2, 2, NA, NA, …\n$ ST313Q04JA   &lt;dbl&gt; 1, 4, NA, 3, 4, NA, 1, 2, 2, NA, 2, NA, NA, NA, 4, 3, 1, …\n$ ST313Q05JA   &lt;dbl&gt; 3, NA, 3, 3, NA, 1, NA, NA, 4, NA, 4, 4, 1, 5, 3, NA, 3, …\n$ ST313Q06JA   &lt;dbl&gt; NA, 4, 2, NA, 4, 1, 2, 2, NA, 2, 4, 2, 5, 2, 5, NA, 1, 2,…\n$ ST313Q07JA   &lt;dbl&gt; NA, NA, NA, NA, 4, 1, NA, 4, 3, 4, NA, NA, NA, NA, 3, NA,…\n$ ST313Q08JA   &lt;dbl&gt; NA, 4, NA, NA, NA, NA, NA, 2, NA, NA, 2, 1, NA, NA, NA, 3…\n$ ST313Q09JA   &lt;dbl&gt; 1, NA, 2, 3, 4, NA, 3, NA, NA, 4, 3, NA, 3, NA, NA, 3, 1,…\n$ ST313Q10JA   &lt;dbl&gt; NA, 4, NA, NA, NA, 1, NA, NA, NA, 3, NA, NA, NA, 2, 4, NA…\n$ ST263Q02JA   &lt;dbl&gt; 1, 1, 2, 2, 1, 4, 2, 3, 3, 3, 3, 2, 4, 3, 2, 2, 2, 2, 3, …\n$ ST263Q04JA   &lt;dbl&gt; 2, 1, 2, 3, 1, 1, 1, 3, 2, 3, 1, 1, 3, 3, 2, 2, 1, 2, 3, …\n$ ST263Q06JA   &lt;dbl&gt; 2, 1, 3, 2, 1, 1, 1, 3, 2, 3, 1, 1, 3, 3, 2, 2, 1, 2, 3, …\n$ ST263Q08JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ ST016Q01NA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ ST059Q01TA   &lt;dbl&gt; 4, 10, 8, 10, 5, 7, 20, 18, 6, 3, 9, 10, 5, 12, 5, 7, 8, …\n$ ST059Q02JA   &lt;dbl&gt; 55, 45, 56, 11, 30, 26, 75, 75, 28, 15, 51, 63, 40, 75, 3…\n$ ST296Q01JA   &lt;dbl&gt; 1, 3, 2, 3, 4, 1, 1, 2, 1, 3, 3, 4, 3, 1, 2, 1, 3, 3, 2, …\n$ ST296Q02JA   &lt;dbl&gt; 1, 2, 3, 1, 3, 1, 1, 2, 1, 3, 3, 3, 2, 1, 4, 1, 3, 1, 1, …\n$ ST296Q03JA   &lt;dbl&gt; 2, 3, 3, 2, 4, 1, 1, 2, 1, 2, 3, 4, 3, 1, 3, 1, 3, 3, 2, …\n$ ST296Q04JA   &lt;dbl&gt; 3, 5, 5, 2, 4, 2, 2, 4, 4, 6, 4, 6, 6, 1, 5, 3, 4, 4, 3, …\n$ ST272Q01JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ ST273Q01JA   &lt;dbl&gt; 3, 4, 3, 2, 4, 3, 2, 3, 2, 3, 3, 3, NA, 2, NA, NA, 4, 4, …\n$ ST273Q02JA   &lt;dbl&gt; NA, 3, 3, NA, NA, 3, 2, 2, 2, 3, 3, NA, 4, 2, 4, 4, NA, 3…\n$ ST273Q03JA   &lt;dbl&gt; NA, 4, NA, NA, 4, NA, NA, 3, 3, 4, NA, 4, 4, NA, 4, 1, 4,…\n$ ST273Q04JA   &lt;dbl&gt; 4, 4, 3, 3, 3, 3, 1, 3, NA, NA, 3, 4, 4, 2, 4, 4, 4, NA, …\n$ ST273Q05JA   &lt;dbl&gt; 4, NA, 4, 2, 3, 3, 2, NA, 3, 3, 3, NA, 4, NA, 2, NA, 4, 4…\n$ ST273Q06JA   &lt;dbl&gt; 3, NA, 3, 4, NA, NA, NA, 3, NA, 3, 3, 4, NA, 2, NA, 1, NA…\n$ ST273Q07JA   &lt;dbl&gt; 3, 4, NA, 4, 2, 3, 4, NA, 3, NA, NA, 4, 4, 2, 2, 1, 4, 4,…\n$ ST270Q01JA   &lt;dbl&gt; 3, 2, 3, 2, 1, 3, 2, 2, 1, 2, 2, 1, 3, 3, 1, 1, 2, 1, 4, …\n$ ST270Q02JA   &lt;dbl&gt; 2, 2, 2, 2, 1, 1, 2, 2, 1, 2, 2, 1, 3, 1, 1, 1, 2, 1, 2, …\n$ ST270Q03JA   &lt;dbl&gt; 2, 2, 2, 2, 1, 1, 2, 2, 1, 2, 2, 1, 3, 2, 1, 1, 2, 1, 1, …\n$ ST270Q04JA   &lt;dbl&gt; 3, 1, 3, 2, 1, 2, 3, 2, 1, 2, 2, 1, 4, 2, 1, 1, 2, 1, 3, …\n$ ST285Q01JA   &lt;dbl&gt; NA, 1, NA, 3, 3, 1, 1, 1, NA, NA, 2, 1, 1, 1, 4, 5, NA, 2…\n$ ST285Q02JA   &lt;dbl&gt; 3, NA, 2, 3, 4, NA, NA, 5, 5, 4, NA, NA, 3, NA, 4, 5, NA,…\n$ ST285Q03JA   &lt;dbl&gt; NA, NA, 3, 3, 2, 1, NA, NA, 4, 4, 3, NA, NA, 1, 4, 5, NA,…\n$ ST285Q04JA   &lt;dbl&gt; NA, 2, NA, NA, 5, NA, 3, NA, NA, 4, NA, 5, 3, NA, 4, NA, …\n$ ST285Q05JA   &lt;dbl&gt; 2, 2, 1, NA, NA, 5, NA, NA, NA, NA, 2, NA, NA, 2, NA, NA,…\n$ ST285Q06JA   &lt;dbl&gt; 3, 2, NA, 3, 5, NA, 4, 5, 5, NA, 2, 5, NA, NA, NA, NA, 4,…\n$ ST285Q07JA   &lt;dbl&gt; 1, NA, 3, NA, NA, 5, NA, NA, 5, 2, 2, 5, 4, 2, NA, 5, 4, …\n$ ST285Q08JA   &lt;dbl&gt; 4, NA, 2, 3, NA, 5, 4, 5, 5, NA, NA, 5, 5, NA, NA, NA, 4,…\n$ ST285Q09JA   &lt;dbl&gt; NA, 3, NA, NA, NA, NA, 4, 5, NA, 4, NA, NA, NA, 1, 4, 5, …\n$ ST283Q01JA   &lt;dbl&gt; NA, NA, NA, NA, NA, 4, 1, NA, NA, 3, 2, 5, NA, NA, NA, 4,…\n$ ST283Q02JA   &lt;dbl&gt; NA, 3, NA, 3, NA, NA, 1, NA, 3, NA, 3, 5, NA, NA, NA, NA,…\n$ ST283Q03JA   &lt;dbl&gt; 3, 3, 1, NA, 5, 4, NA, 4, 5, 3, NA, 5, 3, 1, 4, 2, 4, NA,…\n$ ST283Q04JA   &lt;dbl&gt; 3, 3, 3, 3, NA, NA, NA, 5, NA, 3, NA, 5, NA, NA, 4, 5, NA…\n$ ST283Q05JA   &lt;dbl&gt; 3, 3, NA, 3, 5, NA, 3, NA, 5, 3, NA, NA, 4, NA, NA, NA, N…\n$ ST283Q06JA   &lt;dbl&gt; 2, 2, 1, NA, 5, 3, 1, 4, NA, NA, 2, NA, NA, 1, 4, NA, 4, …\n$ ST283Q07JA   &lt;dbl&gt; 4, NA, NA, 3, 5, 4, 3, 5, 5, NA, 3, NA, 3, 1, 4, NA, NA, …\n$ ST283Q08JA   &lt;dbl&gt; NA, NA, 2, 3, NA, NA, NA, 5, NA, NA, NA, 5, 2, 1, NA, 5, …\n$ ST283Q09JA   &lt;dbl&gt; NA, NA, 2, NA, 5, 4, NA, NA, 5, 3, 3, NA, 3, 1, 4, 5, 4, …\n$ ST275Q01WA   &lt;dbl&gt; NA, 3, 2, NA, NA, 2, 3, NA, 3, NA, 3, NA, NA, 4, 2, 1, 3,…\n$ ST275Q02WA   &lt;dbl&gt; 2, 4, NA, 2, 2, 2, NA, NA, NA, 3, NA, 1, NA, NA, NA, 3, 3…\n$ ST275Q03WA   &lt;dbl&gt; 2, 4, NA, 4, 2, 2, NA, NA, 2, 3, 3, NA, 3, 4, 1, 4, NA, N…\n$ ST275Q04WA   &lt;dbl&gt; 2, NA, 2, 2, NA, NA, 1, 1, 2, NA, NA, 1, NA, NA, 3, NA, N…\n$ ST275Q05WA   &lt;dbl&gt; NA, NA, 1, NA, 1, NA, 3, 1, NA, 2, NA, 1, 3, 2, 1, 1, 1, …\n$ ST275Q06WA   &lt;dbl&gt; 1, 4, NA, 3, 2, NA, NA, 1, 1, NA, NA, 1, NA, NA, 2, NA, N…\n$ ST275Q07WA   &lt;dbl&gt; NA, NA, NA, 1, NA, NA, NA, 1, 1, 2, 4, NA, 3, NA, NA, NA,…\n$ ST275Q08WA   &lt;dbl&gt; 4, NA, 2, NA, 2, 2, 2, NA, NA, NA, 2, 1, 4, 2, NA, NA, NA…\n$ ST275Q09WA   &lt;dbl&gt; NA, 2, 1, NA, NA, 1, 4, 1, NA, 2, 4, NA, 3, 2, NA, 1, 1, …\n$ ST276Q01JA   &lt;dbl&gt; NA, NA, NA, 2, NA, NA, NA, NA, NA, 2, 2, 1, 2, 2, 1, NA, …\n$ ST276Q02JA   &lt;dbl&gt; NA, NA, NA, NA, 2, 2, 2, 1, NA, NA, 2, NA, NA, NA, NA, NA…\n$ ST276Q03JA   &lt;dbl&gt; 4, 3, NA, NA, 2, NA, 2, NA, NA, NA, NA, 1, NA, 3, 1, 2, 3…\n$ ST276Q04JA   &lt;dbl&gt; NA, 2, NA, NA, 2, 2, 2, 1, 1, 2, NA, NA, NA, NA, NA, 2, 2…\n$ ST276Q05JA   &lt;dbl&gt; NA, NA, 2, 2, NA, NA, 2, 1, 2, NA, NA, 1, NA, 2, NA, 2, N…\n$ ST276Q06JA   &lt;dbl&gt; NA, 3, 1, NA, 2, NA, NA, NA, 1, 2, 2, NA, 1, NA, 1, NA, 2…\n$ ST276Q07JA   &lt;dbl&gt; 3, 3, NA, 2, NA, 2, NA, NA, NA, NA, NA, NA, NA, NA, 2, 2,…\n$ ST276Q08JA   &lt;dbl&gt; 3, NA, 3, 2, 2, 2, 4, 4, 4, NA, 3, 1, 4, NA, NA, NA, 4, 4…\n$ ST276Q09JA   &lt;dbl&gt; 3, NA, 4, 2, NA, 2, NA, 4, 1, 3, 2, 1, 3, 2, 3, 4, NA, NA…\n$ ST276Q10JA   &lt;dbl&gt; 3, 4, 3, NA, NA, NA, NA, NA, NA, 2, NA, NA, 3, 2, NA, NA,…\n$ ST268Q01JA   &lt;dbl&gt; 2, 4, 3, 2, 3, 3, 4, 4, 2, 3, 3, 4, 3, 4, 1, 3, 2, 3, 2, …\n$ ST268Q02JA   &lt;dbl&gt; 3, 3, 2, 3, 4, 3, 3, 2, 2, 2, 2, 3, 2, 2, 4, 3, 2, 3, 2, …\n$ ST268Q03JA   &lt;dbl&gt; 3, 3, 3, 3, 4, 3, 4, 3, 3, 3, 3, 4, 2, 4, 2, 2, 2, 3, 3, …\n$ ST268Q04JA   &lt;dbl&gt; 2, 3, 3, 2, 1, 3, 4, 4, 2, 3, 4, 4, 3, 4, 1, 3, 2, 2, 2, …\n$ ST268Q05JA   &lt;dbl&gt; 3, 2, 2, 2, 3, 3, 4, 2, 2, 3, 2, 3, 2, 3, 2, 3, 2, 2, 2, …\n$ ST268Q06JA   &lt;dbl&gt; 3, 3, 2, 2, 2, 2, 3, 2, 2, 3, 3, 3, 2, 4, 1, 2, 2, 2, 3, …\n$ ST268Q07JA   &lt;dbl&gt; 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, …\n$ ST268Q08JA   &lt;dbl&gt; 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, …\n$ ST268Q09JA   &lt;dbl&gt; 3, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, …\n$ ST290Q01WA   &lt;dbl&gt; NA, NA, NA, 3, NA, NA, NA, 3, NA, 3, 4, 4, NA, 4, 2, NA, …\n$ ST290Q02WA   &lt;dbl&gt; 3, 3, 3, 3, 2, NA, NA, NA, 4, NA, 4, 4, 3, 4, NA, NA, NA,…\n$ ST290Q03WA   &lt;dbl&gt; NA, NA, NA, NA, NA, 3, 4, 3, NA, NA, NA, 4, NA, 4, 2, NA,…\n$ ST290Q04WA   &lt;dbl&gt; 3, 3, 2, NA, 2, NA, NA, NA, 3, 3, NA, 4, 2, NA, 2, 3, 2, …\n$ ST290Q05WA   &lt;dbl&gt; 4, 3, 4, NA, 2, 4, NA, NA, NA, 3, 4, NA, 4, NA, NA, NA, N…\n$ ST290Q06WA   &lt;dbl&gt; NA, NA, 3, NA, NA, 2, 4, NA, NA, NA, 4, NA, 4, 4, NA, 4, …\n$ ST290Q07WA   &lt;dbl&gt; NA, 3, 4, 2, NA, 4, 4, 4, 4, 3, NA, NA, 4, NA, 2, 4, 4, N…\n$ ST290Q08WA   &lt;dbl&gt; 2, NA, NA, 2, 2, NA, 3, 4, 4, NA, NA, NA, NA, 4, 2, 4, NA…\n$ ST290Q09WA   &lt;dbl&gt; 4, 3, NA, 2, 4, 4, 4, 4, 4, 3, 4, NA, NA, NA, NA, 4, 4, 4…\n$ ST291Q01JA   &lt;dbl&gt; 3, NA, 2, 2, NA, NA, 3, NA, 4, NA, 4, NA, 3, 4, NA, 4, NA…\n$ ST291Q02JA   &lt;dbl&gt; 3, 3, NA, NA, 2, NA, 3, 4, 4, 3, NA, NA, 4, NA, 2, NA, 2,…\n$ ST291Q03JA   &lt;dbl&gt; 3, 3, 2, 2, 2, 2, NA, 4, 4, NA, 4, NA, NA, NA, NA, NA, 2,…\n$ ST291Q04JA   &lt;dbl&gt; NA, NA, 2, NA, NA, 2, NA, NA, NA, NA, NA, 4, NA, NA, NA, …\n$ ST291Q05JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, 4, 4, NA, NA, NA, 4, 2, 3, 2, 3, …\n$ ST291Q06JA   &lt;dbl&gt; NA, 3, 3, NA, 2, 2, 4, 4, 4, 2, 4, NA, NA, 4, 2, 3, NA, N…\n$ ST291Q07JA   &lt;dbl&gt; NA, NA, NA, NA, NA, 3, NA, 4, 4, 2, NA, NA, 2, 3, 2, NA, …\n$ ST291Q08JA   &lt;dbl&gt; NA, 3, NA, 2, NA, 2, NA, NA, NA, NA, 3, 4, NA, 2, 2, 2, N…\n$ ST291Q09JA   &lt;dbl&gt; 3, 3, 1, 2, 2, NA, 3, NA, NA, 2, 3, 4, NA, NA, NA, NA, NA…\n$ ST291Q10JA   &lt;dbl&gt; 2, NA, NA, 2, 2, NA, NA, NA, NA, 3, NA, 4, 2, NA, NA, NA,…\n$ ST289Q01WA   &lt;dbl&gt; 2, NA, NA, NA, NA, NA, NA, NA, NA, NA, 5, NA, NA, 2, NA, …\n$ ST289Q02JA   &lt;dbl&gt; 5, NA, 5, NA, NA, NA, NA, NA, 5, NA, NA, 5, 3, 5, NA, NA,…\n$ ST289Q03WA   &lt;dbl&gt; NA, NA, NA, NA, 1, NA, NA, NA, NA, 1, NA, 5, 1, NA, 1, NA…\n$ ST289Q04JA   &lt;dbl&gt; NA, 5, 4, 1, NA, 4, 5, 5, 5, NA, NA, 5, NA, NA, NA, NA, N…\n$ ST289Q05WA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, 5, NA, NA, 4, NA, NA, NA, NA, 4, …\n$ ST289Q06JA   &lt;dbl&gt; NA, NA, NA, 4, NA, 5, NA, 5, 5, NA, 5, NA, NA, 5, NA, 5, …\n$ ST289Q07JA   &lt;dbl&gt; 5, NA, 3, NA, 4, 5, 5, 5, NA, NA, NA, 5, NA, NA, 4, NA, N…\n$ ST289Q08WA   &lt;dbl&gt; NA, 5, NA, NA, 3, NA, NA, 5, NA, 2, NA, NA, 1, NA, 4, 2, …\n$ ST289Q09WA   &lt;dbl&gt; 4, 5, NA, NA, NA, 5, 5, NA, NA, NA, 5, NA, 4, NA, NA, 5, …\n$ ST289Q10WA   &lt;dbl&gt; NA, 5, 5, 5, 4, 5, 5, NA, 5, 5, NA, NA, NA, 5, NA, NA, NA…\n$ ST289Q11WA   &lt;dbl&gt; 1, NA, NA, 4, 2, NA, NA, NA, NA, NA, 1, NA, NA, 2, NA, 2,…\n$ ST289Q14JA   &lt;dbl&gt; NA, 5, 2, 4, NA, NA, NA, 5, 5, 5, 4, 5, 1, NA, 2, NA, 3, …\n$ ST293Q01JA   &lt;dbl&gt; NA, NA, NA, 4, 5, 4, 3, NA, 5, 3, 4, 5, 3, NA, NA, NA, NA…\n$ ST293Q02JA   &lt;dbl&gt; NA, 5, 4, 5, 5, NA, NA, 3, NA, NA, NA, 5, 4, 2, 4, 3, 5, …\n$ ST293Q03JA   &lt;dbl&gt; 4, 5, 3, NA, NA, 5, NA, NA, NA, 3, 5, NA, 4, NA, NA, NA, …\n$ ST293Q04JA   &lt;dbl&gt; NA, NA, 3, NA, NA, NA, NA, 1, 1, NA, NA, NA, 2, NA, 4, NA…\n$ ST293Q05JA   &lt;dbl&gt; 3, 5, NA, NA, 5, 5, 1, 1, 5, 4, 5, 5, NA, 1, NA, NA, 3, 2…\n$ ST293Q06JA   &lt;dbl&gt; 2, NA, 4, NA, NA, NA, NA, NA, NA, NA, 5, 5, NA, 1, 5, 5, …\n$ ST293Q07JA   &lt;dbl&gt; 2, NA, NA, 3, NA, NA, 3, 3, 2, NA, NA, 1, NA, 4, NA, 3, N…\n$ ST293Q08JA   &lt;dbl&gt; NA, 4, NA, 5, 5, 5, 1, NA, 5, 4, NA, NA, 2, NA, 4, 5, 2, …\n$ ST293Q09JA   &lt;dbl&gt; 4, 2, 2, 5, 3, 3, 2, 5, NA, 3, 5, NA, NA, 5, 3, 4, NA, NA…\n$ ST292Q01JA   &lt;dbl&gt; 2, 2, 2, 2, 1, 2, 4, 4, 2, 2, 3, 2, 2, 3, 1, NA, 3, 2, 3,…\n$ ST292Q02JA   &lt;dbl&gt; 2, NA, 3, 2, 1, 4, 4, NA, 3, 2, 3, 2, 3, 3, 1, 3, 3, 3, 3…\n$ ST292Q03JA   &lt;dbl&gt; 3, 3, 3, 2, NA, NA, 4, 4, 3, 2, NA, 3, 2, 3, 1, 4, 3, 3, …\n$ ST292Q04JA   &lt;dbl&gt; 2, 3, 3, NA, 1, 4, 4, 4, 3, 2, 3, 3, 2, 3, 1, 4, 3, 3, 3,…\n$ ST292Q05JA   &lt;dbl&gt; NA, 1, 2, 2, 1, 4, 1, 4, NA, NA, 2, 2, 1, 3, NA, 4, NA, N…\n$ ST292Q06JA   &lt;dbl&gt; 3, 1, NA, 2, 1, 2, NA, 4, 3, 1, 3, NA, NA, NA, 1, 2, 1, 2…\n$ ST297Q01JA   &lt;dbl&gt; 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, …\n$ ST297Q03JA   &lt;dbl&gt; 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, …\n$ ST297Q05JA   &lt;dbl&gt; 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, …\n$ ST297Q06JA   &lt;dbl&gt; 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, …\n$ ST297Q07JA   &lt;dbl&gt; 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, …\n$ ST297Q09JA   &lt;dbl&gt; 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, …\n$ ST334Q01JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ ST334Q02JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ ST334Q03JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ ST334Q04JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ ST334Q05JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ ST334Q06JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ ST334Q07JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ ST334Q08JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ ST334Q09JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ ST334Q10JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ ST335Q01JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ ST335Q02JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ ST335Q03JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ ST335Q05JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ ST335Q06JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ ST335Q07JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ ST336Q01JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ ST336Q03JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ ST336Q04JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ ST336Q05JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ ST336Q06JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ ST336Q07JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ ST337Q01JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ ST337Q02JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ ST337Q03JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ ST337Q04JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ ST337Q05JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ ST337Q06JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ ST337Q07JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ ST337Q08JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ ST338Q01JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ ST338Q02JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ ST338Q03JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ ST338Q04JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ ST338Q05JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ ST338Q06JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ ST338Q07JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ ST338Q08JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ ST339Q04JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ ST339Q06JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ ST340Q01JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ ST340Q02JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ ST340Q03JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ ST340Q04JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ ST340Q05JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ ST340Q06JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ ST340Q07JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ ST340Q08JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ ST340Q09JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ ST340Q10JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ ST341Q01JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ ST341Q02JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ ST341Q03JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ ST341Q04JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ ST341Q05JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ ST342Q01JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ ST342Q02JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ ST342Q03JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ ST342Q04JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ ST342Q06JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ ST342Q07JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ ST342Q08JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ ST300Q01JA   &lt;dbl&gt; NA, NA, NA, NA, NA, 5, NA, 5, NA, NA, 3, 5, NA, NA, NA, N…\n$ ST300Q02JA   &lt;dbl&gt; 5, NA, 5, 3, NA, 5, 5, NA, 5, 5, 5, 5, NA, NA, NA, NA, 5,…\n$ ST300Q03JA   &lt;dbl&gt; NA, NA, NA, 3, NA, 5, NA, NA, NA, NA, NA, 5, 1, NA, 4, NA…\n$ ST300Q04JA   &lt;dbl&gt; NA, 2, 2, 3, 5, NA, NA, NA, 1, NA, 1, NA, 1, NA, 3, NA, N…\n$ ST300Q05JA   &lt;dbl&gt; 4, NA, NA, NA, NA, NA, 4, 5, 5, 5, NA, NA, NA, 1, 3, 1, 2…\n$ ST300Q06JA   &lt;dbl&gt; 2, 3, 2, NA, 5, NA, NA, 5, 5, 5, 3, NA, 1, NA, 2, 1, NA, …\n$ ST300Q07JA   &lt;dbl&gt; 4, 3, NA, NA, 5, NA, 3, 4, NA, 5, NA, NA, NA, 4, NA, 5, 4…\n$ ST300Q08JA   &lt;dbl&gt; NA, NA, 3, NA, 5, NA, NA, 5, 5, NA, 3, 5, 1, 4, NA, 1, 2,…\n$ ST300Q09JA   &lt;dbl&gt; NA, 3, NA, 3, 5, 5, 2, NA, NA, NA, NA, NA, 1, 4, NA, 5, N…\n$ ST300Q10JA   &lt;dbl&gt; 4, 5, 1, 3, NA, 5, 1, NA, NA, 5, NA, 5, NA, 4, 2, NA, 1, …\n$ ST327Q01JA   &lt;dbl&gt; 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n$ ST327Q02JA   &lt;dbl&gt; 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n$ ST327Q03JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ ST327Q04JA   &lt;dbl&gt; 2, 1, 3, 3, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n$ ST327Q05JA   &lt;dbl&gt; 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 3, 3, 1, 1, 1, 2, 1, 1, 1, …\n$ ST327Q06JA   &lt;dbl&gt; 1, 1, 3, 3, 2, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n$ ST327Q07JA   &lt;dbl&gt; 3, 3, 3, 3, 3, 3, 1, 1, 3, 3, 3, 1, 1, 1, 1, 1, NA, 3, 3,…\n$ ST327Q08JA   &lt;dbl&gt; 3, 3, 3, 3, 3, 3, 1, 1, 3, 3, 3, 2, 1, 1, 1, 1, NA, 3, 3,…\n$ ST330Q01WA   &lt;dbl&gt; 3, NA, NA, 3, 3, 3, NA, 3, 3, NA, 3, 3, 3, 1, NA, NA, NA,…\n$ ST330Q02WA   &lt;dbl&gt; 2, NA, 1, NA, 3, NA, 3, NA, 3, 3, NA, NA, 1, 1, 2, NA, NA…\n$ ST330Q03WA   &lt;dbl&gt; NA, NA, 3, 3, NA, 3, 3, NA, NA, NA, NA, 1, 3, NA, 3, 1, 3…\n$ ST330Q04WA   &lt;dbl&gt; NA, 1, NA, NA, 3, 3, NA, 2, NA, 1, NA, NA, NA, NA, NA, 3,…\n$ ST330Q05WA   &lt;dbl&gt; NA, 1, NA, NA, NA, NA, 3, NA, NA, NA, NA, 2, NA, 3, 3, NA…\n$ ST330Q06WA   &lt;dbl&gt; NA, 1, NA, NA, 2, NA, 2, NA, 3, 1, 3, 1, NA, NA, 2, 1, NA…\n$ ST330Q07WA   &lt;dbl&gt; 2, NA, 1, 3, NA, NA, 2, 2, 2, 1, NA, NA, NA, NA, NA, NA, …\n$ ST330Q08WA   &lt;dbl&gt; NA, NA, 3, 3, NA, NA, NA, NA, NA, NA, 3, NA, 3, 1, NA, NA…\n$ ST330Q09WA   &lt;dbl&gt; NA, 1, NA, NA, 2, 3, NA, 2, NA, NA, 2, NA, NA, NA, NA, 1,…\n$ ST330Q11WA   &lt;dbl&gt; 2, 1, NA, 3, NA, 3, NA, NA, NA, 1, 2, NA, NA, 3, NA, NA, …\n$ ST330D10WA   &lt;chr&gt; \"7020003\", \"9999999\", \"7020003\", \"9999999\", \"9999999\", \"9…\n$ ST324Q02JA   &lt;dbl&gt; 3, 3, NA, NA, 4, NA, 3, 2, 3, 3, 2, 3, 4, 3, 3, 4, NA, NA…\n$ ST324Q04JA   &lt;dbl&gt; 3, NA, NA, NA, 4, 3, NA, NA, NA, NA, 3, 4, 3, NA, NA, 3, …\n$ ST324Q05JA   &lt;dbl&gt; NA, NA, 2, 2, NA, 4, NA, 2, 3, 1, 2, 4, NA, 3, 4, NA, 3, …\n$ ST324Q07JA   &lt;dbl&gt; 4, NA, 3, NA, 2, NA, 3, NA, NA, 3, NA, 2, NA, NA, 3, 4, 3…\n$ ST324Q10JA   &lt;dbl&gt; NA, 2, 2, 2, NA, 3, NA, 2, 1, 2, NA, NA, NA, 3, 3, NA, 3,…\n$ ST324Q11JA   &lt;dbl&gt; NA, 1, 2, NA, NA, 2, NA, NA, NA, NA, NA, NA, 2, NA, NA, N…\n$ ST324Q12JA   &lt;dbl&gt; 3, NA, 3, 2, NA, NA, 2, NA, 4, NA, NA, 3, NA, 3, NA, NA, …\n$ ST324Q13JA   &lt;dbl&gt; NA, 1, NA, 2, 4, 3, 1, 2, 4, 3, 3, NA, 3, NA, 3, 1, 2, 3,…\n$ ST324Q14JA   &lt;dbl&gt; 2, 3, NA, 2, 2, NA, 2, 3, NA, NA, 3, NA, 2, 3, NA, 2, 2, …\n$ ST347Q01JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ ST347Q02JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ ST348Q01JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ ST348Q02JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ ST348Q03JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ ST348Q04JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ ST348Q05JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ ST348Q06JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ ST348Q07JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ ST348Q08JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ ST349Q01JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ ST350Q01JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ ST351Q01JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ ST351Q02JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ ST351Q03JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ ST351Q04JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ ST351Q05JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ ST351Q06JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ ST351Q07JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ ST351Q08JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ ST352Q01JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ ST352Q02JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ ST352Q03JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ ST352Q04JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ ST352Q05JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ ST352Q06JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ ST352Q07JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ ST352Q08JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ ST353Q01JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ ST353Q02JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ ST353Q03JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ ST353Q04JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ ST353Q05JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ ST353Q06JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ ST353Q07JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ ST353Q08JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ ST354Q01JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ ST354Q02JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ ST354Q03JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ ST354Q04JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ ST354Q05JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ ST354Q06JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ ST354Q07JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ ST354Q08JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ ST354Q09JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ ST354Q10JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ ST355Q01JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ ST355Q02JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ ST355Q03JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ ST355Q04JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ ST355Q05JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ ST355Q06JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ ST355Q07JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ ST355Q08JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ ST356Q01JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ ST331Q01JA   &lt;dbl&gt; 7, 8, 8, 8, 10, 6, 7, 10, 7, 8, 10, 9, 7, 6, 8, 4, 7, 8, …\n$ ST331Q02JA   &lt;dbl&gt; 8, 10, 9, 10, 10, 10, 8, 10, 10, 10, 10, 10, 9, 7, 10, 10…\n$ ST331Q03JA   &lt;dbl&gt; 8, 8, 7, 10, 10, 7, 8, 10, 9, 8, 9, 10, 10, 6, 10, 10, 8,…\n$ FL150Q01TA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ FL150Q02TA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ FL150Q03TA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ FL164Q01HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ FL164Q02HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ FL164Q03HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ FL164Q04HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ FL164Q05HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ FL164Q06HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ FL164Q07HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ FL164Q08HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ FL164Q09HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ FL164Q10HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ FL164Q11HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ FL164Q12HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ FL164Q13HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ FL164Q14HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ FL164Q15HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ FL164Q16HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ FL166Q01HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ FL166Q02HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ FL166Q03HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ FL166Q05HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ FL166Q06HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ FL166Q07HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ FL174Q01JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ FL174Q02JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ FL174Q03JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ FL174Q04JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ FL174Q05JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ FL174Q06JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ FL174Q07JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ FL167Q01HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ FL167Q02HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ FL167Q06JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ FL167Q03HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ FL167Q04HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ FL167Q05HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ FL167Q07JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ FL170Q01JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ FL170Q02JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ FL170Q03JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ FL170Q04JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ FL170Q05JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ FL170Q06JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ FL170Q07JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ FL159Q01HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ FL159Q02HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ FL159Q03HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ FL159Q04HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ FL160Q01HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ FL160Q02HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ FL160Q03HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ FL160Q04HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ FL161Q01HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ FL161Q02HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ FL161Q03HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ FL162Q01HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ FL162Q02HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ FL162Q03HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ FL162Q04HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ FL162Q05HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ FL162Q06HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ FL163Q01HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ FL163Q02HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ FL163Q03HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ FL163Q04HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ FL163Q05HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ FL171Q01JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ FL171Q02JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ FL171Q03JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ FL171Q04JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ FL171Q05JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ FL171Q07JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ FL171Q08JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ FL171Q09JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ FL171Q10JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ FL171Q11JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ FL171Q12JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ FL169Q01HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ FL169Q05JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ FL169Q02HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ FL169Q06JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ FL169Q07JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ FL169Q03HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ FL169Q04HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ FL169Q08JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ FL169Q10JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ FL169Q11JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ FL172Q01JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ FL172Q03JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ FL172Q05JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ FL172Q06JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ IC170Q01JA   &lt;dbl&gt; 4, 4, 1, 2, 5, 3, 5, 3, 4, 4, 5, 2, 1, 5, 4, 4, 4, 1, 3, …\n$ IC170Q02JA   &lt;dbl&gt; 4, 4, 1, 4, 5, 6, 5, 6, 2, 5, 5, 4, 1, 5, 5, 1, 3, 4, 5, …\n$ IC170Q03JA   &lt;dbl&gt; 1, 4, 5, 1, 6, 3, 1, 5, 1, 6, 6, 4, 4, 5, 5, 1, 1, 4, 1, …\n$ IC170Q04JA   &lt;dbl&gt; 4, 4, 5, 1, 5, 3, 5, 5, 1, 4, 5, 4, 5, 5, 5, 4, 1, 4, 5, …\n$ IC170Q05JA   &lt;dbl&gt; 2, 4, 1, 1, 4, 3, 1, 5, 2, 4, 5, 4, 5, 5, 1, 4, 1, 1, 5, …\n$ IC170Q06JA   &lt;dbl&gt; 2, 4, 5, 1, 6, 3, 3, 5, 3, 1, 3, 4, 2, 5, 5, 2, 2, 4, 1, …\n$ IC170Q07JA   &lt;dbl&gt; 4, 4, 5, 1, 5, 3, 3, 5, 5, 4, 5, 4, 4, 5, 5, 4, 5, 3, 3, …\n$ IC171Q01JA   &lt;dbl&gt; 4, 2, 4, 1, 4, 5, 5, 5, 4, 5, 5, 4, 3, 5, 2, 5, 1, 4, 5, …\n$ IC171Q02JA   &lt;dbl&gt; 5, 4, 4, 5, 4, 5, 5, 5, 4, 5, 5, 4, 4, 5, 5, 5, 5, 4, 5, …\n$ IC171Q03JA   &lt;dbl&gt; 1, 1, 4, 1, 1, 5, 1, 5, 4, 1, 6, 4, 4, 5, 5, 6, 1, 4, 1, …\n$ IC171Q04JA   &lt;dbl&gt; 5, 4, 4, 5, 4, 5, 5, 5, 4, 5, 5, 4, 4, 5, 5, 5, 5, 4, 5, …\n$ IC171Q05JA   &lt;dbl&gt; 2, 1, 3, 1, 1, 1, 4, 5, 3, 1, 4, 4, 2, 5, 5, 1, 1, 4, 3, …\n$ IC171Q06JA   &lt;dbl&gt; 4, 1, 5, 1, 1, 5, 5, 5, 4, 5, 4, 4, 1, 5, 2, 5, 1, 4, 3, …\n$ IC172Q01JA   &lt;dbl&gt; 3, 4, 4, 4, 4, 4, 3, 3, 4, 3, 3, 4, 3, 3, 4, 4, 3, 3, 3, …\n$ IC172Q02JA   &lt;dbl&gt; 3, 4, 4, 4, 4, 4, 3, 3, 4, 3, 3, 4, 3, 3, 4, 4, 3, 3, 2, …\n$ IC172Q03JA   &lt;dbl&gt; 3, 4, 3, 4, 3, 4, 1, 3, 3, 2, 4, 2, 3, 3, 4, 4, 3, 3, 2, …\n$ IC172Q04JA   &lt;dbl&gt; 3, 4, 3, 4, 3, 4, 3, 3, 4, 3, 3, 3, 3, 3, 4, 4, 3, 3, 2, …\n$ IC172Q05JA   &lt;dbl&gt; 3, 4, 3, 4, 4, 4, 3, 3, 4, 3, 3, 4, 3, 3, 4, 4, 3, 3, 3, …\n$ IC172Q06JA   &lt;dbl&gt; 3, 4, 4, 4, 4, 4, 2, 3, 4, 3, 3, 4, 4, 3, 4, 4, 3, 3, 2, …\n$ IC172Q07JA   &lt;dbl&gt; 3, 4, 3, 4, 4, 3, 3, 3, 4, 3, 3, 4, 3, 3, 4, 4, 3, 3, 3, …\n$ IC172Q08JA   &lt;dbl&gt; 3, 4, 3, 4, 4, 3, 2, 3, 3, 3, 3, 4, 2, 3, 4, 4, 3, 3, 3, …\n$ IC172Q09JA   &lt;dbl&gt; 3, 4, 4, 4, 4, 3, 4, 3, 4, 3, 3, 4, 3, 3, 4, 4, 3, 3, 2, …\n$ IC173Q01JA   &lt;dbl&gt; 3, 4, 4, 1, 5, 5, 3, 4, 5, 4, 3, 2, 3, 4, 5, 3, 5, 3, 2, …\n$ IC173Q02JA   &lt;dbl&gt; 1, 2, 5, 1, 1, 3, 5, 4, 3, 1, 1, 3, 1, 2, 2, 2, 2, 4, 1, …\n$ IC173Q03JA   &lt;dbl&gt; 2, 4, 4, 1, 5, 3, 3, 4, 2, 3, 3, 2, 3, 2, 2, 1, 2, 2, 1, …\n$ IC173Q04JA   &lt;dbl&gt; 6, 6, 6, 1, 6, 6, 6, 4, 6, 6, 6, 6, 6, 6, 6, 1, 6, 6, 6, …\n$ IC174Q01JA   &lt;dbl&gt; 2, 3, 1, 3, 3, 2, 1, 1, 2, 3, NA, 4, 1, 1, 3, 2, 2, 1, 1,…\n$ IC174Q02JA   &lt;dbl&gt; 4, 3, 4, 3, 5, 4, 3, 4, 4, 4, NA, 5, 4, 3, 1, 4, 4, 4, 4,…\n$ IC174Q03JA   &lt;dbl&gt; 3, 3, 3, 3, 5, 1, 1, 4, 3, 4, 2, 4, 1, 3, 4, 4, 2, 4, 4, …\n$ IC174Q04JA   &lt;dbl&gt; 2, 3, 4, 3, 3, 3, 3, 4, 3, 4, 2, 5, 3, 3, 2, 1, 2, 3, 1, …\n$ IC174Q05JA   &lt;dbl&gt; 1, 3, 1, 3, 3, 2, 1, 4, 3, 2, 2, 3, 1, 2, 1, 1, 2, 1, 1, …\n$ IC174Q06JA   &lt;dbl&gt; 1, 3, 1, 3, 5, 2, 1, 1, 3, 1, 3, 3, 1, 2, 1, 2, 2, 1, 1, …\n$ IC174Q07JA   &lt;dbl&gt; 2, 3, 1, 3, 5, 2, 5, 4, 3, 4, 3, 5, 4, 2, 1, 3, 2, 1, 1, …\n$ IC174Q08JA   &lt;dbl&gt; 2, 3, 3, 3, 3, 3, 4, 4, 3, 3, 3, 5, 3, 2, 5, 3, 3, 1, 1, …\n$ IC174Q09JA   &lt;dbl&gt; 2, 3, 3, 3, 3, 3, 3, 1, 3, 4, 3, 4, 1, 3, 1, 4, 3, 1, 1, …\n$ IC174Q10JA   &lt;dbl&gt; 2, 3, 3, 3, 3, 3, 1, 4, 3, 3, 1, 4, 1, 1, 1, 1, 2, 1, 1, …\n$ IC175Q01JA   &lt;dbl&gt; 2, 4, 4, 1, 5, 4, 3, 5, 4, 4, 3, 4, 3, 3, 4, 5, 1, 3, 3, …\n$ IC175Q02JA   &lt;dbl&gt; 2, 3, 2, 2, 5, 5, 3, 5, 4, 4, 3, 4, 1, 3, 1, 5, 1, 1, 3, …\n$ IC175Q03JA   &lt;dbl&gt; 2, 3, 1, 1, 1, 3, 1, 5, 2, 4, 1, 4, 1, 3, 4, 5, 1, 1, 2, …\n$ IC175Q05JA   &lt;dbl&gt; 1, 3, 1, 2, 2, 3, 1, 5, 3, 4, 1, 5, 3, 3, 4, 3, 1, 1, 3, …\n$ IC176Q01JA   &lt;dbl&gt; 3, 2, 5, 1, 5, 3, 3, 5, 3, 5, 3, 4, 1, 3, 4, 4, 3, 4, 3, …\n$ IC176Q02JA   &lt;dbl&gt; 3, 2, 4, 1, 5, 4, 1, 5, 5, 5, 5, 5, 4, 3, 5, 5, 3, 3, 3, …\n$ IC176Q03JA   &lt;dbl&gt; 4, 2, 3, 1, 5, 4, 1, 5, 4, 5, 4, 5, 1, 3, 5, 5, 3, 4, 3, …\n$ IC176Q04JA   &lt;dbl&gt; 4, 3, 5, 2, 5, 4, 3, 5, 5, 5, 5, 5, 5, 3, 5, 5, 3, 5, 4, …\n$ IC176Q05JA   &lt;dbl&gt; 4, 2, 4, 2, 5, 4, 3, 5, 5, 4, 4, 5, 3, 3, 3, 5, 3, 5, 3, …\n$ IC176Q06JA   &lt;dbl&gt; 3, 1, 2, 1, 5, 4, 4, 5, 5, 2, 3, 5, 1, 3, 3, 3, 4, 5, 1, …\n$ IC176Q07JA   &lt;dbl&gt; 4, 2, 4, 1, 5, 4, 5, 5, 5, 4, 5, 5, 4, 3, 5, 3, 4, 5, 5, …\n$ IC176Q08JA   &lt;dbl&gt; 4, 3, 1, 3, 5, 3, 4, 5, 4, 5, 5, 4, 1, 3, 5, 4, 4, 5, 3, …\n$ IC184Q01JA   &lt;dbl&gt; 3, 3, 1, 5, 1, 4, 1, 1, 3, 4, 4, 5, 1, 5, 1, 4, 3, 5, 1, …\n$ IC184Q02JA   &lt;dbl&gt; 4, 3, 3, 4, 1, 4, 1, 1, 3, 4, 4, 5, 1, 5, 4, 4, 3, 4, 3, …\n$ IC184Q03JA   &lt;dbl&gt; 1, 3, 3, 1, 1, 3, 3, 1, 3, 6, 6, 4, 3, 5, 1, 1, 3, 3, 1, …\n$ IC184Q04JA   &lt;dbl&gt; 1, 3, 1, 1, 1, 3, 6, 1, 2, 6, 6, 2, 6, 1, 1, 1, 3, 6, 1, …\n$ IC177Q01JA   &lt;dbl&gt; 3, 2, 4, 2, 4, 4, 4, 3, 1, 5, 3, 2, 1, 4, 4, 3, 4, 3, 1, …\n$ IC177Q02JA   &lt;dbl&gt; 2, 3, 2, 2, 6, 4, 1, 3, 2, 5, 3, 3, 2, 2, 4, 3, 3, 5, 3, …\n$ IC177Q03JA   &lt;dbl&gt; 3, 3, 3, 2, 4, 4, 3, 3, 2, 5, 3, 3, 4, 4, 5, 3, 2, 4, 3, …\n$ IC177Q04JA   &lt;dbl&gt; 2, 3, 2, 2, 4, 4, 3, 1, 2, 3, 2, 2, 1, 3, 5, 2, 1, 3, 2, …\n$ IC177Q05JA   &lt;dbl&gt; 2, 3, 2, 2, 4, 4, 2, 1, 2, 2, 2, 4, 2, 2, 5, 1, 4, 4, 1, …\n$ IC177Q06JA   &lt;dbl&gt; 2, 3, 2, 2, 4, 1, 2, 1, 2, 4, 2, 2, 1, 3, 5, 3, 1, 3, 2, …\n$ IC177Q07JA   &lt;dbl&gt; 1, 3, 1, 2, 5, 1, 1, 3, 1, 3, 1, 2, 1, 1, 5, 2, 1, 1, 1, …\n$ IC178Q01JA   &lt;dbl&gt; 3, 3, 5, 1, 4, 4, 6, 3, 1, 6, 3, 3, 1, 5, 5, 4, 4, 4, 1, …\n$ IC178Q02JA   &lt;dbl&gt; 2, 3, 2, 1, 6, 4, 1, 3, 2, 6, 3, 4, 3, 2, 5, 3, 4, 5, 3, …\n$ IC178Q03JA   &lt;dbl&gt; 3, 3, 2, 1, 4, 4, 2, 3, 2, 6, 3, 4, 5, 5, 5, 3, 1, 4, 2, …\n$ IC178Q04JA   &lt;dbl&gt; 2, 3, 2, 1, 4, 4, 2, 1, 2, 2, 2, 3, 1, 2, 5, 2, 1, 3, 2, …\n$ IC178Q05JA   &lt;dbl&gt; 2, 3, 1, 1, 4, 4, 1, 1, 2, 5, 1, 4, 2, 2, 5, 2, 1, 4, 1, …\n$ IC178Q06JA   &lt;dbl&gt; 3, 3, 2, 1, 4, 1, 1, 1, 2, 3, 3, 4, 1, 2, 5, 2, 1, 3, 2, …\n$ IC178Q07JA   &lt;dbl&gt; 1, 3, 1, 1, 1, 1, 1, 3, 1, 2, 1, 2, 1, 1, 5, 2, 1, 1, 1, …\n$ IC179Q01JA   &lt;dbl&gt; 1, 3, 2, 1, 2, 4, 2, 2, 3, 1, 2, 1, 1, 1, 2, 1, 2, 3, 3, …\n$ IC179Q02JA   &lt;dbl&gt; 1, 2, 2, 1, 2, 2, 2, 2, 1, 1, 2, 1, 1, 1, 1, 1, 2, 3, 1, …\n$ IC179Q03JA   &lt;dbl&gt; 3, 3, 3, 4, 4, 4, 4, 3, 3, 4, 3, 4, 3, 4, 3, 4, 2, 2, 3, …\n$ IC179Q04JA   &lt;dbl&gt; 2, 3, 2, 1, 2, 4, 2, 2, 4, 1, 2, 4, 1, 3, 3, 3, 2, 2, 2, …\n$ IC179Q05JA   &lt;dbl&gt; 2, 3, 2, 1, 4, 4, 2, 2, 4, 1, 3, 4, 1, 3, 4, 3, 2, 2, 3, …\n$ IC179Q06JA   &lt;dbl&gt; 1, 3, 3, 2, 3, 4, 3, 3, 4, 1, 3, 1, 1, 1, 2, 1, 2, 2, 3, …\n$ IC180Q01JA   &lt;dbl&gt; 3, 2, 2, 2, 3, 4, 2, 2, 2, 3, 2, 2, 2, 3, 2, 1, 3, 2, 2, …\n$ IC180Q02JA   &lt;dbl&gt; 3, 3, 3, 2, 3, 2, 3, 3, 2, 3, 3, 4, 3, 3, 4, 4, 2, 3, 3, …\n$ IC180Q03JA   &lt;dbl&gt; 3, 3, 3, 2, 3, 4, 4, 3, 3, 3, 3, 4, 3, 3, 4, 4, 2, 3, 3, …\n$ IC180Q04JA   &lt;dbl&gt; 2, 2, 2, 2, 3, 1, 2, 3, 3, 3, 3, 4, 1, 1, 1, 2, 2, 3, 2, …\n$ IC180Q05JA   &lt;dbl&gt; 3, 2, 3, 2, 3, 3, 3, 3, 3, 3, 3, 4, 1, 1, NA, 2, 2, 3, 3,…\n$ IC180Q06JA   &lt;dbl&gt; 3, 2, 3, 2, 3, 3, 3, 3, 3, 3, 3, 4, 1, 1, 3, 2, 2, 3, 2, …\n$ IC180Q07JA   &lt;dbl&gt; 3, 2, 2, 2, 2, 4, 1, 3, 3, 3, 2, 2, 3, 2, 1, 4, 2, 3, 2, …\n$ IC180Q08JA   &lt;dbl&gt; 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 2, 1, 2, …\n$ IC181Q01JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ IC181Q02JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ IC181Q03JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ IC181Q04JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ IC182Q01JA   &lt;dbl&gt; 3, 3, 2, 4, 2, 2, 3, 2, 2, 3, 3, 4, 3, 3, 3, 4, 2, 3, 2, …\n$ IC182Q02JA   &lt;dbl&gt; 3, 2, 3, 4, 2, 2, 4, 2, 2, 2, 3, 3, 3, 2, 3, 3, 2, 3, 3, …\n$ IC182Q03JA   &lt;dbl&gt; 3, 3, 3, 4, 3, 3, 4, 3, 3, 3, 3, 4, 3, 3, 4, 4, 2, 3, 3, …\n$ IC183Q01JA   &lt;dbl&gt; 4, 4, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, …\n$ IC183Q02JA   &lt;dbl&gt; 4, 4, 5, 3, 4, 4, 3, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 3, 4, …\n$ IC183Q03JA   &lt;dbl&gt; 4, 4, 2, 3, 4, 4, 3, 4, 4, 3, 3, 4, 3, 4, 4, 4, 4, 4, 4, …\n$ IC183Q04JA   &lt;dbl&gt; 4, 4, 4, 3, 4, 4, 2, 4, 4, 4, 4, 4, 3, 4, 2, 4, 4, 3, 4, …\n$ IC183Q05JA   &lt;dbl&gt; 4, 4, 3, 3, 4, 3, 3, 1, 4, 4, 3, 4, 3, 4, 3, 4, 3, 3, 4, …\n$ IC183Q07JA   &lt;dbl&gt; 4, 4, 3, 3, 4, 4, 3, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, …\n$ IC183Q08JA   &lt;dbl&gt; 4, 4, 2, 3, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 2, 4, 4, 3, 4, …\n$ IC183Q09JA   &lt;dbl&gt; 4, 4, 1, 3, 4, 4, 2, 4, 4, 4, 3, 4, 2, 4, 3, 4, 4, 3, 4, …\n$ IC183Q10JA   &lt;dbl&gt; 4, 2, 1, 3, 4, 4, 2, 4, 3, 2, 3, 4, 1, 4, 2, 4, 1, 4, 2, …\n$ IC183Q12JA   &lt;dbl&gt; 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, …\n$ IC183Q13JA   &lt;dbl&gt; 4, 4, 2, 3, 4, 4, 4, 1, 4, 3, 3, 4, 2, 1, 4, 4, 1, 3, 4, …\n$ IC183Q14JA   &lt;dbl&gt; 2, 4, 1, 3, 5, 2, 2, 1, 2, 5, 2, 2, 1, 1, 1, 2, 1, 2, 1, …\n$ IC183Q15JA   &lt;dbl&gt; 2, 4, 1, 3, 5, 3, 1, 4, 2, 5, 3, 3, 1, 1, 1, 4, 1, 2, 1, …\n$ IC183Q16JA   &lt;dbl&gt; 3, 4, 3, 3, 5, 3, 2, 4, 3, 5, 3, 3, 1, 1, 1, 4, 1, 2, 1, …\n$ WB150Q01HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ WB151Q01HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ WB152Q01HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ WB153Q01HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ WB153Q02HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ WB153Q03HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ WB153Q04HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ WB153Q05HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ WB154Q01HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ WB154Q02HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ WB154Q03HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ WB154Q04HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ WB154Q05HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ WB154Q06HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ WB154Q07HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ WB154Q08HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ WB154Q09HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ WB155Q01HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ WB155Q02HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ WB155Q03HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ WB155Q04HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ WB155Q05HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ WB155Q06HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ WB155Q07HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ WB155Q08HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ WB155Q09HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ WB155Q10HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ WB156Q01HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ WB158Q01HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ WB160Q01HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ WB161Q01HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ WB162Q01HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ WB162Q02HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ WB162Q03HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ WB162Q04HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ WB162Q05HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ WB162Q06HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ WB162Q07HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ WB162Q08HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ WB162Q09HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ WB163Q01HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ WB163Q02HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ WB163Q03HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ WB163Q04HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ WB163Q05HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ WB163Q06HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ WB163Q07HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ WB163Q08HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ WB164Q01HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ WB165Q01HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ WB166Q01HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ WB166Q02HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ WB166Q03HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ WB166Q04HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ WB167Q01HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ WB168Q01HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ WB168Q02HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ WB168Q03HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ WB168Q04HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ WB171Q01HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ WB171Q02HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ WB171Q03HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ WB171Q04HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ WB172Q01HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ WB173Q01HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ WB173Q02HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ WB173Q03HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ WB173Q04HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ WB176Q01HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ WB177Q01HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ WB177Q02HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ WB177Q03HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ WB177Q04HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ WB032Q01NA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ WB032Q02NA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ WB031Q01NA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ WB178Q01HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ WB178Q02HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ WB178Q03HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ WB178Q04HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ WB178Q05HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ WB178Q06HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ WB178Q07HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA001Q01TA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA001Q02TA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA001Q03TA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA003Q01TA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA003Q02TA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA003Q03TA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA003Q05IA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA003Q18WA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA003Q19WA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA003Q20WA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA003Q11JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA003Q12JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA003Q13JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA003Q14JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA003Q15JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA003Q16JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA003Q17JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA196Q01WA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA196Q02WA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA196Q03WA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA196Q04WA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA197Q01WA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA197Q02WA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA197Q03WA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA197Q04WA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA197Q05WA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA008Q01TA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA008Q02TA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA008Q03TA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA008Q04TA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA008Q05TA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA008Q06NA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA008Q07NA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA008Q08NA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA008Q09NA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA008Q10NA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA009Q01NA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA009Q02NA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA009Q03NA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA009Q04NA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA009Q05NA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA009Q06NA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA009Q07NA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA009Q08NA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA009Q09NA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA009Q10NA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA009Q11NA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA007Q01TA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA007Q02TA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA007Q03TA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA007Q04TA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA007Q05TA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA007Q06TA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA007Q07TA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA007Q09NA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA007Q11NA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA007Q12NA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA007Q13NA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA007Q14NA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA007Q15NA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA005Q01TA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA006Q01TA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA006Q02TA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA006Q03TA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA006Q04TA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA006Q05TA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA006Q06TA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA006Q07TA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA006Q08TA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA006Q09TA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA006Q10TA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA006Q11TA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA006Q12HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA006Q13HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA006Q14HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA166Q01HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA167Q02HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA167Q03HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA167Q04HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA167Q05HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA183Q01JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA183Q02JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA183Q03JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA183Q04JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA183Q05JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA183Q06JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA183Q07JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA183Q08JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA018Q01NA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA018Q02NA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA018Q03NA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA177Q01HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA177Q02HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA177Q03HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA177Q04HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA177Q05HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA177Q06HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA177Q07HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA177Q08HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA180Q01HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA182Q01HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA175Q01HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA175Q02HA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA175Q03JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA175Q04JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA185Q01JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA185Q02JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA185Q03JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA185Q04JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA185Q05JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA185Q07JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA185Q08JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA185Q09JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA185Q10JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA186Q01JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA186Q02JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA186Q03JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA186Q04JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA186Q05JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA186Q06JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA186Q07JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA186Q08JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA187Q04JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA187Q06JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA188Q01JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA188Q02JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA188Q03JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA188Q04JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA188Q05JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA188Q06JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA188Q08JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA188Q09JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA188Q10JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA189Q01JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA189Q02JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA189Q03JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA189Q04JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA189Q05JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA189Q06JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA189Q09JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA189Q10JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA194Q01JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA195Q01JA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA041Q01TA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PA042Q01TA   &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ EFFORT1      &lt;dbl&gt; 7, 8, 7, NA, 10, NA, 7, 10, 7, 7, 10, 9, 7, 6, 8, NA, 6, …\n$ EFFORT2      &lt;dbl&gt; 9, 8, 8, NA, 10, NA, 8, 10, 10, 10, 10, 10, 10, 7, 10, NA…\n$ OCOD1        &lt;chr&gt; \"9701\", \"31\", \"9701\", \"41\", \"23\", \"9701\", \"11\", \"23\", \"1\"…\n$ OCOD2        &lt;chr&gt; \"83\", \"21\", \"9704\", \"9705\", \"83\", \"34\", \"31\", \"21\", \"14\",…\n$ OCOD3        &lt;chr&gt; \"2634\", \"9705\", \"9704\", \"2411\", \"21\", \"22\", \"2512\", \"2310…\n$ PROGN        &lt;chr&gt; \"07020002\", \"07020002\", \"07020002\", \"07020002\", \"07020002…\n$ AGE          &lt;dbl&gt; 15.50, 15.83, 15.75, 16.17, 15.58, 15.58, 16.08, 16.00, 1…\n$ GRADE        &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ ISCEDP       &lt;dbl&gt; 344, 344, 344, 344, 344, 344, 344, 344, 344, 344, 344, 34…\n$ IMMIG        &lt;dbl&gt; 1, 1, 1, 1, 1, 3, 1, 3, 1, 1, 1, 1, 1, 3, 1, 2, 3, 3, 1, …\n$ COBN_S       &lt;chr&gt; \"070200\", \"070200\", \"070200\", \"070200\", \"070200\", \"970200…\n$ COBN_M       &lt;chr&gt; \"070200\", \"070200\", \"970200\", \"070200\", \"070200\", \"970200…\n$ COBN_F       &lt;chr&gt; \"070200\", \"070200\", \"070200\", \"070200\", \"070200\", \"970200…\n$ LANGN        &lt;dbl&gt; 998, 998, 998, 998, 998, 998, 998, 998, 998, 998, 998, 99…\n$ REPEAT       &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ MISSSC       &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, …\n$ SKIPPING     &lt;dbl&gt; 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, …\n$ TARDYSD      &lt;dbl&gt; 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ EXERPRAC     &lt;dbl&gt; 1, 4, 2, 5, 9, 1, 2, 0, 3, 5, 1, 2, 5, 2, 4, 0, 2, 3, 2, …\n$ STUDYHMW     &lt;dbl&gt; 4, 7, 3, 5, 7, 10, 0, 10, 5, 3, 5, 5, 10, 0, 8, 5, 5, 5, …\n$ WORKPAY      &lt;dbl&gt; 0, 0, 0, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ WORKHOME     &lt;dbl&gt; 10, 2, 0, 10, 5, 5, 7, 0, 0, 4, 2, 2, 10, 0, 10, 0, 5, 5,…\n$ EXPECEDU     &lt;dbl&gt; 7, 7, 6, NA, 6, 7, 9, 9, 7, 6, 7, 8, 9, 9, 9, 9, 7, 7, 7,…\n$ MATHPREF     &lt;dbl&gt; 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, …\n$ MATHEASE     &lt;dbl&gt; 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, …\n$ MATHMOT      &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ DURECEC      &lt;dbl&gt; 3, 2, NA, 3, NA, 4, 3, NA, NA, 3, NA, 5, NA, 5, 3, 2, NA,…\n$ BSMJ         &lt;dbl&gt; 85.85, NA, NA, 76.65, 79.49, 76.98, 74.66, 85.41, 24.79, …\n$ SISCO        &lt;dbl&gt; 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n$ RELATST      &lt;dbl&gt; -0.2606, 1.2437, 0.7190, -0.2194, 1.0726, 1.1296, -1.0841…\n$ BELONG       &lt;dbl&gt; 0.2442, -0.0437, -0.6137, -1.1147, 2.1143, 0.5159, -0.718…\n$ BULLIED      &lt;dbl&gt; -1.2280, -0.2016, -1.2280, -1.2280, -1.2280, -1.2280, 1.0…\n$ FEELSAFE     &lt;dbl&gt; -0.7560, 1.1246, 0.4417, -0.7560, 1.1246, 0.1413, 0.0936,…\n$ SCHRISK      &lt;dbl&gt; -0.6386, 0.1810, -0.6386, -0.6386, -0.6386, 0.1810, 0.181…\n$ PERSEVAGR    &lt;dbl&gt; 0.4369, 0.4540, -0.4017, 0.5617, -0.5954, -0.1554, 0.4375…\n$ CURIOAGR     &lt;dbl&gt; 2.7951, 0.3058, -0.6563, 0.1778, 0.3406, 0.3247, 0.0134, …\n$ COOPAGR      &lt;dbl&gt; -0.0319, 0.1187, -0.6986, 0.0849, 0.8806, 4.8203, -0.7118…\n$ EMPATAGR     &lt;dbl&gt; 1.3979, 0.1290, -0.2087, -0.1344, -0.5172, -0.5881, -1.26…\n$ ASSERAGR     &lt;dbl&gt; -0.2970, -0.1734, -0.4816, -0.1538, 0.2470, -0.8113, -0.1…\n$ STRESAGR     &lt;dbl&gt; 0.9777, -0.7402, -0.2053, 0.2201, -0.9940, 0.2183, 0.4922…\n$ EMOCOAGR     &lt;dbl&gt; 1.2321, -0.5609, 0.5777, -0.0563, -0.8597, NA, 0.8646, 1.…\n$ GROSAGR      &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ INFOSEEK     &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ FAMSUP       &lt;dbl&gt; -0.3780, -0.5969, -1.0537, -0.8521, 1.7459, 1.7327, -0.88…\n$ DISCLIM      &lt;dbl&gt; 0.3884, 1.1687, 0.2002, -0.1219, 0.1166, -0.1006, -0.8709…\n$ TEACHSUP     &lt;dbl&gt; -0.5635, 0.1475, -0.5635, -0.1002, 1.5558, 0.1475, -0.332…\n$ COGACRCO     &lt;dbl&gt; -0.4092, -0.7102, -0.6541, -0.0820, 0.5051, 0.2635, 0.142…\n$ COGACMCO     &lt;dbl&gt; 0.1666, 0.0024, -0.5604, 0.1868, 2.3426, 0.7819, -0.5560,…\n$ EXPOFA       &lt;dbl&gt; 0.3356, -1.2147, 0.6908, -0.2194, 0.5478, 0.5515, -0.1287…\n$ EXPO21ST     &lt;dbl&gt; -0.7746, -0.5240, 0.0949, 0.4959, 0.4121, 0.4936, 0.2869,…\n$ MATHEFF      &lt;dbl&gt; 0.1429, -0.2874, 0.2226, -0.9344, -0.9322, 0.2637, 1.2000…\n$ MATHEF21     &lt;dbl&gt; 0.4317, 0.7644, -0.4779, -0.5515, -0.5730, -0.2489, 1.401…\n$ FAMCON       &lt;dbl&gt; 1.3180, 4.7588, 0.4736, 0.0594, 0.8973, 2.2322, 3.6192, 4…\n$ ANXMAT       &lt;dbl&gt; 0.3729, 0.6647, 0.0510, 0.6387, 2.5026, -0.7358, -0.9755,…\n$ MATHPERS     &lt;dbl&gt; -0.1305, 0.6178, -0.3993, 1.8158, 1.1353, 0.9918, -1.5183…\n$ CREATEFF     &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ CREATSCH     &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ CREATFAM     &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ CREATAS      &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ CREATOOS     &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ CREATOP      &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ OPENART      &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ IMAGINE      &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ SCHSUST      &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ LEARRES      &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PROBSELF     &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ FAMSUPSL     &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ FEELLAH      &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ SDLEFF       &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ MISCED       &lt;dbl&gt; 8, 7, 4, 6, 7, 7, 6, 9, 8, 8, 4, 9, 10, 6, 4, 9, 8, 8, 6,…\n$ FISCED       &lt;dbl&gt; 7, 7, 4, 6, 7, 9, 2, 8, 8, 7, 4, 9, 10, 9, 6, 4, 9, 8, 6,…\n$ HISCED       &lt;dbl&gt; 8, 7, 4, 6, 7, 9, 6, 9, 8, 8, 4, 9, 10, 9, 6, 9, 9, 8, 6,…\n$ PAREDINT     &lt;dbl&gt; 16.0, 14.5, 12.0, 12.0, 14.5, 16.0, 12.0, 16.0, 16.0, 16.…\n$ BMMJ1        &lt;dbl&gt; 17.00, 37.83, 17.00, 43.33, 75.54, 17.00, 70.34, 75.54, 6…\n$ BFMJ2        &lt;dbl&gt; 30.34, 77.10, NA, NA, 30.34, 57.64, 40.54, 80.78, 43.85, …\n$ HISEI        &lt;dbl&gt; 30.34, 77.10, 17.00, 43.33, 75.54, 57.64, 70.34, 80.78, 6…\n$ ICTRES       &lt;dbl&gt; 0.1940, 0.6249, -0.3987, -0.9028, 0.2514, -0.4733, 0.9904…\n$ HOMEPOS      &lt;dbl&gt; 0.7524, 0.7842, 0.0666, -0.9300, -0.8949, -0.5988, 0.0975…\n$ ESCS         &lt;dbl&gt; 0.1836, 0.8261, -1.0357, -0.9606, 0.0856, 0.1268, -0.0154…\n$ FCFMLRTY     &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ FLSCHOOL     &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ FLMULTSB     &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ FLFAMILY     &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ ACCESSFP     &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ FLCONFIN     &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ FLCONICT     &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ ACCESSFA     &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ ATTCONFM     &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ FRINFLFM     &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ ICTSCH       &lt;dbl&gt; 0.4062, 0.4062, 0.4062, 0.4062, -1.6647, -0.8411, 0.4062,…\n$ ICTAVSCH     &lt;dbl&gt; 7, 7, 7, 7, 5, 6, 7, 6, 7, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, …\n$ ICTHOME      &lt;dbl&gt; 0.3346, 0.3346, 0.3346, 0.3346, 0.3346, 0.3346, 0.3346, 0…\n$ ICTAVHOM     &lt;dbl&gt; 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 5, 6, 6, 6, 6, 5, 6, 6, 6, …\n$ ICTQUAL      &lt;dbl&gt; 0.3623, 2.8889, 1.2313, 2.8889, 1.8870, 1.6615, -0.2086, …\n$ ICTSUBJ      &lt;dbl&gt; -0.1315, 0.5048, 0.9454, -2.0101, 0.6775, 0.6012, 0.5918,…\n$ ICTENQ       &lt;dbl&gt; -0.3767, 0.3109, -0.1658, 0.3109, 1.0316, -0.0477, -0.021…\n$ ICTFEED      &lt;dbl&gt; -0.4038, 0.4297, -0.4292, -0.6744, 0.2776, 0.9257, -0.354…\n$ ICTOUT       &lt;dbl&gt; 0.2260, -0.8080, 0.1088, -1.2894, 2.9804, 0.3464, -0.4834…\n$ ICTWKDY      &lt;dbl&gt; -0.4469, 0.4182, -0.3710, -0.5032, 1.3145, 0.4565, -0.250…\n$ ICTWKEND     &lt;dbl&gt; -0.3452, 0.3311, -0.7926, -3.5000, 0.8948, 0.4976, -1.085…\n$ ICTREG       &lt;dbl&gt; -0.1855, 0.9444, 0.2941, -0.6148, 0.8255, 1.9301, 0.3353,…\n$ ICTINFO      &lt;dbl&gt; 0.2929, -0.4797, 0.0811, -0.8360, 0.4191, 0.2147, 0.1939,…\n$ ICTDISTR     &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ ICTEFFIC     &lt;dbl&gt; 0.5764, 0.7781, -0.8446, -0.5172, 1.0613, 0.3941, -0.5344…\n$ STUBMI       &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ BODYIMA      &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ SOCONPA      &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ LIFESAT      &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PSYCHSYM     &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ SOCCON       &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ EXPWB        &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ CURSUPP      &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PQMIMP       &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PQMCAR       &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PARINVOL     &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PQSCHOOL     &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PASCHPOL     &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ ATTIMMP      &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ PAREXPT      &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ CREATHME     &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ CREATACT     &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ CREATOPN     &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ CREATOR      &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ W_FSTUWT     &lt;dbl&gt; 5.35943, 6.74318, 6.77500, 5.43200, 5.82353, 5.69931, 4.9…\n$ W_FSTURWT1   &lt;dbl&gt; 8.20073, 9.88533, 10.16250, 7.98824, 9.00000, 2.68850, 2.…\n$ W_FSTURWT2   &lt;dbl&gt; 2.63139, 10.36607, 10.16250, 2.66275, 8.48571, 8.76685, 2…\n$ W_FSTURWT3   &lt;dbl&gt; 8.03388, 10.33466, 10.16250, 8.31429, 2.82857, 8.34850, 2…\n$ W_FSTURWT4   &lt;dbl&gt; 8.18690, 3.44489, 3.38750, 7.98824, 9.00000, 8.40156, 7.3…\n$ W_FSTURWT5   &lt;dbl&gt; 7.89416, 3.29511, 3.38750, 2.56226, 8.48571, 2.89878, 7.5…\n$ W_FSTURWT6   &lt;dbl&gt; 8.04452, 3.44489, 3.38750, 2.56226, 8.48571, 9.60179, 2.4…\n$ W_FSTURWT7   &lt;dbl&gt; 2.67796, 3.29830, 3.38750, 2.66275, 9.00000, 2.92228, 7.5…\n$ W_FSTURWT8   &lt;dbl&gt; 2.72897, 10.36607, 10.16250, 2.66275, 3.00000, 8.76685, 7…\n$ W_FSTURWT9   &lt;dbl&gt; 7.74437, 3.29511, 3.38750, 7.98824, 2.82857, 3.05511, 2.4…\n$ W_FSTURWT10  &lt;dbl&gt; 2.67796, 9.89489, 10.16250, 2.66275, 8.48571, 2.89878, 2.…\n$ W_FSTURWT11  &lt;dbl&gt; 2.73358, 3.29830, 3.38750, 8.31429, 2.82857, 3.02482, 7.3…\n$ W_FSTURWT12  &lt;dbl&gt; 8.18690, 9.88533, 10.16250, 2.66275, 2.82857, 2.80052, 7.…\n$ W_FSTURWT13  &lt;dbl&gt; 8.20073, 10.33466, 10.16250, 7.68679, 9.00000, 8.02740, 7…\n$ W_FSTURWT14  &lt;dbl&gt; 2.58146, 10.36607, 10.16250, 7.68679, 8.48571, 8.34850, 7…\n$ W_FSTURWT15  &lt;dbl&gt; 2.68151, 9.89489, 10.16250, 7.98824, 3.00000, 2.58510, 2.…\n$ W_FSTURWT16  &lt;dbl&gt; 2.63139, 3.45536, 3.38750, 8.31429, 2.82857, 8.40156, 7.5…\n$ W_FSTURWT17  &lt;dbl&gt; 2.73358, 3.45536, 3.38750, 2.66275, 3.00000, 8.69635, 2.4…\n$ W_FSTURWT18  &lt;dbl&gt; 7.89416, 9.88533, 10.16250, 2.77143, 3.00000, 2.89878, 7.…\n$ W_FSTURWT19  &lt;dbl&gt; 2.72897, 3.29830, 3.38750, 7.68679, 9.00000, 2.78283, 2.5…\n$ W_FSTURWT20  &lt;dbl&gt; 8.03388, 3.44489, 3.38750, 2.77143, 3.00000, 8.34850, 2.5…\n$ W_FSTURWT21  &lt;dbl&gt; 7.89416, 9.88533, 3.38750, 2.66275, 9.00000, 2.92228, 2.4…\n$ W_FSTURWT22  &lt;dbl&gt; 2.63139, 10.36607, 3.38750, 7.98824, 8.48571, 8.06550, 2.…\n$ W_FSTURWT23  &lt;dbl&gt; 8.03388, 10.33466, 3.38750, 2.77143, 2.82857, 7.73009, 2.…\n$ W_FSTURWT24  &lt;dbl&gt; 7.88647, 3.44489, 10.16250, 2.66275, 9.00000, 9.16534, 7.…\n$ W_FSTURWT25  &lt;dbl&gt; 7.89416, 3.29511, 10.16250, 7.68679, 8.48571, 2.89878, 7.…\n$ W_FSTURWT26  &lt;dbl&gt; 8.36312, 3.44489, 10.16250, 7.68679, 8.48571, 8.76685, 2.…\n$ W_FSTURWT27  &lt;dbl&gt; 2.67796, 3.29830, 10.16250, 7.98824, 9.00000, 2.92228, 7.…\n$ W_FSTURWT28  &lt;dbl&gt; 2.62882, 10.36607, 3.38750, 7.98824, 3.00000, 8.76685, 7.…\n$ W_FSTURWT29  &lt;dbl&gt; 8.03388, 3.29511, 10.16250, 2.66275, 2.82857, 2.80052, 2.…\n$ W_FSTURWT30  &lt;dbl&gt; 2.78196, 9.89489, 3.38750, 7.98824, 8.48571, 2.89878, 2.4…\n$ W_FSTURWT31  &lt;dbl&gt; 2.73358, 3.29830, 10.16250, 2.77143, 2.82857, 2.78283, 7.…\n$ W_FSTURWT32  &lt;dbl&gt; 8.18690, 9.88533, 3.38750, 7.98824, 2.82857, 2.80052, 7.5…\n$ W_FSTURWT33  &lt;dbl&gt; 8.20073, 10.33466, 3.38750, 2.56226, 9.00000, 8.02740, 7.…\n$ W_FSTURWT34  &lt;dbl&gt; 2.67796, 10.36607, 3.38750, 2.56226, 8.48571, 8.34850, 7.…\n$ W_FSTURWT35  &lt;dbl&gt; 2.68151, 9.89489, 3.38750, 2.66275, 3.00000, 2.80052, 2.5…\n$ W_FSTURWT36  &lt;dbl&gt; 2.73358, 3.45536, 10.16250, 2.77143, 2.82857, 8.40156, 7.…\n$ W_FSTURWT37  &lt;dbl&gt; 2.63139, 3.45536, 10.16250, 7.98824, 3.00000, 9.48693, 2.…\n$ W_FSTURWT38  &lt;dbl&gt; 7.89416, 9.88533, 3.38750, 8.31429, 3.00000, 2.89878, 7.3…\n$ W_FSTURWT39  &lt;dbl&gt; 2.62882, 3.29830, 10.16250, 2.56226, 9.00000, 2.78283, 2.…\n$ W_FSTURWT40  &lt;dbl&gt; 8.03388, 3.44489, 10.16250, 8.31429, 3.00000, 9.07446, 2.…\n$ W_FSTURWT41  &lt;dbl&gt; 8.20073, 9.88533, 3.38750, 2.66275, 2.82857, 9.07446, 7.5…\n$ W_FSTURWT42  &lt;dbl&gt; 2.63139, 10.36607, 3.38750, 7.98824, 3.00000, 2.78283, 7.…\n$ W_FSTURWT43  &lt;dbl&gt; 8.03388, 10.33466, 3.38750, 2.77143, 9.00000, 2.92228, 7.…\n$ W_FSTURWT44  &lt;dbl&gt; 8.18690, 3.44489, 10.16250, 2.66275, 2.82857, 2.89878, 2.…\n$ W_FSTURWT45  &lt;dbl&gt; 7.89416, 3.29511, 10.16250, 7.68679, 3.00000, 8.40156, 2.…\n$ W_FSTURWT46  &lt;dbl&gt; 8.04452, 3.44489, 10.16250, 7.68679, 3.00000, 2.57670, 7.…\n$ W_FSTURWT47  &lt;dbl&gt; 2.67796, 3.29830, 10.16250, 7.98824, 2.82857, 8.34850, 2.…\n$ W_FSTURWT48  &lt;dbl&gt; 2.72897, 10.36607, 3.38750, 7.98824, 8.48571, 2.78283, 2.…\n$ W_FSTURWT49  &lt;dbl&gt; 7.74437, 3.29511, 10.16250, 2.66275, 9.00000, 8.02740, 7.…\n$ W_FSTURWT50  &lt;dbl&gt; 2.67796, 9.89489, 3.38750, 7.98824, 3.00000, 8.40156, 7.5…\n$ W_FSTURWT51  &lt;dbl&gt; 2.73358, 3.29830, 10.16250, 2.77143, 9.00000, 8.06550, 2.…\n$ W_FSTURWT52  &lt;dbl&gt; 8.18690, 9.88533, 3.38750, 7.98824, 9.00000, 8.69635, 2.4…\n$ W_FSTURWT53  &lt;dbl&gt; 8.20073, 10.33466, 3.38750, 2.56226, 2.82857, 3.05511, 2.…\n$ W_FSTURWT54  &lt;dbl&gt; 2.58146, 10.36607, 3.38750, 2.56226, 3.00000, 2.92228, 2.…\n$ W_FSTURWT55  &lt;dbl&gt; 2.68151, 9.89489, 3.38750, 2.66275, 8.48571, 9.48693, 7.3…\n$ W_FSTURWT56  &lt;dbl&gt; 2.63139, 3.45536, 10.16250, 2.77143, 9.00000, 2.89878, 2.…\n$ W_FSTURWT57  &lt;dbl&gt; 2.73358, 3.45536, 10.16250, 7.98824, 8.48571, 2.80052, 7.…\n$ W_FSTURWT58  &lt;dbl&gt; 7.89416, 9.88533, 3.38750, 8.31429, 8.48571, 8.40156, 2.5…\n$ W_FSTURWT59  &lt;dbl&gt; 2.72897, 3.29830, 10.16250, 2.56226, 2.82857, 8.76685, 7.…\n$ W_FSTURWT60  &lt;dbl&gt; 8.03388, 3.44489, 10.16250, 8.31429, 8.48571, 2.92228, 7.…\n$ W_FSTURWT61  &lt;dbl&gt; 7.89416, 9.88533, 10.16250, 7.98824, 2.82857, 8.34850, 7.…\n$ W_FSTURWT62  &lt;dbl&gt; 2.63139, 10.36607, 10.16250, 2.66275, 3.00000, 3.02482, 7…\n$ W_FSTURWT63  &lt;dbl&gt; 8.03388, 10.33466, 10.16250, 8.31429, 9.00000, 3.20060, 7…\n$ W_FSTURWT64  &lt;dbl&gt; 7.88647, 3.44489, 3.38750, 7.98824, 2.82857, 2.67580, 2.5…\n$ W_FSTURWT65  &lt;dbl&gt; 7.89416, 3.29511, 3.38750, 2.56226, 3.00000, 8.40156, 2.4…\n$ W_FSTURWT66  &lt;dbl&gt; 8.36312, 3.44489, 3.38750, 2.56226, 3.00000, 2.78283, 7.5…\n$ W_FSTURWT67  &lt;dbl&gt; 2.67796, 3.29830, 3.38750, 2.66275, 2.82857, 8.34850, 2.4…\n$ W_FSTURWT68  &lt;dbl&gt; 2.62882, 10.36607, 10.16250, 2.66275, 8.48571, 2.78283, 2…\n$ W_FSTURWT69  &lt;dbl&gt; 8.03388, 3.29511, 3.38750, 7.98824, 9.00000, 8.69635, 7.5…\n$ W_FSTURWT70  &lt;dbl&gt; 2.78196, 9.89489, 10.16250, 2.66275, 3.00000, 8.40156, 7.…\n$ W_FSTURWT71  &lt;dbl&gt; 2.73358, 3.29830, 3.38750, 8.31429, 9.00000, 8.76685, 2.5…\n$ W_FSTURWT72  &lt;dbl&gt; 8.18690, 9.88533, 10.16250, 2.66275, 9.00000, 8.69635, 2.…\n$ W_FSTURWT73  &lt;dbl&gt; 8.20073, 10.33466, 10.16250, 7.68679, 2.82857, 3.05511, 2…\n$ W_FSTURWT74  &lt;dbl&gt; 2.67796, 10.36607, 10.16250, 7.68679, 3.00000, 2.92228, 2…\n$ W_FSTURWT75  &lt;dbl&gt; 2.68151, 9.89489, 10.16250, 7.98824, 8.48571, 8.69635, 7.…\n$ W_FSTURWT76  &lt;dbl&gt; 2.73358, 3.45536, 3.38750, 8.31429, 9.00000, 2.89878, 2.4…\n$ W_FSTURWT77  &lt;dbl&gt; 2.63139, 3.45536, 3.38750, 2.66275, 8.48571, 2.58510, 7.5…\n$ W_FSTURWT78  &lt;dbl&gt; 7.89416, 9.88533, 10.16250, 2.77143, 8.48571, 8.40156, 2.…\n$ W_FSTURWT79  &lt;dbl&gt; 2.62882, 3.29830, 3.38750, 7.68679, 2.82857, 8.76685, 7.3…\n$ W_FSTURWT80  &lt;dbl&gt; 8.03388, 3.44489, 3.38750, 2.77143, 8.48571, 2.68850, 7.3…\n$ UNIT         &lt;dbl&gt; 1, 1, 1, 1, 1, 2, 2, 1, 1, 2, 1, 2, 2, 2, 1, 1, 1, 2, 2, …\n$ WVARSTRR     &lt;dbl&gt; 70, 53, 2, 27, 35, 50, 65, 1, 63, 4, 13, 65, 42, 68, 15, …\n$ PV1MATH      &lt;dbl&gt; 639.004, 697.191, 693.710, 427.317, 436.462, 569.982, 771…\n$ PV2MATH      &lt;dbl&gt; 601.251, 754.277, 654.450, 410.376, 453.450, 539.609, 672…\n$ PV3MATH      &lt;dbl&gt; 621.480, 671.940, 696.938, 423.586, 392.315, 531.648, 653…\n$ PV4MATH      &lt;dbl&gt; 631.596, 657.300, 646.187, 388.935, 439.986, 534.368, 734…\n$ PV5MATH      &lt;dbl&gt; 579.276, 621.126, 678.119, 330.962, 443.125, 465.815, 727…\n$ PV6MATH      &lt;dbl&gt; 591.791, 655.729, 644.019, 379.988, 452.648, 528.509, 729…\n$ PV7MATH      &lt;dbl&gt; 600.709, 747.934, 720.531, 398.535, 396.970, 514.326, 597…\n$ PV8MATH      &lt;dbl&gt; 587.322, 694.365, 671.425, 422.127, 459.945, 521.029, 772…\n$ PV9MATH      &lt;dbl&gt; 618.131, 742.732, 694.085, 375.354, 438.166, 472.382, 694…\n$ PV10MATH     &lt;dbl&gt; 581.973, 656.934, 668.304, 453.348, 448.084, 503.387, 725…\n$ PV1READ      &lt;dbl&gt; 676.298, 625.585, 620.116, 381.495, 448.199, 469.441, 744…\n$ PV2READ      &lt;dbl&gt; 692.247, 686.716, 559.078, 400.815, 560.636, 500.350, 679…\n$ PV3READ      &lt;dbl&gt; 690.981, 663.147, 554.767, 374.911, 365.478, 375.703, 635…\n$ PV4READ      &lt;dbl&gt; 643.067, 567.435, 587.026, 367.484, 469.970, 377.452, 725…\n$ PV5READ      &lt;dbl&gt; 627.908, 614.500, 591.806, 336.009, 503.664, 470.781, 731…\n$ PV6READ      &lt;dbl&gt; 684.676, 604.745, 570.547, 324.630, 481.215, 415.448, 684…\n$ PV7READ      &lt;dbl&gt; 661.380, 669.375, 599.078, 396.242, 436.800, 448.547, 646…\n$ PV8READ      &lt;dbl&gt; 674.070, 623.735, 545.610, 374.723, 531.226, 434.381, 756…\n$ PV9READ      &lt;dbl&gt; 666.282, 649.579, 610.466, 314.704, 480.997, 411.703, 653…\n$ PV10READ     &lt;dbl&gt; 657.387, 571.261, 590.758, 342.956, 478.578, 410.846, 784…\n$ PV1SCIE      &lt;dbl&gt; 710.634, 670.646, 666.095, 340.308, 456.333, 475.158, 693…\n$ PV2SCIE      &lt;dbl&gt; 618.739, 748.839, 604.771, 329.889, 453.400, 470.030, 626…\n$ PV3SCIE      &lt;dbl&gt; 591.623, 635.443, 704.217, 411.353, 498.937, 461.218, 627…\n$ PV4SCIE      &lt;dbl&gt; 659.770, 639.735, 687.659, 327.974, 532.324, 504.199, 676…\n$ PV5SCIE      &lt;dbl&gt; 635.892, 608.385, 690.974, 292.183, 508.231, 486.930, 661…\n$ PV6SCIE      &lt;dbl&gt; 646.901, 670.662, 617.175, 355.423, 504.461, 493.011, 618…\n$ PV7SCIE      &lt;dbl&gt; 603.569, 734.807, 692.886, 400.182, 404.572, 469.950, 602…\n$ PV8SCIE      &lt;dbl&gt; 621.352, 639.748, 630.900, 317.518, 549.457, 464.012, 653…\n$ PV9SCIE      &lt;dbl&gt; 659.674, 716.768, 656.620, 298.893, 411.062, 440.113, 645…\n$ PV10SCIE     &lt;dbl&gt; 649.719, 655.670, 649.087, 362.702, 473.613, 495.410, 662…\n$ PV1MCCR      &lt;dbl&gt; 649.392, 636.431, 645.218, 437.613, 474.516, 471.365, 718…\n$ PV2MCCR      &lt;dbl&gt; 575.372, 674.370, 680.260, 498.958, 521.987, 546.743, 708…\n$ PV3MCCR      &lt;dbl&gt; 603.792, 716.787, 711.792, 402.737, 434.209, 581.279, 707…\n$ PV4MCCR      &lt;dbl&gt; 656.162, 616.569, 633.124, 407.151, 432.725, 567.093, 720…\n$ PV5MCCR      &lt;dbl&gt; 625.136, 701.626, 711.941, 450.975, 392.901, 498.145, 736…\n$ PV6MCCR      &lt;dbl&gt; 582.174, 686.793, 749.576, 487.698, 444.589, 519.416, 670…\n$ PV7MCCR      &lt;dbl&gt; 665.104, 665.775, 692.915, 391.175, 382.733, 521.639, 749…\n$ PV8MCCR      &lt;dbl&gt; 599.694, 729.194, 648.755, 426.641, 497.778, 513.726, 729…\n$ PV9MCCR      &lt;dbl&gt; 616.165, 715.697, 721.097, 366.883, 439.754, 519.125, 696…\n$ PV10MCCR     &lt;dbl&gt; 628.181, 688.830, 657.165, 435.455, 486.126, 544.408, 779…\n$ PV1MCQN      &lt;dbl&gt; 615.137, 661.706, 569.292, 403.429, 432.794, 526.659, 703…\n$ PV2MCQN      &lt;dbl&gt; 538.617, 762.401, 647.507, 419.847, 494.698, 580.938, 707…\n$ PV3MCQN      &lt;dbl&gt; 587.580, 712.182, 660.431, 418.996, 429.147, 577.745, 703…\n$ PV4MCQN      &lt;dbl&gt; 686.280, 685.954, 569.983, 375.158, 464.070, 622.873, 631…\n$ PV5MCQN      &lt;dbl&gt; 589.078, 722.402, 637.599, 433.093, 446.069, 557.871, 673…\n$ PV6MCQN      &lt;dbl&gt; 554.608, 677.709, 652.780, 453.028, 441.193, 488.815, 645…\n$ PV7MCQN      &lt;dbl&gt; 682.886, 691.586, 636.887, 435.661, 417.452, 602.295, 740…\n$ PV8MCQN      &lt;dbl&gt; 574.889, 688.120, 611.227, 441.660, 474.220, 578.260, 757…\n$ PV9MCQN      &lt;dbl&gt; 601.470, 704.436, 685.701, 430.417, 443.916, 541.486, 721…\n$ PV10MCQN     &lt;dbl&gt; 627.403, 692.040, 604.016, 382.344, 476.528, 572.958, 715…\n$ PV1MCSS      &lt;dbl&gt; 686.193, 664.374, 655.070, 397.737, 429.063, 466.035, 637…\n$ PV2MCSS      &lt;dbl&gt; 656.043, 660.937, 612.146, 336.048, 437.136, 498.416, 712…\n$ PV3MCSS      &lt;dbl&gt; 650.782, 692.654, 646.904, 438.551, 451.101, 502.442, 702…\n$ PV4MCSS      &lt;dbl&gt; 643.126, 654.111, 590.767, 347.416, 464.708, 517.999, 702…\n$ PV5MCSS      &lt;dbl&gt; 675.389, 644.941, 727.077, 420.278, 338.774, 452.092, 663…\n$ PV6MCSS      &lt;dbl&gt; 591.001, 699.918, 648.958, 401.609, 453.538, 494.653, 632…\n$ PV7MCSS      &lt;dbl&gt; 684.203, 653.602, 623.166, 413.761, 366.873, 463.116, 727…\n$ PV8MCSS      &lt;dbl&gt; 617.908, 629.891, 677.449, 299.027, 469.776, 498.289, 719…\n$ PV9MCSS      &lt;dbl&gt; 601.076, 696.030, 654.643, 373.784, 438.499, 441.962, 635…\n$ PV10MCSS     &lt;dbl&gt; 645.941, 663.634, 649.460, 363.817, 484.175, 411.098, 774…\n$ PV1MCUD      &lt;dbl&gt; 597.328, 655.345, 658.932, 393.019, 429.756, 491.327, 650…\n$ PV2MCUD      &lt;dbl&gt; 564.341, 732.821, 648.412, 393.366, 491.067, 522.747, 721…\n$ PV3MCUD      &lt;dbl&gt; 655.238, 737.658, 672.524, 384.864, 445.708, 486.597, 663…\n$ PV4MCUD      &lt;dbl&gt; 638.884, 651.654, 614.591, 379.824, 510.568, 524.480, 680…\n$ PV5MCUD      &lt;dbl&gt; 604.706, 690.450, 664.442, 501.245, 403.908, 483.108, 753…\n$ PV6MCUD      &lt;dbl&gt; 576.996, 666.422, 687.078, 453.339, 412.346, 505.925, 667…\n$ PV7MCUD      &lt;dbl&gt; 672.527, 673.451, 708.829, 425.168, 419.173, 501.566, 746…\n$ PV8MCUD      &lt;dbl&gt; 599.424, 728.294, 640.191, 407.016, 576.384, 506.734, 801…\n$ PV9MCUD      &lt;dbl&gt; 604.423, 701.038, 732.526, 421.738, 392.309, 499.849, 638…\n$ PV10MCUD     &lt;dbl&gt; 664.795, 650.797, 619.894, 421.415, 461.595, 442.838, 734…\n$ PV1MPEM      &lt;dbl&gt; 604.382, 705.040, 676.642, 401.548, 437.563, 528.852, 692…\n$ PV2MPEM      &lt;dbl&gt; 575.460, 710.217, 705.385, 389.686, 474.378, 604.877, 678…\n$ PV3MPEM      &lt;dbl&gt; 534.443, 713.023, 585.184, 390.502, 433.958, 498.130, 711…\n$ PV4MPEM      &lt;dbl&gt; 571.301, 679.747, 670.486, 434.343, 442.276, 511.479, 711…\n$ PV5MPEM      &lt;dbl&gt; 675.638, 661.754, 645.880, 366.385, 522.369, 555.593, 706…\n$ PV6MPEM      &lt;dbl&gt; 566.880, 718.268, 760.958, 401.969, 417.482, 555.839, 749…\n$ PV7MPEM      &lt;dbl&gt; 582.805, 613.478, 731.917, 496.875, 444.665, 553.932, 690…\n$ PV8MPEM      &lt;dbl&gt; 558.696, 643.541, 676.092, 353.233, 464.823, 571.562, 708…\n$ PV9MPEM      &lt;dbl&gt; 662.795, 640.522, 684.182, 476.154, 434.014, 520.155, 719…\n$ PV10MPEM     &lt;dbl&gt; 640.998, 655.268, 702.866, 342.948, 458.216, 609.277, 671…\n$ PV1MPFS      &lt;dbl&gt; 518.732, 763.661, 690.547, 421.798, 454.383, 493.759, 702…\n$ PV2MPFS      &lt;dbl&gt; 557.279, 729.497, 728.787, 467.856, 401.375, 538.097, 662…\n$ PV3MPFS      &lt;dbl&gt; 497.254, 714.971, 633.737, 414.444, 453.331, 485.088, 670…\n$ PV4MPFS      &lt;dbl&gt; 615.386, 753.899, 703.501, 445.029, 414.743, 465.568, 658…\n$ PV5MPFS      &lt;dbl&gt; 615.007, 719.492, 654.486, 389.460, 443.411, 493.251, 653…\n$ PV6MPFS      &lt;dbl&gt; 591.702, 715.191, 734.709, 414.555, 391.559, 545.850, 699…\n$ PV7MPFS      &lt;dbl&gt; 595.836, 702.035, 737.481, 489.032, 386.903, 504.961, 697…\n$ PV8MPFS      &lt;dbl&gt; 540.481, 704.257, 685.489, 363.830, 452.824, 532.093, 692…\n$ PV9MPFS      &lt;dbl&gt; 600.664, 664.705, 665.867, 419.104, 478.373, 568.115, 656…\n$ PV10MPFS     &lt;dbl&gt; 613.118, 705.987, 727.280, 394.856, 407.059, 485.863, 698…\n$ PV1MPIN      &lt;dbl&gt; 602.757, 733.566, 682.130, 407.066, 414.746, 459.876, 691…\n$ PV2MPIN      &lt;dbl&gt; 571.184, 744.273, 692.729, 381.339, 399.365, 490.634, 671…\n$ PV3MPIN      &lt;dbl&gt; 646.605, 758.913, 647.770, 364.773, 447.814, 386.584, 737…\n$ PV4MPIN      &lt;dbl&gt; 679.914, 695.003, 629.600, 406.470, 454.758, 499.082, 731…\n$ PV5MPIN      &lt;dbl&gt; 685.582, 714.181, 693.276, 433.901, 442.892, 441.024, 737…\n$ PV6MPIN      &lt;dbl&gt; 637.760, 716.221, 660.979, 406.423, 463.269, 544.965, 763…\n$ PV7MPIN      &lt;dbl&gt; 645.213, 663.813, 684.474, 489.700, 423.967, 475.647, 782…\n$ PV8MPIN      &lt;dbl&gt; 577.579, 662.428, 656.617, 432.277, 464.304, 504.819, 769…\n$ PV9MPIN      &lt;dbl&gt; 661.673, 640.743, 687.070, 512.069, 435.375, 459.819, 686…\n$ PV10MPIN     &lt;dbl&gt; 670.254, 768.695, 648.410, 374.502, 495.469, 481.600, 708…\n$ PV1MPRE      &lt;dbl&gt; 537.068, 706.337, 630.753, 378.730, 364.784, 523.219, 756…\n$ PV2MPRE      &lt;dbl&gt; 614.320, 672.767, 694.543, 400.807, 399.972, 536.264, 700…\n$ PV3MPRE      &lt;dbl&gt; 583.272, 651.949, 604.546, 407.607, 452.831, 454.319, 687…\n$ PV4MPRE      &lt;dbl&gt; 620.093, 620.759, 614.087, 336.451, 394.357, 501.514, 701…\n$ PV5MPRE      &lt;dbl&gt; 634.054, 645.072, 603.798, 317.742, 409.755, 498.824, 724…\n$ PV6MPRE      &lt;dbl&gt; 602.552, 677.174, 644.046, 349.040, 428.787, 523.705, 680…\n$ PV7MPRE      &lt;dbl&gt; 595.217, 634.813, 710.851, 450.198, 375.015, 497.360, 697…\n$ PV8MPRE      &lt;dbl&gt; 603.353, 648.907, 656.938, 392.060, 414.975, 508.547, 736…\n$ PV9MPRE      &lt;dbl&gt; 611.942, 641.203, 690.323, 447.422, 441.178, 499.691, 734…\n$ PV10MPRE     &lt;dbl&gt; 663.352, 644.001, 664.134, 382.088, 421.531, 580.387, 727…\n$ SENWT        &lt;dbl&gt; 0.63867, 0.80357, 0.80736, 0.64732, 0.69397, 0.67917, 0.5…\n$ VER_DAT      &lt;chr&gt; \"01MAY23:14:19:45\", \"01MAY23:14:19:44\", \"01MAY23:14:19:45…\n$ i            &lt;dbl&gt; 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 218, 21…\n\n\n\n\n\nBelow code chunk shows no duplicate records found in dataset.\n\n\nShow code\nsfu_qqq_SG[duplicated(sfu_qqq_SG),]\n\n\n# A tibble: 0 × 1,279\n# ℹ 1,279 variables: CNT &lt;chr&gt;, CNTRYID &lt;dbl&gt;, CNTSCHID &lt;dbl&gt;, CNTSTUID &lt;dbl&gt;,\n#   CYC &lt;chr&gt;, NatCen &lt;chr&gt;, STRATUM &lt;chr&gt;, SUBNATIO &lt;chr&gt;, REGION &lt;dbl&gt;,\n#   OECD &lt;dbl&gt;, ADMINMODE &lt;dbl&gt;, LANGTEST_QQQ &lt;dbl&gt;, LANGTEST_COG &lt;dbl&gt;,\n#   LANGTEST_PAQ &lt;dbl&gt;, Option_CT &lt;dbl&gt;, Option_FL &lt;dbl&gt;, Option_ICTQ &lt;dbl&gt;,\n#   Option_WBQ &lt;dbl&gt;, Option_PQ &lt;dbl&gt;, Option_TQ &lt;dbl&gt;, Option_UH &lt;dbl&gt;,\n#   BOOKID &lt;dbl&gt;, ST001D01T &lt;dbl&gt;, ST003D02T &lt;dbl&gt;, ST003D03T &lt;dbl&gt;,\n#   ST004D01T &lt;dbl&gt;, ST250Q01JA &lt;dbl&gt;, ST250Q02JA &lt;dbl&gt;, ST250Q03JA &lt;dbl&gt;, …\n\n\nBelow code chunk shows many missing values in dataset, also observed from observations on data sample and data structure.\n\n\nShow code\nsum(is.na(sfu_qqq_SG))\n\n\n[1] 4168500\n\n\n\n\n\n\n\n\n\n\n\nInitial observations on dataset\n\n\n\n\nThe dataset of Singapore students contains 6,066 rows of records with 1,279 variables. A visual look at the overview of the data structure revealed the following:\n\nThere are more than a thousand variables, most of which may not be required in the subsequent analysis since the dataset records the responses of the students’ to the questionnaire in full. Hence, subsequent data processing will extract relevant variables for further analysis.\nThere are many variables which has “NA” as its value, though these variables may not be required for the analysis. Another check for missing values will be done once the required variables have been extracted.\nNo duplicates are present in the dataset."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#extraction-of-relevant-variables",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#extraction-of-relevant-variables",
    "title": "A Look into Singapore Students’ Performance Using PISA 2022",
    "section": "2.4 Extraction of relevant variables",
    "text": "2.4 Extraction of relevant variables\nBelow code chunks are used to extract the variables that are required for further analysis to meet the task objectives. Variables required are:\n\nStudentID, denoted by CNTSTUID\nEstimate measure for student’s performance\n\nPlausible values (PVs) for each of the three domains, i.e. MATHS, SCIENCE and READING, denoted by PV{N}{DOMAIN} where N is the nth plausible value for the DOMAIN.\n\nSchool\n\nSchoolID, denoted by CNTSCHID\nWhether school is public or independent, denoted by STRATUM.\n\nGender\n\nFemale or Male, denoted by ST004D01T.\n\nMeasure for socioeconomic status\n\nDenoted by ESCS, which is an index that measures economic, social and cultural status.\n\n\n\n\nShow code\nreq_cols &lt;- c(\"CNTSTUID\", \n              \"PV1MATH\", \"PV2MATH\", \"PV3MATH\", \"PV4MATH\", \"PV5MATH\", \"PV6MATH\", \"PV7MATH\", \"PV8MATH\", \"PV9MATH\", \"PV10MATH\", \n              \"PV1READ\", \"PV2READ\", \"PV3READ\", \"PV4READ\", \"PV5READ\", \"PV6READ\", \"PV7READ\", \"PV8READ\", \"PV9READ\", \"PV10READ\",\n              \"PV1SCIE\", \"PV2SCIE\", \"PV3SCIE\", \"PV4SCIE\", \"PV5SCIE\", \"PV6SCIE\", \"PV7SCIE\", \"PV8SCIE\", \"PV9SCIE\", \"PV10SCIE\",\n              \"CNTSCHID\",\n              \"STRATUM\",\n              \"ST004D01T\", \n              \"ESCS\", \n              \"HOMEPOS\", \n              \"ICTRES\",\n              \"HISEI\",\n              \"PAREDINT\")\nsfu_qqq_SG_req &lt;- sfu_qqq_SG[req_cols] %&gt;% \n  mutate(ST004D01T = as.factor(ST004D01T),\n         CNTSTUID = as.character(CNTSTUID),\n         CNTSCHID = as.character(CNTSCHID))\n\n\n\nData sampleData check\n\n\n\n\n\nShow-code\ndatatable(head(sfu_qqq_SG_req, 8),\n          rownames = FALSE,\n          options = list(dom = c(\"t\")),\n          style = \"bootstrap\")\n\n\n\n\n\n\n\n\n\n\nThere exists extracted variables with values of “NA” within the dataset.\n\n\nShow-code\nnames(which(colSums(is.na(sfu_qqq_SG_req))&gt;0))\n\n\n[1] \"ESCS\"     \"HOMEPOS\"  \"ICTRES\"   \"HISEI\"    \"PAREDINT\"\n\n\nBelow code is used to find out the number of “NA” values within each variable, with the most “NA” (at approx. 5% of records) being observed for the variable “HISEI” which is an index representing the highest parental occupational status.\n\n\nShow-code\n(colSums(is.na(sfu_qqq_SG_req)))\n\n\n CNTSTUID   PV1MATH   PV2MATH   PV3MATH   PV4MATH   PV5MATH   PV6MATH   PV7MATH \n        0         0         0         0         0         0         0         0 \n  PV8MATH   PV9MATH  PV10MATH   PV1READ   PV2READ   PV3READ   PV4READ   PV5READ \n        0         0         0         0         0         0         0         0 \n  PV6READ   PV7READ   PV8READ   PV9READ  PV10READ   PV1SCIE   PV2SCIE   PV3SCIE \n        0         0         0         0         0         0         0         0 \n  PV4SCIE   PV5SCIE   PV6SCIE   PV7SCIE   PV8SCIE   PV9SCIE  PV10SCIE  CNTSCHID \n        0         0         0         0         0         0         0         0 \n  STRATUM ST004D01T      ESCS   HOMEPOS    ICTRES     HISEI  PAREDINT \n        0         0        47        40        40       310        57"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#compute-mean-pv-values-for-each-domain",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#compute-mean-pv-values-for-each-domain",
    "title": "A Look into Singapore Students’ Performance Using PISA 2022",
    "section": "3.1 Compute mean PV values for each domain",
    "text": "3.1 Compute mean PV values for each domain\nThe PISA statistics provides 10 plausible values (PVs) for each student in each of the three domains. The plausible values provides more accurate and reliable estimates of students’ abilities and overall performance of educational systems. The mean value of 10 PVs is computed to represent the average of the 10 estimates, which is then used as an estimation of the particular students’ PV. Below code chunk is used to perform the computation.\n\n\nShow Code\n# computation for Math PVs\nsfu_qqq_SG_req[\"PVMATH_final\"] &lt;- sfu_qqq_SG_req %&gt;%\n  select(\"PV1MATH\", \"PV2MATH\", \"PV3MATH\", \"PV4MATH\", \"PV5MATH\", \"PV6MATH\", \"PV7MATH\", \"PV8MATH\", \"PV9MATH\", \"PV10MATH\") %&gt;% \n  apply(, MARGIN=1, FUN=mean)\n\n# computation for READING PVs\nsfu_qqq_SG_req[\"PVREAD_final\"] &lt;- sfu_qqq_SG_req %&gt;%\n  select(\"PV1READ\", \"PV2READ\", \"PV3READ\", \"PV4READ\", \"PV5READ\", \"PV6READ\", \"PV7READ\", \"PV8READ\", \"PV9READ\", \"PV10READ\") %&gt;% \n  apply(, MARGIN=1, FUN=mean)\n\n# computation for SCIENCE PVs\nsfu_qqq_SG_req[\"PVSCIE_final\"] &lt;- sfu_qqq_SG_req %&gt;%\n  select(\"PV1SCIE\", \"PV2SCIE\", \"PV3SCIE\", \"PV4SCIE\", \"PV5SCIE\", \"PV6SCIE\", \"PV7SCIE\", \"PV8SCIE\", \"PV9SCIE\", \"PV10SCIE\") %&gt;% \n  apply(, MARGIN=1, FUN=mean)\n\ndatatable(head(sfu_qqq_SG_req[c(\"CNTSTUID\", \"PVMATH_final\", \"PVREAD_final\", \"PVSCIE_final\")], 8),\n          rownames = FALSE,\n          options = list(dom = c(\"t\")),\n          style = \"bootstrap\",\n          caption = \"Table showing computed mean values\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#mapping-pv-values-into-performance-levels",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#mapping-pv-values-into-performance-levels",
    "title": "A Look into Singapore Students’ Performance Using PISA 2022",
    "section": "3.2 Mapping PV Values into Performance Levels",
    "text": "3.2 Mapping PV Values into Performance Levels\nUsing the performance band definitions of each domain provided in PISA 2022 Technical Report (Chapter 17), the mean PV values were mapped into the respective performance level using the mean of the PV estimate. The performance band definitions for the domains are shown below.\n\nMATHREADINGSCIENCE\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBelow code chunks map the mean PVs of the three domains into their respective performance levels:\n\n\nShow Code\n# mapping MATH PV\nsfu_qqq_SG_req[\"MATH_level\"] &lt;- cut(sfu_qqq_SG_req$PVMATH_final, \n                                    breaks = c(0, 233.17, 295.46999, 357.76999, 420.06999, 482.37999, 544.67999, 606.98999, 669.29999, 2000),\n                                    labels = c(\"Below 1c\", \"Level 1c\", \"Level 1b\", \"Level 1a\", \"Level 2\", \"Level 3\", \"Level 4\", \"Level 5\", \"Level 6\"))\n\n# mapping READING PV\nsfu_qqq_SG_req[\"READ_level\"] &lt;- cut(sfu_qqq_SG_req$PVREAD_final, \n                                    breaks = c(0, 189.32999, 262.03999, 334.74999, 407.46999, 480.17999, 552.88999, 625.60999, 698.31999, 2000),\n                                    labels = c(\"Below 1c\", \"Level 1c\", \"Level 1b\", \"Level 1a\", \"Level 2\", \"Level 3\", \"Level 4\", \"Level 5\", \"Level 6\"))\n\n# mapping SCIENCE PV\nsfu_qqq_SG_req[\"SCIE_level\"] &lt;- cut(sfu_qqq_SG_req$PVSCIE_final, \n                                    breaks = c(0, 260.53999, 334.93999, 409.53999, 484.13999, 558.72999, 633.32999, 707.92999, 2000),\n                                    labels = c(\"Below 1b\", \"Level 1b\", \"Level 1a\", \"Level 2\", \"Level 3\", \"Level 4\", \"Level 5\", \"Level 6\"))\n\ndatatable(head(sfu_qqq_SG_req[c(\"CNTSTUID\", \"MATH_level\", \"READ_level\", \"SCIE_level\")], 8),\n          rownames = FALSE,\n          options = list(dom = c(\"t\")),\n          style = \"bootstrap\",\n          caption = \"Table showing mapped performance levels for three domains\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#recoding-school-category-and-gender",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#recoding-school-category-and-gender",
    "title": "A Look into Singapore Students’ Performance Using PISA 2022",
    "section": "3.3 Recoding School Category and Gender",
    "text": "3.3 Recoding School Category and Gender\nThe values of the variables representing school category (i.e. public or private) and gender (i,e, male or female) are recoded for easier visual interpretation. These values are represented using numbers or non-intuitive tags in the dataset. The code chunks below are used to recode the values.\n\n\nShow Code\nsfu_qqq_SG_req &lt;- sfu_qqq_SG_req %&gt;% \n# gender\n  mutate(ST004D01T = case_when(ST004D01T == 1 ~ \"Female\",\n                               ST004D01T == 2 ~ \"Male\",\n                               TRUE ~ \"Not mentioned\")) %&gt;% \n# school category\n  mutate(STRATUM = case_when(STRATUM == \"SGP01\" ~ \"Public Sch\",\n                             STRATUM == \"SGP02\" ~ \"Public Sch\",\n                             STRATUM == \"SGP03\" ~ \"Private Sch\",\n                             STRATUM == \"SGP97\" ~ \"Undisclosed\",\n                             TRUE ~ \"Unknown code\"))\n\ndatatable(head(sfu_qqq_SG_req[c(\"CNTSTUID\", \"ST004D01T\", \"STRATUM\")], 8),\n          rownames = FALSE,\n          options = list(dom = c(\"t\")),\n          style = \"bootstrap\",\n          caption = \"Table showing recoded values\")\n\n\n\n\n\n\n\nVisualising distributions of School Category and Gender\n\nBy genderBy school category\n\n\n\n\nShow Code\ngender_bar &lt;- ggplot(data = sfu_qqq_SG_req,\n       aes(x=ST004D01T)) +\n  geom_bar(fill = \"lightblue\") + \n  labs(x = NULL, \n       y = \"Num of students\") +\n  theme_pander() +\n  ggtitle(\"Distribution of students by gender\") + \n  theme(plot.title = element_text(size = 12)) \n\ngender_box_math &lt;- ggplot(data = sfu_qqq_SG_req,\n                     aes(x = ST004D01T, y = PVMATH_final)) +\n  geom_boxplot() +\n  scale_y_continuous(limits = c(0,1000)) +\n  theme_pander() +\n  labs (x = NULL,\n        y = NULL) +\n  ggtitle(\"Math\") +\n  theme(plot.title = element_text(size = 10)) +\n  coord_flip()\n\ngender_box_read &lt;- ggplot(data = sfu_qqq_SG_req,\n                     aes(x = ST004D01T, y = PVREAD_final)) +\n  geom_boxplot() +\n  scale_y_continuous(limits = c(0,1000)) +\n  theme_pander() +\n  labs (x = NULL,\n        y = NULL) +\n  ggtitle(\"Reading\") +\n  theme(plot.title = element_text(size = 10)) +\n  coord_flip()\n\ngender_box_scie &lt;- ggplot(data = sfu_qqq_SG_req,\n                     aes(x = ST004D01T, y = PVSCIE_final)) +\n  geom_boxplot() +\n  scale_y_continuous(limits = c(0,1000)) +\n  theme_pander() +\n  labs (x = NULL,\n        y = NULL) +\n  ggtitle(\"Science\") +\n  theme(plot.title = element_text(size = 10)) +\n  coord_flip()\n\ngender_bar | (gender_box_math / gender_box_read / gender_box_scie)\n\n\n\n\n\n\n\n\n\n\n\nDISCUSSIONS & INSIGHTS\n\n\n\n\nAfter recoding is done for the gender, by using the variable “ST004D01T”, it was observed that the number of male and female students in the dataset are rather even. A preliminary look at the distribution via the boxplots seemed to reveal that female students performed better at Reading, while male students performed better at Math and Science. However, as there is significant overlap in the boxplots, further analysis via EDA techniques will be done to see if there could be more insights that could be derived.\n\n\n\n\n\n\n\nShow Code\nschool_bar &lt;- ggplot(data = sfu_qqq_SG_req,\n       aes(x=STRATUM)) +\n  geom_bar(fill = \"lightblue\") + \n  labs(x = NULL, \n       y = \"Num of students\") +\n  theme_pander() +\n  ggtitle(\"Distribution of students by school\") + \n  theme(plot.title = element_text(size = 12)) \n\nschool_box_math &lt;- ggplot(data = sfu_qqq_SG_req,\n                     aes(x = STRATUM, y = PVMATH_final)) +\n  geom_boxplot() +\n  scale_y_continuous(limits = c(0,1000)) +\n  theme_pander() +\n  labs (x = NULL,\n        y = NULL) +\n  ggtitle(\"Math\") +\n  theme(plot.title = element_text(size = 10)) +\n  coord_flip()\n\nschool_box_read &lt;- ggplot(data = sfu_qqq_SG_req,\n                     aes(x = STRATUM, y = PVREAD_final)) +\n  geom_boxplot() +\n  scale_y_continuous(limits = c(0,1000)) +\n  theme_pander() +\n  labs (x = NULL,\n        y = NULL) +\n  ggtitle(\"Reading\") +\n  theme(plot.title = element_text(size = 10)) +\n  coord_flip()\n\nschool_box_scie &lt;- ggplot(data = sfu_qqq_SG_req,\n                     aes(x = STRATUM, y = PVSCIE_final)) +\n  geom_boxplot() +\n  scale_y_continuous(limits = c(0,1000)) +\n  theme_pander() +\n  labs (x = NULL,\n        y = NULL) +\n  ggtitle(\"Science\") +\n  theme(plot.title = element_text(size = 10)) +\n  coord_flip()\n\nschool_bar | (school_box_math / school_box_read / school_box_scie)\n\n\n\n\n\n\n\n\n\n\n\nDISCUSSIONS & INSIGHTS\n\n\n\n\nAfter recoding is done for the school category, by using the variable “STRATUM”, it was observed that the numbers of public school vs private school students in the dataset is rather unbalanced, though this is within expectations as the number of public schools in Singapore is much larger than private schools.\nConsequently, subsequent EDA on the relationship between performance and schools should be done with this observation in mind, i.e. a probability density approach might be more relevant in looking at the distribution of performance of both public and private schools."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#distribution-of-singapore-students-performance-in-math-reading-and-science",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#distribution-of-singapore-students-performance-in-math-reading-and-science",
    "title": "A Look into Singapore Students’ Performance Using PISA 2022",
    "section": "4.1 Distribution of Singapore students’ performance in Math, Reading, and Science",
    "text": "4.1 Distribution of Singapore students’ performance in Math, Reading, and Science\nIn this section, the raincloud plot is used to provide a visual overview of students’ performances in the three domains. The raincloud plot is a data visualisation technique that provides a half density distribution diagram, and thus is able to provide additional insights, such as the existence of multiple modalities, which could suggests the possibility of groups. Using the raincloud plot, we were able to come up with insights and hypothesis, which could be examined further using CDA techniques.\nBelow are the code chunks for this data visualisation:\n\n\nCode\n# manipulate data for plotting\nmath_only &lt;- sfu_qqq_SG_req %&gt;%\n  select(\"PVMATH_final\")\nmath_only['Domain'] = \"MATH\"\ncolnames(math_only) &lt;- c(\"Score\", \"Domain\")\n\nread_only &lt;- sfu_qqq_SG_req %&gt;%\n  select(\"PVREAD_final\")\nread_only['Domain'] = \"READING\"\ncolnames(read_only) &lt;- c(\"Score\", \"Domain\")\n\nscie_only &lt;- sfu_qqq_SG_req %&gt;%\n  select(\"PVSCIE_final\")\nscie_only['Domain'] = \"SCIENCE\"\ncolnames(scie_only) &lt;- c(\"Score\", \"Domain\")\n\nall_scores &lt;- rbind(math_only, read_only, scie_only)\n\nggplot(all_scores, \n       aes(x = Domain, y = Score)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.4,\n               .width = 0,\n               point_colour = NA,\n               scale = 0.2,\n               alpha = 0.4,\n               fill = \"blue\") +\n  geom_boxplot(width = 0.1,\n               outlier.shape = NA) +\n  stat_dots(side = \"left\",\n            justification = 1.5,\n            binwidth = unit(0.0022, \"npc\"),\n            dotsize = 1,\n            scale = 0.01,\n            position = \"dodge\",\n            alpha = 0.4,\n            color = \"lightblue\") +\n  coord_flip(xlim = c(0.6, 2.8)) +\n  theme_minimal() +\n  plot_annotation(title = \"Distribution of Singapore students performance by Domain\")\n\n\n\n\n\n\n\n\n\n\n\nDISCUSSIONS & INSIGHTS\n\n\n\n\nUsing the above plots, insights pertaining to the distribution of the performance of Singapore students were obtained:\n\nFrom the density plot, the peak frequencies for Math and Science occurs at higher scores as compared to Reading, suggesting that Singapore students’ performed better in Maths and Science. This observation is also apparent from the boxplot, where the median scores for Reading is lower.\nFrom the inverted dot plot, it was observed that the distributions are quite similarly shaped for all three domains, though the number of students scoring better in Math and Science is higher, indicated by the higher number of dots ay higher scores.\nThe outliers for all 3 domains occur at only the lower range, but as the numbers are not high, this may not be of concern.\nThe dot plot also suggests the possibility of multiple modalities in the distributions of Reading and Science scores, which might influence the choice of subsequent analyses."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#student-gender-seems-to-make-a-difference-in-performance",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#student-gender-seems-to-make-a-difference-in-performance",
    "title": "A Look into Singapore Students’ Performance Using PISA 2022",
    "section": "4.2 Student gender seems to make a difference in performance",
    "text": "4.2 Student gender seems to make a difference in performance\nHere, we use the ridge plot to plot out the density distributions of the performance proxy, i.e. the average Plausible Value for each domain, and compare the density distributions across the domains by gender, so as to see if any hypothesis or insights on possible relationship between gender and performance can be derived.\nBelow are the code chunks for the data visualisation.\n\nData VizNormality test2 sample-test (non-parametric)\n\n\n\n\nShow Code\nmath_ridge &lt;- ggplot(sfu_qqq_SG_req, \n       aes(x = PVMATH_final,\n           y = ST004D01T,\n           fill = ST004D01T,\n           color = ST004D01T))+\n  geom_density_ridges(bandwidth = 15,\n                      alpha = .5) +\n  labs(x = NULL,\n       y = NULL) +\n  scale_x_continuous(limits=c(100,900)) +\n  annotate(geom = \"text\",\n           x=830,\n           y=3,\n           label = \"Male students recorded peak\\nfrequency at higher Math score\",\n           size = 2) +\n  annotate(geom = \"label\",\n           x=120,\n           y=3,\n           label = \"Math\",\n           size = 4) +\n  theme_minimal() +\n  theme(legend.position=\"none\",\n        axis.text.x = element_blank())\n\nread_ridge &lt;- ggplot(sfu_qqq_SG_req, \n       aes(x = PVREAD_final,\n           y = ST004D01T,\n           fill = ST004D01T,\n           color = ST004D01T))+\n  geom_density_ridges(bandwidth = 15,\n                      alpha = .5) +\n  labs(x = NULL,\n       y = NULL) +\n  scale_x_continuous(limits=c(100,900)) +\n  annotate(geom = \"text\",\n           x=800,\n           y=3.3,\n           label = \"Female and Male students recorded peak\\nfrequency at similar Reading score\",\n           size = 2) +\n  annotate(geom = \"label\",\n           x=120,\n           y=3,\n           label = \"Reading\",\n           size = 4) +\n  theme_minimal() +\n  theme(legend.position=\"none\",\n        axis.text.x = element_blank())\n\nscie_ridge &lt;- ggplot(sfu_qqq_SG_req, \n       aes(x = PVSCIE_final,\n           y = ST004D01T,\n           fill = ST004D01T,\n           color = ST004D01T))+\n  geom_density_ridges(bandwidth = 15,\n                      alpha = .5) +\n  labs(x = \"Score for each domain\",\n       y = NULL) +\n  scale_x_continuous(limits=c(100,900)) +\n  annotate(geom = \"text\",\n           x=820,\n           y=3,\n           label = \"Male students recorded peak\\nfrequency at higher Science score\",\n           size = 2) +\n  annotate(geom = \"label\",\n           x=120,\n           y=3,\n           label = \"Science\",\n           size = 4) +\n  theme_minimal() +\n  theme(legend.position=\"none\",\n        axis.title = element_text(size = 8, color = \"grey20\"))\n\nfig2 &lt;- math_ridge / read_ridge / scie_ridge\n\nfig2 +\n  plot_annotation(title = \"Male students performed better in Math and Science\")\n\n\n\n\n\n\n\nBelow code chunks are used to plot the performances for the 3 domains by gender on Q-Q plots.\nFor the normality test at 95% confidence interval, we hypothesize that:\n\nH0 = The performance of students in the 3 domains, grouped by gender, are normally distributed\nH1 = The underlying distributions are not normally distributed\n\nVisually, the points can be observed to be deviating from the normal line, hence the implication is that the underlying distributions might not be normal.\n\n\nShow code\nqq_gender_math &lt;- ggplot(data = sfu_qqq_SG_req,\n      mapping = aes(sample = PVMATH_final,\n                    fill = ST004D01T)) +\n  stat_qq_band(alpha=0.15) +\n  stat_qq_line(alpha=0.15) +\n  stat_qq_point(size=0.5) +\n  facet_wrap(~ST004D01T,\n             nrow = 1) +\n  labs(title = \"Q-Q plot for Math \\nby gender\") +\n  theme_linedraw() +\n  theme(legend.position = \"none\",\n        axis.text = element_blank(),\n        axis.title = element_blank(),\n        axis.ticks = element_blank(),\n        plot.background = element_rect(),\n        panel.grid = element_blank())\n\nqq_gender_read &lt;- ggplot(data = sfu_qqq_SG_req,\n      mapping = aes(sample = PVREAD_final,\n                    fill = ST004D01T)) +\n  stat_qq_band(alpha=0.15) +\n  stat_qq_line(alpha=0.15) +\n  stat_qq_point(size=0.5) +\n  facet_wrap(~ST004D01T,\n             nrow = 1) +\n  labs(title = \"Q-Q plot for Reading \\nby gender\") +\n  theme_linedraw() +\n  theme(legend.position = \"none\",\n        axis.text = element_blank(),\n        axis.title = element_blank(),\n        axis.ticks = element_blank(),\n        plot.background = element_rect(),\n        panel.grid = element_blank())\n\nqq_gender_scie &lt;- ggplot(data = sfu_qqq_SG_req,\n      mapping = aes(sample = PVSCIE_final,\n                    fill = ST004D01T)) +\n  stat_qq_band(alpha=0.15) +\n  stat_qq_line(alpha=0.15) +\n  stat_qq_point(size=0.5) +\n  facet_wrap(~ST004D01T,\n             nrow = 1) +\n  labs(title = \"Q-Q plot for Science \\nby gender\") +\n  theme_linedraw() +\n  theme(legend.position = \"none\",\n        axis.text = element_blank(),\n        axis.title = element_blank(),\n        axis.ticks = element_blank(),\n        plot.background = element_rect(),\n        panel.grid = element_blank())\n\nqq_gender_math | qq_gender_read | qq_gender_scie\n\n\n\n\n\nThe Shapiro-Wilk test for normality was used to test and confirm the visual observations above. The code chunks below details outcome of th\n\n\nShow Code\nmath_sw &lt;- sfu_qqq_SG_req %&gt;% \n  group_by(ST004D01T) %&gt;% \n  shapiro_test(PVMATH_final)\n\nread_sw &lt;- sfu_qqq_SG_req %&gt;% \n  group_by(ST004D01T) %&gt;% \n  shapiro_test(PVREAD_final)\n\nscie_sw &lt;- sfu_qqq_SG_req %&gt;% \n  group_by(ST004D01T) %&gt;% \n  shapiro_test(PVSCIE_final)\n\ncombined_sw &lt;- rbind(math_sw, read_sw, scie_sw)\n\ndatatable(data = combined_sw,\n          rownames = FALSE,\n          options = list(dom = c(\"t\")),\n          style = \"bootstrap\",\n          caption = \"Table showing Shapiro-Wilk normality test results\")\n\n\n\n\n\n\n\nSince the p-value for all the distributions tested are lower than the significance level of 0.05 (taking a 95% confidence level), we reject the null hypothesis (H0) that the underlying distributions are normally distributed. This means that the performance of students (grouped by gender) in all three domains do not follow a normal distribution. This implication is that a non-parametric test will be used in subsequent analysis to test if there is any significant statistical difference in the student’s performance in the three domains according to their gender.\n\n\nHere, we use the non-parametric Wilcoxon rank-sum test with the following pairs of hypotheses using 95% confidence level. The ggbetweenstats function of ggstatsplot package is used for the test, as well as showing the outcome in a visual plot.\nHypothesis 1:\n\nH0 = There is no difference in the median Math performance of Singapore students by gender.\nH1 = There is a difference in the median Math performance of Singapore students.\n\n\n\nShow Code\nggbetweenstats(data = sfu_qqq_SG_req,\n               x = ST004D01T,\n               y = PVMATH_final,\n               type = \"nonparametric\",\n               conf.level = 0.95,\n               ylab = \"Math score\",\n               xlab = \"Gender\",\n               title = \"2 sample non-parametric test on Math score by gender\") +\n  scale_color_manual(values = c(\"palegreen\", \"pink\", \"black\")) +\n  theme_bw() +\n  theme(legend.position = \"none\")\n\n\n\n\n\nThe p-value obtained from the 2-sample non-parametric test is lower than significance level of 0.05, thus rejecting the null hypothesis that there is no difference in Math performance between genders. Specifically, Male students had a higher median than Female students, suggesting that Male students had performed better in Math.\nHypothesis 2:\n\nH0 = There is no difference in the median Reading performance of Singapore students by gender.\nH1 = There is a difference in the median Reading performance of Singapore students.\n\n\n\nShow Code\nggbetweenstats(data = sfu_qqq_SG_req,\n               x = ST004D01T,\n               y = PVREAD_final,\n               type = \"nonparametric\",\n               conf.level = 0.95,\n               ylab = \"Reading score\",\n               xlab = \"Gender\",\n               title = \"2 sample non-parametric test on Reading score by gender\") +\n  scale_color_manual(values = c(\"palegreen\", \"pink\", \"black\")) +\n  theme_bw() +\n  theme(legend.position = \"none\")\n\n\n\n\n\nThe p-value obtained from the 2-sample non-parametric test is lower than significance level of 0.05, thus rejecting the null hypothesis that there is no difference in Reading performance between genders. Specifically, Female students had a higher median than Male students, suggesting that Female students had performed better in Reading.\nHypothesis 3:\n\nH0 = There is no difference in the median Science performance of Singapore students by gender.\nH1 = There is a difference in the median Science performance of Singapore students.\n\n\n\nShow Code\nggbetweenstats(data = sfu_qqq_SG_req,\n               x = ST004D01T,\n               y = PVSCIE_final,\n               type = \"nonparametric\",\n               conf.level = 0.95,\n               ylab = \"Science score\",\n               xlab = \"Gender\",\n               title = \"2 sample non-parametric test on Science score by gender\") +\n  scale_color_manual(values = c(\"palegreen\", \"pink\", \"black\")) +\n  theme_bw() +\n  theme(legend.position = \"none\")\n\n\n\n\n\nThe p-value obtained from the 2-sample non-parrametric test is lower than significance level of 0.05, thus rejecting the null hypothesis that there is no difference in Science performance between genders. Specifically, Male students had a higher median than Female students, suggesting that Male students had performed better in Science.\n\n\n\n\n\n\n\n\n\nDISCUSSIONS & INSIGHTS\n\n\n\n\nUsing the above plots, differences in the distribution across both gender groups can be observed. The insights are:\n\nThe range in performances between the two genders are similar when compared within the same domain. However, across the domains, both genders had density distribution with longer upper tails for Math, while having longer lower tails for Reading. This suggests that both genders likely performed better in Math than Reading.\nIn terms of the peak frequency in the density distribution, Male students recorded peak frequencies at higher scores for both Math and Science, while being at a similar score compared to Females for Reading. This suggests that a higher proportion of Male students performed better for Math and Science, though this needs to be confirmed by CDA techniques as the ridges for the Male students are skewed left.\nThe follow-on non-parametric 2-sample tests confirmed the rejection of the null hypothesis, and suggests that there are differences in performance between the 2 genders."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#public-schools-seem-to-exhibit-higher-disparity-in-performance",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#public-schools-seem-to-exhibit-higher-disparity-in-performance",
    "title": "A Look into Singapore Students’ Performance Using PISA 2022",
    "section": "4.3 Public schools seem to exhibit higher disparity in performance",
    "text": "4.3 Public schools seem to exhibit higher disparity in performance\nHere, we use the ridge plot to plot out the density distributions of the performance proxy, i.e. the average Plausible Value for each domain, and compare the density distributions across the domains by school category, so as to see if any hypothesis or insights on possible relationship between school category and performance can be derived.\nTogether with the density ridge plot, a histogram for the average scores of schools for each of the domains was also plotted, so as to see how the public and private schools compared to each other in terms of average student performance.\nBelow are the code chunks for the data visualisation.\n\nData VizNormality test2-sample test (parametric and non-parametric)\n\n\n\n\nShow Code\nmath_ridge_2 &lt;- ggplot(sfu_qqq_SG_req, \n       aes(x = PVMATH_final,\n           y = STRATUM,\n           fill = STRATUM,\n           color = STRATUM))+\n  geom_density_ridges(bandwidth = 20,\n                      alpha = .5) +\n  labs(x = NULL,\n       y = NULL) +\n  scale_x_continuous(limits=c(100,900)) +\n  annotate(geom = \"text\",\n           x=275,\n           y=2.7,\n           label = \"Public school students \\nrecorded peak frequency at \\nhigher Math score\",\n           size = 2) +\n  annotate(geom = \"label\",\n           x=840,\n           y=3,\n           label = \"Math\",\n           size = 3) +\n  theme_minimal() +\n  theme(legend.position=\"none\",\n        axis.text = element_blank())\n\nread_ridge_2 &lt;- ggplot(sfu_qqq_SG_req, \n       aes(x = PVREAD_final,\n           y = STRATUM,\n           fill = STRATUM,\n           color = STRATUM))+\n  geom_density_ridges(bandwidth = 20,\n                      alpha = .5) +\n  labs(x = NULL,\n       y = NULL) +\n  scale_x_continuous(limits=c(100,900)) +\n  annotate(geom = \"text\",\n           x=275,\n           y=2.8,\n           label = \"Private school students \\nrecorded peak frequency at \\nhigher Reading score\",\n           size = 2) +\n  annotate(geom = \"label\",\n           x=820,\n           y=3,\n           label = \"Reading\",\n           size = 3) +\n  theme_minimal() +\n  theme(legend.position=\"none\",\n        axis.text = element_blank())\n\nscie_ridge_2 &lt;- ggplot(sfu_qqq_SG_req, \n       aes(x = PVSCIE_final,\n           y = STRATUM,\n           fill = STRATUM,\n           color = STRATUM))+\n  geom_density_ridges(bandwidth = 20,\n                      alpha = .5) +\n  labs(x = \"Score for each domain\",\n       y = NULL) +\n  scale_x_continuous(limits=c(100,900)) +\n  annotate(geom = \"text\",\n           x=275,\n           y=2.8,\n           label = \"Public and Private school \\nstudents recorded peak \\nfrequency at similar \\nScience score\",\n           size = 2) +\n  annotate(geom = \"label\",\n           x=820,\n           y=3,\n           label = \"Science\",\n           size = 3) +\n  theme_minimal() +\n  theme(legend.position=\"none\",\n        axis.text.y = element_blank(),\n        axis.title = element_text(size = 8, color = \"grey20\"))\n\n# code producing histograms\nnew_df &lt;- sfu_qqq_SG_req %&gt;% \n  select(c(\"CNTSCHID\", \"PVMATH_final\", \"PVREAD_final\", \"PVSCIE_final\", \"STRATUM\")) %&gt;% \n  group_by(sfu_qqq_SG_req$CNTSCHID, STRATUM) %&gt;% \n  summarise_at(vars(PVMATH_final, PVREAD_final, PVSCIE_final), mean)\n\nmath_hist_1 &lt;- ggplot(data = new_df,\n       aes(x = PVMATH_final,\n           fill = STRATUM)) +\n  geom_histogram(bins = 50, alpha = 0.5) +\n  labs(y = NULL,\n       x = NULL) +\n  scale_x_continuous(limits = c(300,800)) +\n  scale_y_continuous(limits = c(0,20)) +\n  theme_light() +\n  theme(legend.position = \"none\")\n\nread_hist_1 &lt;- ggplot(data = new_df,\n       aes(x = PVREAD_final,\n           fill = STRATUM)) +\n  geom_histogram(bins = 50, alpha = 0.5) +\n  labs(y = \"Count of schools\",\n       x = NULL) +\n  scale_x_continuous(limits = c(300,800)) +\n  scale_y_continuous(limits = c(0,20)) +\n  theme_light() +\n  theme(legend.position = \"none\",\n        axis.title = element_text(size = 8, color = \"grey20\"))\n\nscie_hist_1 &lt;- ggplot(data = new_df,\n       aes(x = PVSCIE_final,\n           fill = STRATUM)) +\n  geom_histogram(bins = 50, alpha = 0.5) +\n  labs(y = NULL,\n       x = \"Ave score of individual school\") +\n  scale_x_continuous(limits = c(300,800)) +\n  scale_y_continuous(limits = c(0,20)) +\n  theme_light() +\n  theme(legend.title=element_blank(),\n        legend.text = element_text(size = 6),\n        legend.position = \"left\",\n        axis.title = element_text(size = 8, color = \"grey20\"))\n\nfig3 &lt;- (math_ridge_2 / read_ridge_2 / scie_ridge_2) | (math_hist_1 / read_hist_1 / scie_hist_1)\n\nfig3 +\n  plot_annotation(title = \"Do all schools perform equally well?\", subtitle = \"Private schools appear to have an edge over Public schools\")\n\n\n\n\n\n\n\nBelow code chunks are used to plot the performances for the 3 domains by school category on Q-Q plots.\nFor the normality test at 95% confidence interval, we hypothesize that:\n\nH0 = The performance of students in the 3 domains, grouped by school category, are normally distributed\nH1 = The underlying distributions are not normally distributed\n\nVisually, the points can be observed to be deviating from the normal line, hence the implication is that the underlying distributions might not be normal.\n\n\nShow code\nqq_school_math &lt;- ggplot(data = sfu_qqq_SG_req,\n      mapping = aes(sample = PVMATH_final,\n                    fill = STRATUM)) +\n  stat_qq_band(alpha=0.15) +\n  stat_qq_line(alpha=0.15) +\n  stat_qq_point(size=0.5) +\n  facet_wrap(~STRATUM,\n             nrow = 1) +\n  labs(title = \"Q-Q plot for Math \\nby school category\") +\n  theme_linedraw() +\n  theme(legend.position = \"none\",\n        axis.text = element_blank(),\n        axis.title = element_blank(),\n        axis.ticks = element_blank(),\n        plot.background = element_rect(),\n        panel.grid = element_blank())\n\nqq_school_read &lt;- ggplot(data = sfu_qqq_SG_req,\n      mapping = aes(sample = PVREAD_final,\n                    fill = STRATUM)) +\n  stat_qq_band(alpha=0.15) +\n  stat_qq_line(alpha=0.15) +\n  stat_qq_point(size=0.5) +\n  facet_wrap(~STRATUM,\n             nrow = 1) +\n  labs(title = \"Q-Q plot for Reading \\nby school category\") +\n  theme_linedraw() +\n  theme(legend.position = \"none\",\n        axis.text = element_blank(),\n        axis.title = element_blank(),\n        axis.ticks = element_blank(),\n        plot.background = element_rect(),\n        panel.grid = element_blank())\n\nqq_school_scie &lt;- ggplot(data = sfu_qqq_SG_req,\n      mapping = aes(sample = PVSCIE_final,\n                    fill = STRATUM)) +\n  stat_qq_band(alpha=0.15) +\n  stat_qq_line(alpha=0.15) +\n  stat_qq_point(size=0.5) +\n  facet_wrap(~STRATUM,\n             nrow = 1) +\n  labs(title = \"Q-Q plot for Science \\nby school category\") +\n  theme_linedraw() +\n  theme(legend.position = \"none\",\n        axis.text = element_blank(),\n        axis.title = element_blank(),\n        axis.ticks = element_blank(),\n        plot.background = element_rect(),\n        panel.grid = element_blank())\n\nqq_school_math | qq_school_read | qq_school_scie\n\n\n\n\n\nThe Shapiro-Wilk test for normality was used to test and confirm the visual observations above. However, as the number of samples for “Public Sch” is larger than 5000 (more than 6000), we will conduct the Shapiro-Wilk test for the “Private Sch” distribution, while assuming that that for the “Public Sch” are approximately normal (since sample size is large). Consequently, the choice of the subsequent 2-sample test will be dependent on whether the distribution for “Private Sch” students are normally distributed.\nThe code chunks below details outcome of the tests.\n\n\nShow Code\nmath_sw_sch &lt;- sfu_qqq_SG_req %&gt;% \n  group_by(STRATUM) %&gt;%\n  filter(STRATUM == \"Private Sch\") %&gt;% \n  shapiro_test(PVMATH_final)\n\nread_sw_sch &lt;- sfu_qqq_SG_req %&gt;% \n  group_by(STRATUM) %&gt;%\n  filter(STRATUM == \"Private Sch\") %&gt;% \n  shapiro_test(PVREAD_final)\n\nscie_sw_sch &lt;- sfu_qqq_SG_req %&gt;% \n  group_by(STRATUM) %&gt;%\n  filter(STRATUM == \"Private Sch\") %&gt;% \n  shapiro_test(PVSCIE_final)\n\ncombined_sw_sch &lt;- rbind(math_sw_sch, read_sw_sch, scie_sw_sch)\n\ndatatable(data = combined_sw_sch,\n          rownames = FALSE,\n          options = list(dom = c(\"t\")),\n          style = \"bootstrap\",\n          caption = \"Table showing Shapiro-Wilk normality test results\")\n\n\n\n\n\n\n\nSince the p-value for the distributions of Reading and Science performance are lower than the significance level of 0.05 (taking a 95% confidence level), we reject the null hypothesis (H0) that the underlying distributions are normally distributed, while we fail to reject the hypothesis that the distribution for Math performance of Private Sch students are normal as the p-value obtained is 0.202 (greater than significance level of 0.05).\nThe implication is that a non-parametric test will be used in subsequent analysis for Reading and Science, while a parametric test will be used for Math, to test if there is any significant statistical difference in the student’s performance in the three domains according to their school category.\n\n\nHere, we use either the parametric Welch t-test or the non-parametric Wilcoxon rank-sum test with the following pairs of hypotheses using 95% confidence level. The ggbetweenstats function of ggstatsplot package is used for the test, as well as showing the outcome in a visual plot.\nHypothesis 1:\n\nH0 = There is no difference in the mean Math performance of Singapore students in different category.\nH1 = There is a difference in the mean Math performance of Singapore students.\n\n\n\nShow Code\nggbetweenstats(data = sfu_qqq_SG_req,\n               x = STRATUM,\n               y = PVMATH_final,\n               type = \"parametric\",\n               conf.level = 0.95,\n               ylab = \"Math score\",\n               xlab = \"School Category\",\n               title = \"2 sample parametric test on Math score by school category\") +\n  scale_color_manual(values = c(\"palegreen\", \"pink\", \"black\")) +\n  theme_bw() +\n  theme(legend.position = \"none\")\n\n\n\n\n\nThe p-value obtained from the 2-sample t-test is lower than significance level of 0.05, thus rejecting the null hypothesis that there is no difference in Math performance between school categories. Specifically, private school students had a higher mean than public school students, suggesting that private school students had performed better in Math.\nHypothesis 2:\n\nH0 = There is no difference in the median Reading performance of Singapore students by school category.\nH1 = There is a difference in the median Reading performance of Singapore students.\n\n\n\nShow Code\nggbetweenstats(data = sfu_qqq_SG_req,\n               x = STRATUM,\n               y = PVREAD_final,\n               type = \"nonparametric\",\n               conf.level = 0.95,\n               ylab = \"Reading score\",\n               xlab = \"School Category\",\n               title = \"2 sample non-parametric test on Reading score by school category\") +\n  scale_color_manual(values = c(\"palegreen\", \"pink\", \"black\")) +\n  theme_bw() +\n  theme(legend.position = \"none\")\n\n\n\n\n\nThe p-value obtained from the 2-sample non-parametric test is lower than significance level of 0.05, thus rejecting the null hypothesis that there is no difference in Reading performance between school categories. Specifically, private school students had a higher median than public school students, suggesting that private school students had performed better in Reading.\nHypothesis 3:\n\nH0 = There is no difference in the median Science performance of Singapore students in different school category.\nH1 = There is a difference in the median Science performance of Singapore students.\n\n\n\nShow Code\nggbetweenstats(data = sfu_qqq_SG_req,\n               x = STRATUM,\n               y = PVSCIE_final,\n               type = \"nonparametric\",\n               conf.level = 0.95,\n               ylab = \"Science score\",\n               xlab = \"School Category\",\n               title = \"2 sample non-parametric test on Reading score by school category\") +\n  scale_color_manual(values = c(\"palegreen\", \"pink\", \"black\")) +\n  theme_bw() +\n  theme(legend.position = \"none\")\n\n\n\n\n\nThe p-value obtained from the 2-sample non-parametric test is lower than significance level of 0.05, thus rejecting the null hypothesis that there is no difference in Science performance between school categories. Specifically, private school students had a higher median than public school students, suggesting that private school students had performed better in Science.\n\n\n\n\n\n\n\n\n\nDISCUSSIONS & INSIGHTS\n\n\n\n\nUsing the above plots, differences in the distributions across school categories were analysed. The insights are:\n\nThe density ridges for private schools generally has steeper slopes as compared to public schools. From this, we can infer that the differences in performance of public schools varies more, i.e. public schools’ performance are less “equal” than that of private schools.\nIn terms of the peak frequency in the density distribution, private school students recorded peak frequencies at lower score for Math, at higher score for Reading and at similar score for Science. Subsequent CDA techniques was used to confirm the observations.\nFrom the histogram plots, it was also observed that the range of school average scores is smaller in private schools than in public schools, suggesting that performance among private schools could be more consistent.\nThe follow-on 2-sample tests confirmed the rejection of the null hypothesis, and suggests that private school students had better performance in all three domains, contrary to what EDA had initially suggested."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#positive-correlation-between-performance-and-socioeconomic-status",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#positive-correlation-between-performance-and-socioeconomic-status",
    "title": "A Look into Singapore Students’ Performance Using PISA 2022",
    "section": "4.4 Positive correlation between performance and socioeconomic status",
    "text": "4.4 Positive correlation between performance and socioeconomic status\nNext, we use scatter plots to visualise correlations between the performance proxy, i.e. the average Plausible Value for each domain, and the socioeconomic status (measured by ESCS index by OECD PISA), so as to see if any hypothesis or insights on possible relationship between socioeconomic status and performance can be derived.\nBelow are the code chunks for the data visualisation.\n\n\nShow Code\n# Code for computing correlation coefficient\n\nmath_corr &lt;- cor.test(x=sfu_qqq_SG_req$PVMATH_final,\n         y=sfu_qqq_SG_req$ESCS,\n         method=\"pearson\")\n\nmath_annotate &lt;- paste(\"r = \", as.character(round(math_corr$estimate,3)), \"\\np-value = \", as.character(math_corr$p.value))\n\nread_corr &lt;- cor.test(x=sfu_qqq_SG_req$PVREAD_final,\n         y=sfu_qqq_SG_req$ESCS,\n         method=\"pearson\")\n\nread_annotate &lt;- paste(\"r = \", as.character(round(read_corr$estimate,3)), \"\\np-value = \", as.character(read_corr$p.value))\n\nscie_corr &lt;- cor.test(x=sfu_qqq_SG_req$PVSCIE_final,\n         y=sfu_qqq_SG_req$ESCS,\n         method=\"pearson\")\n\nscie_annotate &lt;- paste(\"r = \", as.character(round(scie_corr$estimate,3)), \"\\np-value = \", as.character(scie_corr$p.value))\n\n# actual plots start here\nmath_scatter &lt;- ggplot(data = sfu_qqq_SG_req,\n                       aes(x = PVMATH_final,\n                           y = ESCS)) +\n  geom_point(size = 0.8,\n             alpha = 0.3,\n             color = \"violet\") +\n  geom_smooth(method = lm, linewidth = 0.5, formula = y~x) +\n  scale_x_continuous(limits = c(100,900)) + \n  labs(x = \"Math score\",\n       y = \"Socioeconomic index (ESCS)\") +\n  annotate(geom = \"label\", \n           x = 500, \n           y = 3.25, \n           label = math_annotate,\n           size = 2,\n           color = \"brown\",\n           fill = \"lightyellow\") +\n  theme_light()\n\nread_scatter &lt;- ggplot(data = sfu_qqq_SG_req,\n                       aes(x = PVREAD_final,\n                           y = ESCS)) +\n  geom_point(size = 0.8,\n             alpha = 0.3,\n             color = \"salmon\") +\n  geom_smooth(method = lm, linewidth = 0.5, formula = y~x) +\n  scale_x_continuous(limits = c(100,900)) + \n  labs(x = \"Reading score\",\n       y = NULL) +\n  annotate(geom = \"label\", \n           x = 500, \n           y = 3.25, \n           label = read_annotate,\n           size = 2,\n           color = \"brown\",\n           fill = \"lightyellow\") +\n  theme_light()\n\nscie_scatter &lt;- ggplot(data = sfu_qqq_SG_req,\n                       aes(x = PVSCIE_final,\n                           y = ESCS)) +\n  geom_point(size = 0.8,\n             alpha = 0.3,\n             color = \"palegreen\") +\n  geom_smooth(method = lm, linewidth = 0.5, formula = y~x) +\n  scale_x_continuous(limits = c(100,900)) + \n  labs(x = \"Science score\",\n       y = NULL) +\n  annotate(geom = \"label\", \n           x = 500, \n           y = 3.25, \n           label = scie_annotate,\n           size = 2,\n           color = \"brown\",\n           fill = \"lightyellow\") +\n  theme_light()\n\nfig4 &lt;- math_scatter | read_scatter | scie_scatter\n\nfig4 +\n  plot_annotation(title = \"Student performance increases with socioeconomic status\",\n                  subtitle = \"Performance for all domains are positively correlated with socioeconomic status, \\nindicating that family's financial ability likely affects student's performance\")\n\n\n\n\n\n\n\n\n\n\n\nDISCUSSIONS & INSIGHTS\n\n\n\n\nUsing the above plots, possible relationships between socioeconomic status and performance were analysed. The insights are:\n\nAll 3 scatter plots suggests the possibility of positive correlation between socioeconomic status and performance. However, there are also many points on the plots which are far away from the best fit line, suggesting that the fit may not be that good. As such, a correlation test was done to analyse the correlation.\nIn all 3 plots, further observations are:\n\nThe dots are more dense at the top right hand portion of the individual plots, suggesting that higher performance students generally had higher socioeconomic statuses.\nThere are more outliers at the bottom of the plots, suggesting the existence of some students with low socioeconomic statuses having performed relatively well for the three domains.\n\nA correlation test performed confirmed that the correlation coefficients between socioeconomic status and performance for all three domains were approx. 0.44."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#a-look-into-the-details-in-relationship-between-performance-and-components-of-socioeconomic-status",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#a-look-into-the-details-in-relationship-between-performance-and-components-of-socioeconomic-status",
    "title": "A Look into Singapore Students’ Performance Using PISA 2022",
    "section": "4.5 A look into the details in relationship between performance and components of socioeconomic status",
    "text": "4.5 A look into the details in relationship between performance and components of socioeconomic status\nFinally, we use multiple trellis box plots to investigate into the possible relations between the performance levels, obtained by mapping the average Plausible Value for each domain to performance scales defined by PISA, and the individual components breakdown (i.e. occupation, education and home possessions of parents) of the ESCS index, so as to see if there could be any dominating components that could explain for the observations in 4.4.\nBelow are the code chunks for the data visualisation.\n\n\nShow Code\n#HISEI index\nmath_level_h &lt;- ggplot(data=sfu_qqq_SG_req,\n       aes(x=MATH_level,\n           y=HISEI)) + \n  geom_boxplot(outlier.size = 0.8, \n               outlier.alpha = 0.6, \n               outlier.color = \"blue\",\n               fill = \"lightblue\") + \n  stat_summary(geom = \"point\",\n               fun.y = \"mean\",\n               color = \"salmon\",\n               size = 1) +\n  labs(x = \"Math \\nperformance\",\n       y = NULL) +\n  theme_light() + \n  coord_flip() +\n  theme(axis.text.x = element_blank(),\n        axis.title.y = element_text(size = 9, color = \"grey20\"))\n\nread_level_h &lt;- ggplot(data=sfu_qqq_SG_req,\n       aes(x=READ_level,\n           y=HISEI)) + \n  geom_boxplot(outlier.size = 0.8, \n               outlier.alpha = 0.6, \n               outlier.color = \"blue\",\n               fill = \"lightblue\") + \n  stat_summary(geom = \"point\",\n               fun.y = \"mean\",\n               color = \"salmon\",\n               size = 1) +\n  labs(x = \"Reading \\nperformance\",\n       y = NULL) +\n  theme_light() + \n  coord_flip() +\n  theme(axis.text.x = element_blank(),\n        axis.title.y = element_text(size = 9, color = \"grey20\"))\n\nscie_level_h &lt;- ggplot(data=sfu_qqq_SG_req,\n       aes(x=SCIE_level,\n           y=HISEI)) + \n  geom_boxplot(outlier.size = 0.8, \n               outlier.alpha = 0.6, \n               outlier.color = \"blue\",\n               fill = \"lightblue\") + \n  stat_summary(geom = \"point\",\n               fun.y = \"mean\",\n               color = \"salmon\",\n               size = 1) +\n  labs(x = \"Science \\nperformance\",\n       y = \"Parent \\noccupation index\") +\n  theme_light() + \n  coord_flip() +\n  theme(axis.title.x = element_text(size = 9, color = \"grey20\"),\n        axis.title.y = element_text(size = 9, color = \"grey20\"))\n\n# PAREDINT index\nmath_level_p &lt;- ggplot(data=sfu_qqq_SG_req,\n       aes(x=MATH_level,\n           y=PAREDINT)) + \n  geom_boxplot(outlier.size = 0.8, \n               outlier.alpha = 0.6, \n               outlier.color = \"black\",\n               fill = \"lightblue\") + \n  stat_summary(geom = \"point\",\n               fun.y = \"mean\",\n               color = \"salmon\",\n               size = 1) +\n  labs(x = NULL,\n       y = NULL) +\n  theme_light() + \n  coord_flip() +\n  theme(axis.text.x = element_blank(),\n        axis.text.y = element_blank())\n\nread_level_p &lt;- ggplot(data=sfu_qqq_SG_req,\n       aes(x=READ_level,\n           y=PAREDINT)) + \n  geom_boxplot(outlier.size = 0.8, \n               outlier.alpha = 0.6, \n               outlier.color = \"black\",\n               fill = \"lightblue\") + \n  stat_summary(geom = \"point\",\n               fun.y = \"mean\",\n               color = \"salmon\",\n               size = 1) +\n  labs(x = NULL,\n       y = NULL) +\n  theme_light() + \n  coord_flip() +\n  theme(axis.text.x = element_blank(),\n        axis.text.y = element_blank())\n\nscie_level_p &lt;- ggplot(data=sfu_qqq_SG_req,\n       aes(x=SCIE_level,\n           y=PAREDINT)) + \n  geom_boxplot(outlier.size = 0.8, \n               outlier.alpha = 0.6, \n               outlier.color = \"black\",\n               fill = \"lightblue\") + \n  stat_summary(geom = \"point\",\n               fun.y = \"mean\",\n               color = \"salmon\",\n               size = 1) +\n  labs(x = NULL,\n       y = \"Highest parent \\neducation in years\") +\n  theme_light() + \n  coord_flip() +\n  theme(axis.text.y = element_blank(),\n        axis.title.x = element_text(size = 9, color = \"grey20\"))\n\n# HOMEPOS index\nmath_level_home &lt;- ggplot(data=sfu_qqq_SG_req,\n       aes(x=MATH_level,\n           y=HOMEPOS)) + \n  geom_boxplot(outlier.size = 0.8, \n               outlier.alpha = 0.6, \n               outlier.color = \"red\",\n               fill = \"lightblue\") + \n  stat_summary(geom = \"point\",\n               fun.y = \"mean\",\n               color = \"salmon\",\n               size = 1) +\n  labs(x = NULL,\n       y = NULL) +\n  theme_light() + \n  coord_flip() +\n  theme(axis.text.x = element_blank(),\n        axis.text.y = element_blank())\n\nread_level_home &lt;- ggplot(data=sfu_qqq_SG_req,\n       aes(x=READ_level,\n           y=HOMEPOS)) + \n  geom_boxplot(outlier.size = 0.8, \n               outlier.alpha = 0.6, \n               outlier.color = \"red\",\n               fill = \"lightblue\") + \n  stat_summary(geom = \"point\",\n               fun.y = \"mean\",\n               color = \"salmon\",\n               size = 1) +\n  labs(x = NULL,\n       y = NULL) +\n  theme_light() + \n  coord_flip() +\n  theme(axis.text.x = element_blank(),\n        axis.text.y = element_blank())\n\nscie_level_home &lt;- ggplot(data=sfu_qqq_SG_req,\n       aes(x=SCIE_level,\n           y=HOMEPOS)) + \n  geom_boxplot(outlier.size = 0.8, \n               outlier.alpha = 0.6, \n               outlier.color = \"red\",\n               fill = \"lightblue\") + \n  stat_summary(geom = \"point\",\n               fun.y = \"mean\",\n               color = \"salmon\",\n               size = 1) +\n  labs(x = NULL,\n       y = \"Home possessions\") +\n  theme_light() + \n  coord_flip() +\n  theme(axis.text.y = element_blank(),\n        axis.title.x = element_text(size = 9, color = \"grey20\"))\n\nfig5 &lt;- (math_level_h / read_level_h / scie_level_h) | (math_level_p / read_level_p / scie_level_p) | (math_level_home / read_level_home / scie_level_home)\n\nfig5 + \n  plot_annotation(title = \"Breakdown by Socioeconomic Components\", subtitle = \"Plots reveal detailed insights: Parents' occupation and home possessions likely the key contributors \\nbehind the correlation between performance and socioeconomic status\")\n\n\n\n\n\n\n\n\n\n\n\nDISCUSSIONS & INSIGHTS\n\n\n\n\nUsing the above plots, possible relationships between performance and the components of ESCS index were analysed. The insights are:\n\nParent occupation index:\n\nThe means and medians generally increases as performance level increases, with an outlier observed for Science, whereby there was a low performer with high parent occupation index. Despite so, as this is an isolated data point, this could be a rare exception.\n\nParent education (in years):\n\nThough the means generally increase slightly with increase in performance, the relationship might not be so clear in this case as the boxplots are mostly overlapping.\n\nHome possessions:\n\nThe means and medians generally increases as performance level increase. However, the existence of many outliers makes this observation less certain.\n\n\nPutting the above observations together, it can be inferred that the more likely contributors behind the correlation identified in 4.4 to be due to parents’ occupation and home possessions, and less by parents’ education."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#loading-r-packages",
    "href": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#loading-r-packages",
    "title": "In-class Exercise 1: Now You See It!",
    "section": "Loading R packages",
    "text": "Loading R packages\nIn this hands-on exercise, two R packages will be used. They are:\n\ntidyverse, and\nhaven\n\nThe code chunk used is as follows:\n\npacman::p_load(tidyverse, haven)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#importing-pisa-data",
    "href": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#importing-pisa-data",
    "title": "In-class Exercise 1: Now You See It!",
    "section": "Importing PISA data",
    "text": "Importing PISA data\nThe code chunk below uses read_sas() of haven to import PISA data into R environment.\n\nstu_qqq &lt;- read_sas(\"data/cy08msp_stu_qqq.sas7bdat\")\n\n\nstu_qqq_SG &lt;- stu_qqq %&gt;%\n  filter(CNT == \"SGP\") \n\n\nwrite_rds(stu_qqq_SG,\n          \"data/stu_qqq_SG.rds\")\n\n\nsfu_qqq_SG &lt;- read_rds(\"data/stu_qqq_SG.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07b/Hands-on_Ex07b.html",
    "href": "Hands-on_Ex/Hands-on_Ex07b/Hands-on_Ex07b.html",
    "title": "Hands-on Exercise 7b",
    "section": "",
    "text": "Proportional symbol maps (also known as graduate symbol maps) are a class of maps that use the visual variable of size to represent differences in the magnitude of a discrete, abruptly changing phenomenon, e.g. counts of people. Like choropleth maps, you can create classed or unclassed versions of these maps. The classed ones are known as range-graded or graduated symbols, and the unclassed are called proportional symbols, where the area of the symbols are proportional to the values of the attribute being mapped. In this hands-on exercise, you will learn how to create a proportional symbol map showing the number of wins by Singapore Pools’ outlets using an R package called tmap.\n\n\nBy the end of this hands-on exercise, you will acquire the following skills by using appropriate R packages:\n\nTo import an aspatial data file into R.\nTo convert it into simple point feature data frame and at the same time, to assign an appropriate projection reference to the newly create simple point feature data frame.\nTo plot interactive proportional symbol maps.\n\n\n\n\nBefore we get started, we need to ensure that tmap package of R and other related R packages have been installed and loaded into R.\n\npacman::p_load(sf, tmap, tidyverse)\n\n\n\n\n\n\n\nThe data set use for this hands-on exercise is called SGPools_svy21. The data is in csv file format.\nFigure below shows the first 15 records of SGPools_svy21.csv. It consists of seven columns. The XCOORD and YCOORD columns are the x-coordinates and y-coordinates of SingPools outlets and branches. They are in Singapore SVY21 Projected Coordinates System.\n\n\n\n\nThe code chunk below uses read_csv() function of readr package to import SGPools_svy21.csv into R as a tibble data frame called sgpools.\n\nsgpools &lt;- read_csv(\"data/aspatial/SGPools_svy21.csv\")\n\nAfter importing the data file into R, it is important for us to examine if the data file has been imported correctly.\nThe code chunk below shows list() is used to do the job.\n\nlist(sgpools) \n\n[[1]]\n# A tibble: 306 × 7\n   NAME           ADDRESS POSTCODE XCOORD YCOORD `OUTLET TYPE` `Gp1Gp2 Winnings`\n   &lt;chr&gt;          &lt;chr&gt;      &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;                     &lt;dbl&gt;\n 1 Livewire (Mar… 2 Bayf…    18972 30842. 29599. Branch                        5\n 2 Livewire (Res… 26 Sen…    98138 26704. 26526. Branch                       11\n 3 SportsBuzz (K… Lotus …   738078 20118. 44888. Branch                        0\n 4 SportsBuzz (P… 1 Sele…   188306 29777. 31382. Branch                       44\n 5 Prime Serango… Blk 54…   552542 32239. 39519. Branch                        0\n 6 Singapore Poo… 1A Woo…   731001 21012. 46987. Branch                        3\n 7 Singapore Poo… Blk 64…   370064 33990. 34356. Branch                       17\n 8 Singapore Poo… Blk 88…   370088 33847. 33976. Branch                       16\n 9 Singapore Poo… Blk 30…   540308 33910. 41275. Branch                       21\n10 Singapore Poo… Blk 20…   560202 29246. 38943. Branch                       25\n# ℹ 296 more rows\n\n\nNotice that the sgpools data in tibble data frame and not the common R data frame.\n\n\n\nThe code chunk below converts sgpools data frame into a simple feature data frame by using st_as_sf() of sf packages.\n\nsgpools_sf &lt;- st_as_sf(sgpools, \n                       coords = c(\"XCOORD\", \"YCOORD\"),\n                       crs= 3414)\n\nThings to learn from the arguments above:\n\nThe coords argument requires you to provide the column name of the x-coordinates first then followed by the column name of the y-coordinates.\nThe crs argument required you to provide the coordinates system in epsg format. EPSG: 3414 is Singapore SVY21 Projected Coordinate System. You can search for other country’s epsg code by refering to epsg.io.\n\nFigure below shows the data table of sgpools_sf. Notice that a new column called geometry has been added into the data frame.\n\nYou can display the basic information of the newly created sgpools_sf by using the code chunk below.\n\nlist(sgpools_sf)\n\n[[1]]\nSimple feature collection with 306 features and 5 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 7844.194 ymin: 26525.7 xmax: 45176.57 ymax: 47987.13\nProjected CRS: SVY21 / Singapore TM\n# A tibble: 306 × 6\n   NAME                         ADDRESS POSTCODE `OUTLET TYPE` `Gp1Gp2 Winnings`\n * &lt;chr&gt;                        &lt;chr&gt;      &lt;dbl&gt; &lt;chr&gt;                     &lt;dbl&gt;\n 1 Livewire (Marina Bay Sands)  2 Bayf…    18972 Branch                        5\n 2 Livewire (Resorts World Sen… 26 Sen…    98138 Branch                       11\n 3 SportsBuzz (Kranji)          Lotus …   738078 Branch                        0\n 4 SportsBuzz (PoMo)            1 Sele…   188306 Branch                       44\n 5 Prime Serangoon North        Blk 54…   552542 Branch                        0\n 6 Singapore Pools Woodlands C… 1A Woo…   731001 Branch                        3\n 7 Singapore Pools 64 Circuit … Blk 64…   370064 Branch                       17\n 8 Singapore Pools 88 Circuit … Blk 88…   370088 Branch                       16\n 9 Singapore Pools Anchorvale … Blk 30…   540308 Branch                       21\n10 Singapore Pools Ang Mo Kio … Blk 20…   560202 Branch                       25\n# ℹ 296 more rows\n# ℹ 1 more variable: geometry &lt;POINT [m]&gt;\n\n\nThe output shows that sgppols_sf is in point feature class. It’s epsg ID is 3414. The bbox provides information of the extend of the geospatial data.\n\n\n\n\nTo create an interactive proportional symbol map in R, the view mode of tmap will be used.\nThe code churn below will turn on the interactive mode of tmap.\n\ntmap_mode(\"view\")\n\n\n\nThe code chunks below are used to create an interactive point symbol map.\n\ntm_shape(sgpools_sf)+\ntm_bubbles(col = \"red\",\n           size = 0.6,\n           border.col = \"black\",\n           border.lwd = 0.8,\n           alpha = 0.6)\n\n\n\n\n\n\n\n\n\nTo draw a proportional symbol map, we need to assign a numerical variable to the size visual attribute. The code chunks below show that the variable Gp1Gp2Winnings is assigned to size visual attribute.\n\ntm_shape(sgpools_sf)+\ntm_bubbles(col = \"red\",\n           size = \"Gp1Gp2 Winnings\",\n           border.col = \"black\",\n           border.lwd = 0.8,\n           alpha = 0.6)\n\n\n\n\n\n\n\n\n\nThe proportional symbol map can be further improved by using the colour visual attribute. In the code chunks below, OUTLET_TYPE variable is used as the colour attribute variable.\n\ntm_shape(sgpools_sf)+\ntm_bubbles(col = \"OUTLET TYPE\", \n          size = \"Gp1Gp2 Winnings\",\n          border.col = \"black\",\n          border.lwd = 0.8,\n          alpha = 0.6)\n\n\n\n\n\n\n\n\n\nAn impressive and little-know feature of tmap’s view mode is that it also works with faceted plots. The argument sync in tm_facets() can be used in this case to produce multiple maps with synchronised zoom and pan settings.\n\ntm_shape(sgpools_sf)+\ntm_bubbles(col = \"OUTLET TYPE\", \n          size = \"Gp1Gp2 Winnings\",\n          border.col = \"black\",\n          border.lwd = 0.8,\n          alpha = 0.6) +\n  tm_facets(by = \"OUTLET TYPE\",\n            nrow=1,\n            sync=T)\n\n\n\n\n\n\n\n\n\n\n\n\n\nBefore you end the session, it is wiser to switch tmap’s Viewer back to plot mode by using the code chunk below.\n\ntmap_mode(\"plot\")\n\n\n\n\n\n\n\n\n\ntmap: Thematic Maps in R\ntmap\ntmap: get started!\ntmap: changes in version 2.0\ntmap: creating thematic maps in a flexible way (useR!2015)\nExploring and presenting maps with tmap (useR!2017)\n\n\n\n\n\nsf: Simple Features for R\nSimple Features for R: StandardizedSupport for Spatial Vector Data\nReading, Writing and Converting Simple Features\n\n\n\n\n\ndplyr\nTidy data\ntidyr: Easily Tidy Data with ‘spread()’ and ‘gather()’ Functions"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07b/Hands-on_Ex07b.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex07b/Hands-on_Ex07b.html#overview",
    "title": "Hands-on Exercise 7b",
    "section": "",
    "text": "Proportional symbol maps (also known as graduate symbol maps) are a class of maps that use the visual variable of size to represent differences in the magnitude of a discrete, abruptly changing phenomenon, e.g. counts of people. Like choropleth maps, you can create classed or unclassed versions of these maps. The classed ones are known as range-graded or graduated symbols, and the unclassed are called proportional symbols, where the area of the symbols are proportional to the values of the attribute being mapped. In this hands-on exercise, you will learn how to create a proportional symbol map showing the number of wins by Singapore Pools’ outlets using an R package called tmap.\n\n\nBy the end of this hands-on exercise, you will acquire the following skills by using appropriate R packages:\n\nTo import an aspatial data file into R.\nTo convert it into simple point feature data frame and at the same time, to assign an appropriate projection reference to the newly create simple point feature data frame.\nTo plot interactive proportional symbol maps.\n\n\n\n\nBefore we get started, we need to ensure that tmap package of R and other related R packages have been installed and loaded into R.\n\npacman::p_load(sf, tmap, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07b/Hands-on_Ex07b.html#geospatial-data-wrangling",
    "href": "Hands-on_Ex/Hands-on_Ex07b/Hands-on_Ex07b.html#geospatial-data-wrangling",
    "title": "Hands-on Exercise 7b",
    "section": "",
    "text": "The data set use for this hands-on exercise is called SGPools_svy21. The data is in csv file format.\nFigure below shows the first 15 records of SGPools_svy21.csv. It consists of seven columns. The XCOORD and YCOORD columns are the x-coordinates and y-coordinates of SingPools outlets and branches. They are in Singapore SVY21 Projected Coordinates System.\n\n\n\n\nThe code chunk below uses read_csv() function of readr package to import SGPools_svy21.csv into R as a tibble data frame called sgpools.\n\nsgpools &lt;- read_csv(\"data/aspatial/SGPools_svy21.csv\")\n\nAfter importing the data file into R, it is important for us to examine if the data file has been imported correctly.\nThe code chunk below shows list() is used to do the job.\n\nlist(sgpools) \n\n[[1]]\n# A tibble: 306 × 7\n   NAME           ADDRESS POSTCODE XCOORD YCOORD `OUTLET TYPE` `Gp1Gp2 Winnings`\n   &lt;chr&gt;          &lt;chr&gt;      &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;                     &lt;dbl&gt;\n 1 Livewire (Mar… 2 Bayf…    18972 30842. 29599. Branch                        5\n 2 Livewire (Res… 26 Sen…    98138 26704. 26526. Branch                       11\n 3 SportsBuzz (K… Lotus …   738078 20118. 44888. Branch                        0\n 4 SportsBuzz (P… 1 Sele…   188306 29777. 31382. Branch                       44\n 5 Prime Serango… Blk 54…   552542 32239. 39519. Branch                        0\n 6 Singapore Poo… 1A Woo…   731001 21012. 46987. Branch                        3\n 7 Singapore Poo… Blk 64…   370064 33990. 34356. Branch                       17\n 8 Singapore Poo… Blk 88…   370088 33847. 33976. Branch                       16\n 9 Singapore Poo… Blk 30…   540308 33910. 41275. Branch                       21\n10 Singapore Poo… Blk 20…   560202 29246. 38943. Branch                       25\n# ℹ 296 more rows\n\n\nNotice that the sgpools data in tibble data frame and not the common R data frame.\n\n\n\nThe code chunk below converts sgpools data frame into a simple feature data frame by using st_as_sf() of sf packages.\n\nsgpools_sf &lt;- st_as_sf(sgpools, \n                       coords = c(\"XCOORD\", \"YCOORD\"),\n                       crs= 3414)\n\nThings to learn from the arguments above:\n\nThe coords argument requires you to provide the column name of the x-coordinates first then followed by the column name of the y-coordinates.\nThe crs argument required you to provide the coordinates system in epsg format. EPSG: 3414 is Singapore SVY21 Projected Coordinate System. You can search for other country’s epsg code by refering to epsg.io.\n\nFigure below shows the data table of sgpools_sf. Notice that a new column called geometry has been added into the data frame.\n\nYou can display the basic information of the newly created sgpools_sf by using the code chunk below.\n\nlist(sgpools_sf)\n\n[[1]]\nSimple feature collection with 306 features and 5 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 7844.194 ymin: 26525.7 xmax: 45176.57 ymax: 47987.13\nProjected CRS: SVY21 / Singapore TM\n# A tibble: 306 × 6\n   NAME                         ADDRESS POSTCODE `OUTLET TYPE` `Gp1Gp2 Winnings`\n * &lt;chr&gt;                        &lt;chr&gt;      &lt;dbl&gt; &lt;chr&gt;                     &lt;dbl&gt;\n 1 Livewire (Marina Bay Sands)  2 Bayf…    18972 Branch                        5\n 2 Livewire (Resorts World Sen… 26 Sen…    98138 Branch                       11\n 3 SportsBuzz (Kranji)          Lotus …   738078 Branch                        0\n 4 SportsBuzz (PoMo)            1 Sele…   188306 Branch                       44\n 5 Prime Serangoon North        Blk 54…   552542 Branch                        0\n 6 Singapore Pools Woodlands C… 1A Woo…   731001 Branch                        3\n 7 Singapore Pools 64 Circuit … Blk 64…   370064 Branch                       17\n 8 Singapore Pools 88 Circuit … Blk 88…   370088 Branch                       16\n 9 Singapore Pools Anchorvale … Blk 30…   540308 Branch                       21\n10 Singapore Pools Ang Mo Kio … Blk 20…   560202 Branch                       25\n# ℹ 296 more rows\n# ℹ 1 more variable: geometry &lt;POINT [m]&gt;\n\n\nThe output shows that sgppols_sf is in point feature class. It’s epsg ID is 3414. The bbox provides information of the extend of the geospatial data."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07b/Hands-on_Ex07b.html#drawing-proportional-symbol-map",
    "href": "Hands-on_Ex/Hands-on_Ex07b/Hands-on_Ex07b.html#drawing-proportional-symbol-map",
    "title": "Hands-on Exercise 7b",
    "section": "",
    "text": "To create an interactive proportional symbol map in R, the view mode of tmap will be used.\nThe code churn below will turn on the interactive mode of tmap.\n\ntmap_mode(\"view\")\n\n\n\nThe code chunks below are used to create an interactive point symbol map.\n\ntm_shape(sgpools_sf)+\ntm_bubbles(col = \"red\",\n           size = 0.6,\n           border.col = \"black\",\n           border.lwd = 0.8,\n           alpha = 0.6)\n\n\n\n\n\n\n\n\n\nTo draw a proportional symbol map, we need to assign a numerical variable to the size visual attribute. The code chunks below show that the variable Gp1Gp2Winnings is assigned to size visual attribute.\n\ntm_shape(sgpools_sf)+\ntm_bubbles(col = \"red\",\n           size = \"Gp1Gp2 Winnings\",\n           border.col = \"black\",\n           border.lwd = 0.8,\n           alpha = 0.6)\n\n\n\n\n\n\n\n\n\nThe proportional symbol map can be further improved by using the colour visual attribute. In the code chunks below, OUTLET_TYPE variable is used as the colour attribute variable.\n\ntm_shape(sgpools_sf)+\ntm_bubbles(col = \"OUTLET TYPE\", \n          size = \"Gp1Gp2 Winnings\",\n          border.col = \"black\",\n          border.lwd = 0.8,\n          alpha = 0.6)\n\n\n\n\n\n\n\n\n\nAn impressive and little-know feature of tmap’s view mode is that it also works with faceted plots. The argument sync in tm_facets() can be used in this case to produce multiple maps with synchronised zoom and pan settings.\n\ntm_shape(sgpools_sf)+\ntm_bubbles(col = \"OUTLET TYPE\", \n          size = \"Gp1Gp2 Winnings\",\n          border.col = \"black\",\n          border.lwd = 0.8,\n          alpha = 0.6) +\n  tm_facets(by = \"OUTLET TYPE\",\n            nrow=1,\n            sync=T)\n\n\n\n\n\n\n\n\n\n\n\n\n\nBefore you end the session, it is wiser to switch tmap’s Viewer back to plot mode by using the code chunk below.\n\ntmap_mode(\"plot\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07b/Hands-on_Ex07b.html#all-about-tmap-package",
    "href": "Hands-on_Ex/Hands-on_Ex07b/Hands-on_Ex07b.html#all-about-tmap-package",
    "title": "Hands-on Exercise 7b",
    "section": "",
    "text": "tmap: Thematic Maps in R\ntmap\ntmap: get started!\ntmap: changes in version 2.0\ntmap: creating thematic maps in a flexible way (useR!2015)\nExploring and presenting maps with tmap (useR!2017)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07b/Hands-on_Ex07b.html#geospatial-data-wrangling-1",
    "href": "Hands-on_Ex/Hands-on_Ex07b/Hands-on_Ex07b.html#geospatial-data-wrangling-1",
    "title": "Hands-on Exercise 7b",
    "section": "",
    "text": "sf: Simple Features for R\nSimple Features for R: StandardizedSupport for Spatial Vector Data\nReading, Writing and Converting Simple Features"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07b/Hands-on_Ex07b.html#data-wrangling",
    "href": "Hands-on_Ex/Hands-on_Ex07b/Hands-on_Ex07b.html#data-wrangling",
    "title": "Hands-on Exercise 7b",
    "section": "",
    "text": "dplyr\nTidy data\ntidyr: Easily Tidy Data with ‘spread()’ and ‘gather()’ Functions"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html",
    "title": "Hands-on Exercise 6",
    "section": "",
    "text": "By the end of this hands-on exercise you will be able create the followings data visualisation by using R packages:\n\nplotting a calender heatmap by using ggplot2 functions,\nplotting a cycle plot by using ggplot2 function,\nplotting a slopegraph\nplotting a horizon chart\n\n\n\n\nWrite a code chunk to check, install and launch the following R packages: scales, viridis, lubridate, ggthemes, gridExtra, readxl, knitr, data.table and tidyverse.\n\npacman::p_load(scales, viridis, lubridate, ggthemes, gridExtra, readxl, knitr, data.table, CGPfunctions, ggHoriPlot, tidyverse)\n\n\n\n\nIn this section, you will learn how to plot a calender heatmap programmatically by using ggplot2 package.\n\nBy the end of this section, you will be able to:\n\nplot a calender heatmap by using ggplot2 functions and extension,\nto write function using R programming,\nto derive specific date and time related field by using base R and lubridate packages\nto perform data preparation task by using tidyr and dplyr packages.\n\n\n\nFor the purpose of this hands-on exercise, eventlog.csv file will be used. This data file consists of 199,999 rows of time-series cyber attack records by country.\n\n\n\nFirst, you will use the code chunk below to import eventlog.csv file into R environment and called the data frame as attacks.\n\nattacks &lt;- read_csv(\"data/eventlog.csv\")\n\n\n\n\nIt is always a good practice to examine the imported data frame before further analysis is performed.\nFor example, kable() can be used to review the structure of the imported data frame.\n\nkable(head(attacks))\n\n\n\n\ntimestamp\nsource_country\ntz\n\n\n\n\n2015-03-12 15:59:16\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:00:48\nFR\nEurope/Paris\n\n\n2015-03-12 16:02:26\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:02:38\nUS\nAmerica/Chicago\n\n\n2015-03-12 16:03:22\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:03:45\nCN\nAsia/Shanghai\n\n\n\n\n\nThere are three columns, namely timestamp, source_country and tz.\n\ntimestamp field stores date-time values in POSIXct format.\nsource_country field stores the source of the attack. It is in ISO 3166-1 alpha-2 country code.\ntz field stores time zone of the source IP address.\n\n\n\n\nStep 1: Deriving weekday and hour of day fields\nBefore we can plot the calender heatmap, two new fields namely wkday and hour need to be derived. In this step, we will write a function to perform the task.\n\nmake_hr_wkday &lt;- function(ts, sc, tz) {\n  real_times &lt;- ymd_hms(ts,\n                        tz = tz[1],\n                        quiet=T)\n  dt&lt;- data.table(source_country = sc,\n                  wkday = weekdays(real_times),\n                  hour = hour(real_times))\n  return(dt)\n}\n\n\n\n\n\n\n\nNote\n\n\n\n\nymd_hms() and hour() are from lubridate package, and\nweekdays() is a base R function.\n\n\n\nStep 2: Deriving the attacks tibble data frame\n\nwkday_levels &lt;- c('Saturday', 'Friday',\n                   'Thursday', 'Wednesday',\n                   'Tuesday', 'Monday',\n                   'Sunday')\nattacks &lt;- attacks %&gt;% \n  group_by(tz) %&gt;% \n  do(make_hr_wkday(.$timestamp,\n                   .$source_country,\n                   .$tz)) %&gt;% \n  ungroup() %&gt;% \n  mutate(wkday = factor(wkday,\n                        levels = wkday_levels),\n         hour = factor(hour, levels = 0:23))\n\n\n\n\n\n\n\nNote\n\n\n\nBeside extracting the necessary data into attacks data frame, mutate() of dplyr package is used to convert wkday and hour fields into factor so they’ll be ordered when plotting.\n\n\nTable below shows the tidy tibble table after processing.\n\nkable(head(attacks))\n\n\n\n\ntz\nsource_country\nwkday\nhour\n\n\n\n\nAfrica/Cairo\nBG\nSaturday\n20\n\n\nAfrica/Cairo\nTW\nSunday\n6\n\n\nAfrica/Cairo\nTW\nSunday\n8\n\n\nAfrica/Cairo\nCN\nSunday\n11\n\n\nAfrica/Cairo\nUS\nSunday\n15\n\n\nAfrica/Cairo\nCA\nMonday\n11\n\n\n\n\n\n\n\n\n\ngrouped &lt;- attacks %&gt;% \n  count(wkday, hour) %&gt;% \n  ungroup() %&gt;% \n  na.omit()\n\nggplot(grouped,\n       aes(hour,\n           wkday,\n           fill=n)) +\n  geom_tile(color = \"white\",\n            size=0.1) +\n  theme_tufte(base_family = \"Helvetica\") +\n  coord_equal() +\n  scale_fill_gradient(name = \"# of attacks\",\n                      low = \"skyblue\",\n                      high = \"darkblue\") +\n  labs(x = NULL,\n       y = NULL,\n       title = \"Attacks by weekday and time of day\") +\n  theme(axis.ticks = element_blank(),\n        plot.title = element_text(hjust=0.5),\n        legend.title = element_text(size=8),\n        legend.text = element_text(size=6))\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk\n\n\n\n\na tibble data table called grouped is derived by aggregating the attack by wkday and hour fields.\na new field called n is derived by using group_by() and count() functions.\nna.omit() is used to exclude missing value.\ngeom_tile() is used to plot tiles (grids) at each x and y position. color and size arguments are used to specify the border color and line size of the tiles.\ntheme_tufte() of ggthemes package is used to remove unnecessary chart junk. To learn which visual components of default ggplot2 have been excluded, you are encouraged to comment out this line to examine the default plot.\ncoord_equal() is used to ensure the plot will have an aspect ratio of 1:1.\nscale_fill_gradient() function is used to creates a two colour gradient (low-high).\n\n\n\nThen we can simply group the count by hour and wkday and plot it, since we know that we have values for every combination there’s no need to further preprocess the data.\n\n\n\nChallenge: Building multiple heatmaps for the top four countries with the highest number of attacks.\n\n\n\n\nStep 1: Deriving attack by country object\nIn order to identify the top 4 countries with the highest number of attacks, you are required to do the followings:\n\ncount the number of attacks by country,\ncalculate the percent of attackes by country, and\nsave the results in a tibble data frame.\n\n\nattacks_by_country &lt;- count(attacks, source_country) %&gt;% \n  mutate(percent=percent(n/sum(n))) %&gt;% \n  arrange(desc(n))\n\nStep 2: Preparing the tidyr data frame\nIn this step, you are required to extract the attack records of the top 4 countries from attacks data frame and save the data in a new tibble data frame (i.e. top4_attacks).\n\ntop4 &lt;- attacks_by_country$source_country[1:4]\ntop4_attacks &lt;- attacks %&gt;% \n  filter(source_country %in% top4) %&gt;% \n  count(source_country, wkday, hour) %&gt;% \n  ungroup() %&gt;% \n  mutate(source_country = factor(source_country, levels = top4)) %&gt;% \n  na.omit()\n\n\n\n\nStep 3: Plotting the Multiple Calender Heatmap by using ggplot2 package.\n\nggplot(top4_attacks,\n       aes(hour,\n           wkday,\n           fill=n)) +\n  geom_tile(color = \"white\",\n            size=0.1) +\n  theme_tufte(base_family = \"Helvetica\") +\n  coord_equal() +\n  scale_fill_gradient(name=\"# of attacks\",\n                      low = \"skyblue\",\n                      high = \"darkblue\") +\n  facet_wrap(~source_country, ncol = 2) +\n  labs(x = NULL,\n       y = NULL,\n       title  =\"Attacks on top 4 countries by weekday and time of day\") +\n  theme(axis.ticks = element_blank(),\n        axis.text.x = element_text(size = 7),\n        plot.title = element_text(hjust = 0.5),\n        legend.title = element_text(size = 8),\n        legend.text = element_text(size = 6))\n\n\n\n\n\n\n\n\nIn this section, you will learn how to plot a cycle plot showing the time-series patterns and trend of visitor arrivals from Vietnam programmatically by using ggplot2 functions.\n\n\n\nFor the purpose of this hands-on exercise, arrivals_by_air.xlsx will be used.\nThe code chunk below imports arrivals_by_air.xlsx by using read_excel() of readxl package and save it as a tibble data frame called air.\n\nair &lt;- read_excel(\"data/arrivals_by_air.xlsx\")\n\n\n\n\nNext, two new fields called month and year are derived from Month-Year field.\n\nair$month &lt;- factor(month(air$`Month-Year`),\n                    levels=1:12,\n                    labels=month.abb,\n                    ordered=TRUE)\nair$year &lt;- year(ymd(air$`Month-Year`))\n\n\n\n\nNext, the code chunk below is use to extract data for the target country (i.e. Vietnam)\n\nVietnam &lt;- air %&gt;% \n  select(`Vietnam`, month, year) %&gt;% \n  filter(year &gt;= 2010)\n\n\n\n\nThe code chunk below uses group_by() and summarise() of dplyr to compute year average arrivals by month.\n\nhline.data &lt;- Vietnam %&gt;% \n  group_by(month) %&gt;% \n  summarise(avgvalue = mean(`Vietnam`))\n\n\n\n\nThe code chunk below is used to plot the cycle plot.\n\nggplot() +\n  geom_line(data=Vietnam,\n            aes(x=year,\n                y=`Vietnam`,\n                group=month),\n            colour=\"black\") +\n  geom_hline(aes(yintercept=avgvalue),\n             data=hline.data,\n             linetype=6,\n             colour=\"red\",\n             size=0.5) +\n  facet_grid(~month) +\n  labs(axis.text.x = element_blank(),\n       title = \"Visitor arrivals from Vietnam by air, Jan 2010-Dec 2019\") +\n  xlab(\"\") +\n  ylab(\"No. of Visitors\") +\n  theme_tufte(base_family = \"Helvetica\")\n\n\n\n\n\n\n\n\nIn this section you will learn how to plot a slopegraph by using R.\nBefore getting start, make sure that CGPfunctions has been installed and loaded onto R environment. Then, refer to Using newggslopegraph to learn more about the function. Lastly, read more about newggslopegraph() and its arguments by referring to this link.\n\n\nImport the rice data set into R environment by using the code chunk below.\n\nrice &lt;- read_csv(\"data/rice.csv\")\n\n\n\n\nNext, code chunk below will be used to plot a basic slopegraph as shown below.\n\nrice %&gt;% \n  mutate(Year=factor(Year)) %&gt;% \n  filter(Year %in%  c(1961, 1980)) %&gt;% \n  newggslopegraph(Year, Yield, Country,\n                  Title = \"Rice Yield of Top 11 Asian Countries\",\n                  SubTitle = \"1961-1980\",\n                  Caption = \"Prepared by: WM\")\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\nFor effective data visualisation design, factor() is used convert the value type of Year field from numeric to factor."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#learning-outcome",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#learning-outcome",
    "title": "Hands-on Exercise 6",
    "section": "",
    "text": "By the end of this hands-on exercise you will be able create the followings data visualisation by using R packages:\n\nplotting a calender heatmap by using ggplot2 functions,\nplotting a cycle plot by using ggplot2 function,\nplotting a slopegraph\nplotting a horizon chart"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#getting-started---do-it-yourself",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#getting-started---do-it-yourself",
    "title": "Hands-on Exercise 6",
    "section": "",
    "text": "Write a code chunk to check, install and launch the following R packages: scales, viridis, lubridate, ggthemes, gridExtra, readxl, knitr, data.table and tidyverse.\n\npacman::p_load(scales, viridis, lubridate, ggthemes, gridExtra, readxl, knitr, data.table, CGPfunctions, ggHoriPlot, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#plotting-calendar-heatmap",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#plotting-calendar-heatmap",
    "title": "Hands-on Exercise 6",
    "section": "",
    "text": "In this section, you will learn how to plot a calender heatmap programmatically by using ggplot2 package.\n\nBy the end of this section, you will be able to:\n\nplot a calender heatmap by using ggplot2 functions and extension,\nto write function using R programming,\nto derive specific date and time related field by using base R and lubridate packages\nto perform data preparation task by using tidyr and dplyr packages.\n\n\n\nFor the purpose of this hands-on exercise, eventlog.csv file will be used. This data file consists of 199,999 rows of time-series cyber attack records by country.\n\n\n\nFirst, you will use the code chunk below to import eventlog.csv file into R environment and called the data frame as attacks.\n\nattacks &lt;- read_csv(\"data/eventlog.csv\")\n\n\n\n\nIt is always a good practice to examine the imported data frame before further analysis is performed.\nFor example, kable() can be used to review the structure of the imported data frame.\n\nkable(head(attacks))\n\n\n\n\ntimestamp\nsource_country\ntz\n\n\n\n\n2015-03-12 15:59:16\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:00:48\nFR\nEurope/Paris\n\n\n2015-03-12 16:02:26\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:02:38\nUS\nAmerica/Chicago\n\n\n2015-03-12 16:03:22\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:03:45\nCN\nAsia/Shanghai\n\n\n\n\n\nThere are three columns, namely timestamp, source_country and tz.\n\ntimestamp field stores date-time values in POSIXct format.\nsource_country field stores the source of the attack. It is in ISO 3166-1 alpha-2 country code.\ntz field stores time zone of the source IP address.\n\n\n\n\nStep 1: Deriving weekday and hour of day fields\nBefore we can plot the calender heatmap, two new fields namely wkday and hour need to be derived. In this step, we will write a function to perform the task.\n\nmake_hr_wkday &lt;- function(ts, sc, tz) {\n  real_times &lt;- ymd_hms(ts,\n                        tz = tz[1],\n                        quiet=T)\n  dt&lt;- data.table(source_country = sc,\n                  wkday = weekdays(real_times),\n                  hour = hour(real_times))\n  return(dt)\n}\n\n\n\n\n\n\n\nNote\n\n\n\n\nymd_hms() and hour() are from lubridate package, and\nweekdays() is a base R function.\n\n\n\nStep 2: Deriving the attacks tibble data frame\n\nwkday_levels &lt;- c('Saturday', 'Friday',\n                   'Thursday', 'Wednesday',\n                   'Tuesday', 'Monday',\n                   'Sunday')\nattacks &lt;- attacks %&gt;% \n  group_by(tz) %&gt;% \n  do(make_hr_wkday(.$timestamp,\n                   .$source_country,\n                   .$tz)) %&gt;% \n  ungroup() %&gt;% \n  mutate(wkday = factor(wkday,\n                        levels = wkday_levels),\n         hour = factor(hour, levels = 0:23))\n\n\n\n\n\n\n\nNote\n\n\n\nBeside extracting the necessary data into attacks data frame, mutate() of dplyr package is used to convert wkday and hour fields into factor so they’ll be ordered when plotting.\n\n\nTable below shows the tidy tibble table after processing.\n\nkable(head(attacks))\n\n\n\n\ntz\nsource_country\nwkday\nhour\n\n\n\n\nAfrica/Cairo\nBG\nSaturday\n20\n\n\nAfrica/Cairo\nTW\nSunday\n6\n\n\nAfrica/Cairo\nTW\nSunday\n8\n\n\nAfrica/Cairo\nCN\nSunday\n11\n\n\nAfrica/Cairo\nUS\nSunday\n15\n\n\nAfrica/Cairo\nCA\nMonday\n11\n\n\n\n\n\n\n\n\n\ngrouped &lt;- attacks %&gt;% \n  count(wkday, hour) %&gt;% \n  ungroup() %&gt;% \n  na.omit()\n\nggplot(grouped,\n       aes(hour,\n           wkday,\n           fill=n)) +\n  geom_tile(color = \"white\",\n            size=0.1) +\n  theme_tufte(base_family = \"Helvetica\") +\n  coord_equal() +\n  scale_fill_gradient(name = \"# of attacks\",\n                      low = \"skyblue\",\n                      high = \"darkblue\") +\n  labs(x = NULL,\n       y = NULL,\n       title = \"Attacks by weekday and time of day\") +\n  theme(axis.ticks = element_blank(),\n        plot.title = element_text(hjust=0.5),\n        legend.title = element_text(size=8),\n        legend.text = element_text(size=6))\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk\n\n\n\n\na tibble data table called grouped is derived by aggregating the attack by wkday and hour fields.\na new field called n is derived by using group_by() and count() functions.\nna.omit() is used to exclude missing value.\ngeom_tile() is used to plot tiles (grids) at each x and y position. color and size arguments are used to specify the border color and line size of the tiles.\ntheme_tufte() of ggthemes package is used to remove unnecessary chart junk. To learn which visual components of default ggplot2 have been excluded, you are encouraged to comment out this line to examine the default plot.\ncoord_equal() is used to ensure the plot will have an aspect ratio of 1:1.\nscale_fill_gradient() function is used to creates a two colour gradient (low-high).\n\n\n\nThen we can simply group the count by hour and wkday and plot it, since we know that we have values for every combination there’s no need to further preprocess the data.\n\n\n\nChallenge: Building multiple heatmaps for the top four countries with the highest number of attacks.\n\n\n\n\nStep 1: Deriving attack by country object\nIn order to identify the top 4 countries with the highest number of attacks, you are required to do the followings:\n\ncount the number of attacks by country,\ncalculate the percent of attackes by country, and\nsave the results in a tibble data frame.\n\n\nattacks_by_country &lt;- count(attacks, source_country) %&gt;% \n  mutate(percent=percent(n/sum(n))) %&gt;% \n  arrange(desc(n))\n\nStep 2: Preparing the tidyr data frame\nIn this step, you are required to extract the attack records of the top 4 countries from attacks data frame and save the data in a new tibble data frame (i.e. top4_attacks).\n\ntop4 &lt;- attacks_by_country$source_country[1:4]\ntop4_attacks &lt;- attacks %&gt;% \n  filter(source_country %in% top4) %&gt;% \n  count(source_country, wkday, hour) %&gt;% \n  ungroup() %&gt;% \n  mutate(source_country = factor(source_country, levels = top4)) %&gt;% \n  na.omit()\n\n\n\n\nStep 3: Plotting the Multiple Calender Heatmap by using ggplot2 package.\n\nggplot(top4_attacks,\n       aes(hour,\n           wkday,\n           fill=n)) +\n  geom_tile(color = \"white\",\n            size=0.1) +\n  theme_tufte(base_family = \"Helvetica\") +\n  coord_equal() +\n  scale_fill_gradient(name=\"# of attacks\",\n                      low = \"skyblue\",\n                      high = \"darkblue\") +\n  facet_wrap(~source_country, ncol = 2) +\n  labs(x = NULL,\n       y = NULL,\n       title  =\"Attacks on top 4 countries by weekday and time of day\") +\n  theme(axis.ticks = element_blank(),\n        axis.text.x = element_text(size = 7),\n        plot.title = element_text(hjust = 0.5),\n        legend.title = element_text(size = 8),\n        legend.text = element_text(size = 6))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#plotting-cycle-plot",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#plotting-cycle-plot",
    "title": "Hands-on Exercise 6",
    "section": "",
    "text": "In this section, you will learn how to plot a cycle plot showing the time-series patterns and trend of visitor arrivals from Vietnam programmatically by using ggplot2 functions.\n\n\n\nFor the purpose of this hands-on exercise, arrivals_by_air.xlsx will be used.\nThe code chunk below imports arrivals_by_air.xlsx by using read_excel() of readxl package and save it as a tibble data frame called air.\n\nair &lt;- read_excel(\"data/arrivals_by_air.xlsx\")\n\n\n\n\nNext, two new fields called month and year are derived from Month-Year field.\n\nair$month &lt;- factor(month(air$`Month-Year`),\n                    levels=1:12,\n                    labels=month.abb,\n                    ordered=TRUE)\nair$year &lt;- year(ymd(air$`Month-Year`))\n\n\n\n\nNext, the code chunk below is use to extract data for the target country (i.e. Vietnam)\n\nVietnam &lt;- air %&gt;% \n  select(`Vietnam`, month, year) %&gt;% \n  filter(year &gt;= 2010)\n\n\n\n\nThe code chunk below uses group_by() and summarise() of dplyr to compute year average arrivals by month.\n\nhline.data &lt;- Vietnam %&gt;% \n  group_by(month) %&gt;% \n  summarise(avgvalue = mean(`Vietnam`))\n\n\n\n\nThe code chunk below is used to plot the cycle plot.\n\nggplot() +\n  geom_line(data=Vietnam,\n            aes(x=year,\n                y=`Vietnam`,\n                group=month),\n            colour=\"black\") +\n  geom_hline(aes(yintercept=avgvalue),\n             data=hline.data,\n             linetype=6,\n             colour=\"red\",\n             size=0.5) +\n  facet_grid(~month) +\n  labs(axis.text.x = element_blank(),\n       title = \"Visitor arrivals from Vietnam by air, Jan 2010-Dec 2019\") +\n  xlab(\"\") +\n  ylab(\"No. of Visitors\") +\n  theme_tufte(base_family = \"Helvetica\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#plotting-slopegraph",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#plotting-slopegraph",
    "title": "Hands-on Exercise 6",
    "section": "",
    "text": "In this section you will learn how to plot a slopegraph by using R.\nBefore getting start, make sure that CGPfunctions has been installed and loaded onto R environment. Then, refer to Using newggslopegraph to learn more about the function. Lastly, read more about newggslopegraph() and its arguments by referring to this link.\n\n\nImport the rice data set into R environment by using the code chunk below.\n\nrice &lt;- read_csv(\"data/rice.csv\")\n\n\n\n\nNext, code chunk below will be used to plot a basic slopegraph as shown below.\n\nrice %&gt;% \n  mutate(Year=factor(Year)) %&gt;% \n  filter(Year %in%  c(1961, 1980)) %&gt;% \n  newggslopegraph(Year, Yield, Country,\n                  Title = \"Rice Yield of Top 11 Asian Countries\",\n                  SubTitle = \"1961-1980\",\n                  Caption = \"Prepared by: WM\")\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\nFor effective data visualisation design, factor() is used convert the value type of Year field from numeric to factor."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05d/Hands-on_Ex05d.html",
    "href": "Hands-on_Ex/Hands-on_Ex05d/Hands-on_Ex05d.html",
    "title": "Hands-on Exercise 5d",
    "section": "",
    "text": "Parallel coordinates plot is a data visualisation specially designed for visualising and analysing multivariate, numerical data. It is ideal for comparing multiple variables together and seeing the relationships between them. For example, the variables contribute to Happiness Index. Parallel coordinates was invented by Alfred Inselberg in the 1970s as a way to visualize high-dimensional data. This data visualisation technique is more often found in academic and scientific communities than in business and consumer data visualizations. As pointed out by Stephen Few(2006), “This certainly isn’t a chart that you would present to the board of directors or place on your Web site for the general public. In fact, the strength of parallel coordinates isn’t in their ability to communicate some truth in the data to others, but rather in their ability to bring meaningful multivariate patterns and comparisons to light when used interactively for analysis.” For example, parallel coordinates plot can be used to characterise clusters detected during customer segmentation.\nBy the end of this hands-on exercise, you will gain hands-on experience on:\n\nplotting statistic parallel coordinates plots by using ggparcoord() of GGally package,\nplotting interactive parallel coordinates plots by using parcoords package, and\nplotting interactive parallel coordinates plots by using parallelPlot package.\n\n\n\n\nFor this exercise, the GGally, parcoords, parallelPlot and tidyverse packages will be used.\nThe code chunks below are used to install and load the packages in R.\n\npacman::p_load(GGally, parallelPlot, tidyverse)\n\n\n\n\nIn this hands-on exercise, the World Happinees 2018 (http://worldhappiness.report/ed/2018/) data will be used. The data set is download at https://s3.amazonaws.com/happiness-report/2018/WHR2018Chapter2OnlineData.xls. The original data set is in Microsoft Excel format. It has been extracted and saved in csv file called WHData-2018.csv.\nIn the code chunk below, read_csv() of readr package is used to import WHData-2018.csv into R and save it into a tibble data frame object called wh.\n\nwh &lt;- read_csv(\"data/WHData-2018.csv\")\n\n\n\n\nIn this section, you will learn how to plot static parallel coordinates plot by using ggparcoord() of GGally package. Before getting started, it is a good practice to read the function description in detail.\n\n\nCode chunk below shows a typical syntax used to plot a basic static parallel coordinates plot by using ggparcoord().\n\nggparcoord(data = wh, \n           columns = c(7:12))\n\n\n\n\nNotice that only two argument namely data and columns is used. Data argument is used to map the data object (i.e. wh) and columns is used to select the columns for preparing the parallel coordinates plot.\n\n\n\nThe basic parallel coordinates failed to reveal any meaning understanding of the World Happiness measures. In this section, you will learn how to makeover the plot by using a collection of arguments provided by ggparcoord().\n\nggparcoord(data=wh,\n           columns=c(7:12),\n           groupColumn=2,\n           scale=\"uniminmax\",\n           alphaLines=0.2,\n           boxplot=T,\n           title=\"Parallel Coordinates Plot of World Happines Variables\") +\n    theme(legend.text = element_text(size=4),\n        legend.key.width = unit(0.5, \"cm\"),\n        legend.key.height = unit(0.3, \"cm\"),\n        axis.text = element_text(size=4),\n        text = element_text(size = 4))\n\n\n\n\nThings to learn from the code chunk above.\n\ngroupColumn argument is used to group the observations (i.e. parallel lines) by using a single variable (i.e. Region) and colour the parallel coordinates lines by region name.\nscale argument is used to scale the variables in the parallel coordinate plot by using uniminmax method. The method univariately scale each variable so the minimum of the variable is zero and the maximum is one.\nalphaLines argument is used to reduce the intensity of the line colour to 0.2. The permissible value range is between 0 to 1.\nboxplot argument is used to turn on the boxplot by using logical TRUE. The default is FALSE.\ntitle argument is used to provide the parallel coordinates plot a title.\n\n\n\n\nSince ggparcoord() is developed by extending ggplot2 package, we can combination use some of the ggplot2 function when plotting a parallel coordinates plot.\nIn the code chunk below, facet_wrap() of ggplot2 is used to plot 10 small multiple parallel coordinates plots. Each plot represent one geographical region such as East Asia.\n\nggparcoord(data=wh,\n           columns=c(7:12),\n           groupColumn = 2,\n           scale = \"uniminmax\",\n           alphaLines = 0.2,\n           boxplot=T,\n           title = \"Multiple Parallel Coordinates Plots of World Happines Variables by Region\") +\n  facet_wrap(~Region) +\n  theme(legend.text = element_text(size=4),\n        legend.key.width = unit(0.5, \"cm\"),\n        legend.key.height = unit(0.3, \"cm\"),\n        axis.text = element_text(size=4),\n        text = element_text(size = 4))\n\n\n\n\nOne of the aesthetic defect of the current design is that some of the variable names overlap on x-axis.\n\n\n\nTo make the x-axis text label easy to read, let us rotate the labels by 30 degrees. We can rotate axis text labels using theme() function in ggplot2 as shown in the code chunk below\n\nggparcoord(data=wh,\n           columns = c(7:12),\n           groupColumn = 2,\n           scale = \"uniminmax\",\n           alphaLines = 0.2,\n           boxplot = T,\n           title = \"Multiple Parallel Coordinates Plots of World Happines Variables by Region\") +\n  facet_wrap(~Region) +\n  theme(axis.text.x = element_text(angle=30, size=3),\n        legend.text = element_text(size=4),\n        legend.key.width = unit(0.5, \"cm\"),\n        legend.key.height = unit(0.3, \"cm\"),\n        axis.text.y = element_text(size=4),\n        text = element_text(size = 4))\n\n\n\n\nThing to learn from the code chunk above:\n\nTo rotate x-axis text labels, we use axis.text.x as argument to theme() function. And we specify element_text(angle = 30) to rotate the x-axis text by an angle 30 degree.\n\n\n\n\nRotating x-axis text labels to 30 degrees makes the label overlap with the plot and we can avoid this by adjusting the text location using hjust argument to theme’s text element with element_text(). We use axis.text.x as we want to change the look of x-axis text.\n\nggparcoord(data=wh,\n           columns = c(7:12),\n           groupColumn = 2,\n           scale = \"uniminmax\",\n           alphaLines = 0.2,\n           boxplot = T,\n           title = \"Multiple Parallel Coordinates Plots of World Happines Variables by Region\") +\n  facet_wrap(~Region) +\n  theme(axis.text.x = element_text(angle=30, size=3, hjust=1),\n        legend.text = element_text(size=4),\n        legend.key.width = unit(0.5, \"cm\"),\n        legend.key.height = unit(0.3, \"cm\"),\n        axis.text.y = element_text(size=4),\n        text = element_text(size = 4))\n\n\n\n\n\n\n\n\nparallelPlot is an R package specially designed to plot a parallel coordinates plot by using ‘htmlwidgets’ package and d3.js. In this section, you will learn how to use functions provided in parallelPlot package to build interactive parallel coordinates plot.\n\n\nThe code chunk below plot an interactive parallel coordinates plot by using parallelPlot().\n\nwh &lt;- wh %&gt;% \n  select(\"Happiness score\", c(7:12))\nparallelPlot(wh,\n             width=320,\n             height=250)\n\n\n\n\n\nNotice that some of the axis labels are too long. You will learn how to overcome this problem in the next step.\n\n\n\nIn the code chunk below, rotateTitle argument is used to avoid overlapping axis labels.\n\nparallelPlot(wh,\n             rotateTitle=T)\n\n\n\n\n\nOne of the useful interactive feature of parallelPlot is we can click on a variable of interest, for example Happiness score, the monotonous blue colour (default) will change a blues with different intensity colour scheme will be used.\n\n\n\nWe can change the default blue colour scheme by using continousCS argument as shown in the code chunk below.\n\nparallelPlot(wh,\n             continuousCS = \"YlOrRd\",\n             rotateTitle = T)\n\n\n\n\n\n\n\n\nIn the code chunk below, histoVisibility argument is used to plot histogram along the axis of each variables.\n\nhistoVisibility &lt;- rep(TRUE, ncol(wh))\nparallelPlot(wh,\n             rotateTitle = T,\n             histoVisibility = histoVisibility)\n\n\n\n\n\n\n\n\n\n\nggparcoord() of GGally package\nparcoords user guide\nparallelPlot"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05d/Hands-on_Ex05d.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex05d/Hands-on_Ex05d.html#overview",
    "title": "Hands-on Exercise 5d",
    "section": "",
    "text": "Parallel coordinates plot is a data visualisation specially designed for visualising and analysing multivariate, numerical data. It is ideal for comparing multiple variables together and seeing the relationships between them. For example, the variables contribute to Happiness Index. Parallel coordinates was invented by Alfred Inselberg in the 1970s as a way to visualize high-dimensional data. This data visualisation technique is more often found in academic and scientific communities than in business and consumer data visualizations. As pointed out by Stephen Few(2006), “This certainly isn’t a chart that you would present to the board of directors or place on your Web site for the general public. In fact, the strength of parallel coordinates isn’t in their ability to communicate some truth in the data to others, but rather in their ability to bring meaningful multivariate patterns and comparisons to light when used interactively for analysis.” For example, parallel coordinates plot can be used to characterise clusters detected during customer segmentation.\nBy the end of this hands-on exercise, you will gain hands-on experience on:\n\nplotting statistic parallel coordinates plots by using ggparcoord() of GGally package,\nplotting interactive parallel coordinates plots by using parcoords package, and\nplotting interactive parallel coordinates plots by using parallelPlot package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05d/Hands-on_Ex05d.html#installing-and-launching-r-packages",
    "href": "Hands-on_Ex/Hands-on_Ex05d/Hands-on_Ex05d.html#installing-and-launching-r-packages",
    "title": "Hands-on Exercise 5d",
    "section": "",
    "text": "For this exercise, the GGally, parcoords, parallelPlot and tidyverse packages will be used.\nThe code chunks below are used to install and load the packages in R.\n\npacman::p_load(GGally, parallelPlot, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05d/Hands-on_Ex05d.html#data-preparation",
    "href": "Hands-on_Ex/Hands-on_Ex05d/Hands-on_Ex05d.html#data-preparation",
    "title": "Hands-on Exercise 5d",
    "section": "",
    "text": "In this hands-on exercise, the World Happinees 2018 (http://worldhappiness.report/ed/2018/) data will be used. The data set is download at https://s3.amazonaws.com/happiness-report/2018/WHR2018Chapter2OnlineData.xls. The original data set is in Microsoft Excel format. It has been extracted and saved in csv file called WHData-2018.csv.\nIn the code chunk below, read_csv() of readr package is used to import WHData-2018.csv into R and save it into a tibble data frame object called wh.\n\nwh &lt;- read_csv(\"data/WHData-2018.csv\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05d/Hands-on_Ex05d.html#plotting-static-parallel-coordinates-plot",
    "href": "Hands-on_Ex/Hands-on_Ex05d/Hands-on_Ex05d.html#plotting-static-parallel-coordinates-plot",
    "title": "Hands-on Exercise 5d",
    "section": "",
    "text": "In this section, you will learn how to plot static parallel coordinates plot by using ggparcoord() of GGally package. Before getting started, it is a good practice to read the function description in detail.\n\n\nCode chunk below shows a typical syntax used to plot a basic static parallel coordinates plot by using ggparcoord().\n\nggparcoord(data = wh, \n           columns = c(7:12))\n\n\n\n\nNotice that only two argument namely data and columns is used. Data argument is used to map the data object (i.e. wh) and columns is used to select the columns for preparing the parallel coordinates plot.\n\n\n\nThe basic parallel coordinates failed to reveal any meaning understanding of the World Happiness measures. In this section, you will learn how to makeover the plot by using a collection of arguments provided by ggparcoord().\n\nggparcoord(data=wh,\n           columns=c(7:12),\n           groupColumn=2,\n           scale=\"uniminmax\",\n           alphaLines=0.2,\n           boxplot=T,\n           title=\"Parallel Coordinates Plot of World Happines Variables\") +\n    theme(legend.text = element_text(size=4),\n        legend.key.width = unit(0.5, \"cm\"),\n        legend.key.height = unit(0.3, \"cm\"),\n        axis.text = element_text(size=4),\n        text = element_text(size = 4))\n\n\n\n\nThings to learn from the code chunk above.\n\ngroupColumn argument is used to group the observations (i.e. parallel lines) by using a single variable (i.e. Region) and colour the parallel coordinates lines by region name.\nscale argument is used to scale the variables in the parallel coordinate plot by using uniminmax method. The method univariately scale each variable so the minimum of the variable is zero and the maximum is one.\nalphaLines argument is used to reduce the intensity of the line colour to 0.2. The permissible value range is between 0 to 1.\nboxplot argument is used to turn on the boxplot by using logical TRUE. The default is FALSE.\ntitle argument is used to provide the parallel coordinates plot a title.\n\n\n\n\nSince ggparcoord() is developed by extending ggplot2 package, we can combination use some of the ggplot2 function when plotting a parallel coordinates plot.\nIn the code chunk below, facet_wrap() of ggplot2 is used to plot 10 small multiple parallel coordinates plots. Each plot represent one geographical region such as East Asia.\n\nggparcoord(data=wh,\n           columns=c(7:12),\n           groupColumn = 2,\n           scale = \"uniminmax\",\n           alphaLines = 0.2,\n           boxplot=T,\n           title = \"Multiple Parallel Coordinates Plots of World Happines Variables by Region\") +\n  facet_wrap(~Region) +\n  theme(legend.text = element_text(size=4),\n        legend.key.width = unit(0.5, \"cm\"),\n        legend.key.height = unit(0.3, \"cm\"),\n        axis.text = element_text(size=4),\n        text = element_text(size = 4))\n\n\n\n\nOne of the aesthetic defect of the current design is that some of the variable names overlap on x-axis.\n\n\n\nTo make the x-axis text label easy to read, let us rotate the labels by 30 degrees. We can rotate axis text labels using theme() function in ggplot2 as shown in the code chunk below\n\nggparcoord(data=wh,\n           columns = c(7:12),\n           groupColumn = 2,\n           scale = \"uniminmax\",\n           alphaLines = 0.2,\n           boxplot = T,\n           title = \"Multiple Parallel Coordinates Plots of World Happines Variables by Region\") +\n  facet_wrap(~Region) +\n  theme(axis.text.x = element_text(angle=30, size=3),\n        legend.text = element_text(size=4),\n        legend.key.width = unit(0.5, \"cm\"),\n        legend.key.height = unit(0.3, \"cm\"),\n        axis.text.y = element_text(size=4),\n        text = element_text(size = 4))\n\n\n\n\nThing to learn from the code chunk above:\n\nTo rotate x-axis text labels, we use axis.text.x as argument to theme() function. And we specify element_text(angle = 30) to rotate the x-axis text by an angle 30 degree.\n\n\n\n\nRotating x-axis text labels to 30 degrees makes the label overlap with the plot and we can avoid this by adjusting the text location using hjust argument to theme’s text element with element_text(). We use axis.text.x as we want to change the look of x-axis text.\n\nggparcoord(data=wh,\n           columns = c(7:12),\n           groupColumn = 2,\n           scale = \"uniminmax\",\n           alphaLines = 0.2,\n           boxplot = T,\n           title = \"Multiple Parallel Coordinates Plots of World Happines Variables by Region\") +\n  facet_wrap(~Region) +\n  theme(axis.text.x = element_text(angle=30, size=3, hjust=1),\n        legend.text = element_text(size=4),\n        legend.key.width = unit(0.5, \"cm\"),\n        legend.key.height = unit(0.3, \"cm\"),\n        axis.text.y = element_text(size=4),\n        text = element_text(size = 4))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05d/Hands-on_Ex05d.html#plotting-interactive-parallel-coordinates-plot-parallelplot-methods",
    "href": "Hands-on_Ex/Hands-on_Ex05d/Hands-on_Ex05d.html#plotting-interactive-parallel-coordinates-plot-parallelplot-methods",
    "title": "Hands-on Exercise 5d",
    "section": "",
    "text": "parallelPlot is an R package specially designed to plot a parallel coordinates plot by using ‘htmlwidgets’ package and d3.js. In this section, you will learn how to use functions provided in parallelPlot package to build interactive parallel coordinates plot.\n\n\nThe code chunk below plot an interactive parallel coordinates plot by using parallelPlot().\n\nwh &lt;- wh %&gt;% \n  select(\"Happiness score\", c(7:12))\nparallelPlot(wh,\n             width=320,\n             height=250)\n\n\n\n\n\nNotice that some of the axis labels are too long. You will learn how to overcome this problem in the next step.\n\n\n\nIn the code chunk below, rotateTitle argument is used to avoid overlapping axis labels.\n\nparallelPlot(wh,\n             rotateTitle=T)\n\n\n\n\n\nOne of the useful interactive feature of parallelPlot is we can click on a variable of interest, for example Happiness score, the monotonous blue colour (default) will change a blues with different intensity colour scheme will be used.\n\n\n\nWe can change the default blue colour scheme by using continousCS argument as shown in the code chunk below.\n\nparallelPlot(wh,\n             continuousCS = \"YlOrRd\",\n             rotateTitle = T)\n\n\n\n\n\n\n\n\nIn the code chunk below, histoVisibility argument is used to plot histogram along the axis of each variables.\n\nhistoVisibility &lt;- rep(TRUE, ncol(wh))\nparallelPlot(wh,\n             rotateTitle = T,\n             histoVisibility = histoVisibility)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05d/Hands-on_Ex05d.html#references",
    "href": "Hands-on_Ex/Hands-on_Ex05d/Hands-on_Ex05d.html#references",
    "title": "Hands-on Exercise 5d",
    "section": "",
    "text": "ggparcoord() of GGally package\nparcoords user guide\nparallelPlot"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05b/Hands-on_Ex05b.html",
    "href": "Hands-on_Ex/Hands-on_Ex05b/Hands-on_Ex05b.html",
    "title": "Hands-on Exercise 5b",
    "section": "",
    "text": "Correlation coefficient is a popular statistic that use to measure the type and strength of the relationship between two variables. The values of a correlation coefficient ranges between -1.0 and 1.0. A correlation coefficient of 1 shows a perfect linear relationship between the two variables, while a -1.0 shows a perfect inverse relationship between the two variables. A correlation coefficient of 0.0 shows no linear relationship between the two variables.\nWhen multivariate data are used, the correlation coefficeints of the pair comparisons are displayed in a table form known as correlation matrix or scatterplot matrix.\nThere are three broad reasons for computing a correlation matrix.\n\nTo reveal the relationship between high-dimensional variables pair-wisely.\nTo input into other analyses. For example, people commonly use correlation matrices as inputs for exploratory factor analysis, confirmatory factor analysis, structural equation models, and linear regression when excluding missing values pairwise.\nAs a diagnostic when checking other analyses. For example, with linear regression a high amount of correlations suggests that the linear regression’s estimates will be unreliable.\n\nWhen the data is large, both in terms of the number of observations and the number of variables, Corrgram tend to be used to visually explore and analyse the structure and the patterns of relations among variables. It is designed based on two main schemes:\n\nRendering the value of a correlation to depict its sign and magnitude, and\nReordering the variables in a correlation matrix so that “similar” variables are positioned adjacently, facilitating perception.\n\nIn this hands-on exercise, you will learn how to plot data visualisation for visualising correlation matrix with R. It consists of three main sections. First, you will learn how to create correlation matrix using pairs() of R Graphics. Next, you will learn how to plot corrgram using corrplot package of R. Lastly, you will learn how to create an interactive correlation matrix using plotly R.\n\n\n\nBefore you get started, you are required:\n\nto start a new R project, and\nto create a new R Markdown document.\n\nNext, you will use the code chunk below to install and launch corrplot, ggpubr, plotly and tidyverse in RStudio.\n\npacman::p_load(corrplot, ggstatsplot, tidyverse, corrgram, ellipse)\n\n\n\n\nIn this hands-on exercise, the Wine Quality Data Set of UCI Machine Learning Repository will be used. The data set consists of 13 variables and 6497 observations. For the purpose of this exercise, we have combined the red wine and white wine data into one data file. It is called wine_quality and is in csv file format.\n\n\nFirst, let us import the data into R by using read_csv() of readr package.\n\nwine &lt;- read_csv(\"data/wine_quality.csv\")\n\nNotice that beside quality and type, the rest of the variables are numerical and continuous data type.\n\n\n\n\nThere are more than one way to build scatterplot matrix with R. In this section, you will learn how to create a scatterplot matrix by using the pairs function of R Graphics.\nBefore you continue to the next step, you should read the syntax description of pairsfunction.\n\n\nFigure below shows the scatter plot matrix of Wine Quality Data. It is a 11 by 11 matrix.\n\npairs(wine[,1:11])\n\n\n\n\nThe required input of pairs() can be a matrix or data frame. The code chunk used to create the scatterplot matrix is relatively simple. It uses the default pairs function. Columns 2 to 12 of wine dataframe is used to build the scatterplot matrix. The variables are: fixed acidity, volatile acidity, citric acid, residual sugar, chlorides, free sulfur dioxide, total sulfur dioxide, density, pH, sulphates and alcohol.\n\npairs(wine[,2:12])\n\n\n\n\n\n\n\npairs function of R Graphics provided many customisation arguments. For example, it is a common practice to show either the upper half or lower half of the correlation matrix instead of both. This is because a correlation matrix is symmetric.\nTo show the lower half of the correlation matrix, the upper.panel argument will be used as shown in the code chunk below.\n\npairs(wine[,2:12], upper.panel = NULL)\n\n\n\n\nSimilarly, you can display the upper half of the correlation matrix by using the code chun below.\n\npairs(wine[,2:12], lower.panel = NULL)\n\n\n\n\n\n\n\nTo show the correlation coefficient of each pair of variables instead of a scatter plot, panel.cor function will be used. This will also show higher correlations in a larger font.\nDon’t worry about the details for now-just type this code into your R session or script. Let’s have more fun way to display the correlation matrix.\n\npanel.cor &lt;- function(x, y, digits=2, prefix=\"\", cex.cor, ...) {\nusr &lt;- par(\"usr\")\non.exit(par(usr))\npar(usr = c(0, 1, 0, 1))\nr &lt;- abs(cor(x, y, use=\"complete.obs\"))\ntxt &lt;- format(c(r, 0.123456789), digits=digits)[1]\ntxt &lt;- paste(prefix, txt, sep=\"\")\nif(missing(cex.cor)) cex.cor &lt;- 0.8/strwidth(txt)\ntext(0.5, 0.5, txt, cex = cex.cor * (1 + r) / 2)\n}\n\npairs(wine[,2:12], \n      upper.panel = panel.cor)\n\n\n\n\n\n\n\n\nOne of the major limitation of the correlation matrix is that the scatter plots appear very cluttered when the number of observations is relatively large (i.e. more than 500 observations). To over come this problem, Corrgram data visualisation technique suggested by D. J. Murdoch and E. D. Chow (1996) and Friendly, M (2002) and will be used.\nThe are at least three R packages provide function to plot corrgram, they are:\n\ncorrgram\nellipse\ncorrplot\n\nOn top that, some R package like ggstatsplot package also provides functions for building corrgram.\nIn this section, you will learn how to visualising correlation matrix by using ggcorrmat() of ggstatsplot package.\n\n\nOne of the advantage of using ggcorrmat() over many other methods to visualise a correlation matrix is it’s ability to provide a comprehensive and yet professional statistical report as shown in the figure below.\n\nggcorrmat(\n  data = wine, \n  cor.vars = 1:11)\n\n\n\n\n\nggcorrmat(\n  data = wine, \n  cor.vars = 1:11,\n  ggcorrplot.args = list(outline.color = \"black\", \n                         hc.order = TRUE,\n                         tl.cex = 10),\n  title    = \"Correlogram for wine dataset\",\n  subtitle = \"Four pairs are not significant at p &lt; 0.05\"\n)\n\n\n\n\nThings to learn from the code chunk above:\n\ncor.vars argument is used to compute the correlation matrix needed to build the corrgram.\nggcorrplot.args argument provide additional (mostly aesthetic) arguments that will be passed to ggcorrplot::ggcorrplot function. The list should avoid any of the following arguments since they are already internally being used: corr, method, p.mat, sig.level, ggtheme, colors, lab, pch, legend.title, digits.\n\nThe sample sub-code chunk can be used to control specific component of the plot such as the font size of the x-axis, y-axis, and the statistical report.\n\nggcorrmat(\n  data = wine, \n  cor.vars = 1:11,\n  ggcorrplot.args = list(outline.color = \"black\", \n                         hc.order = TRUE,\n                         tl.cex = 10),\n  ggplot.component = list(\n    theme(text=element_text(size=5),\n      axis.text.x = element_text(size = 8),\n      axis.text.y = element_text(size = 8))),\n  title    = \"Correlogram for wine dataset\",\n  subtitle = \"Four pairs are not significant at p &lt; 0.05\"\n)\n\n\n\n\n\n\n\n\nSince ggstasplot is an extension of ggplot2, it also supports faceting. However the feature is not available in ggcorrmat() but in the grouped_ggcorrmat() of ggstatsplot.\n\ngrouped_ggcorrmat(\n  data = wine,\n  cor.vars = 1:11,\n  grouping.var = type,\n  type = \"robust\",\n  p.adjust.method = \"holm\",\n  plotgrid.args = list(ncol = 2),\n  ggcorrplot.args = list(outline.color = \"black\", \n                         hc.order = TRUE,\n                         tl.cex = 1),\n  annotation.args = list(\n    tag_levels = \"a\",\n    title = \"Correlogram for wine dataset\",\n    subtitle = \"The measures are: alcohol, sulphates, fixed acidity, citric acid, chlorides, residual sugar, density, free sulfur dioxide and volatile acidity\",\n    caption = \"Dataset: UCI Machine Learning Repository\"\n  )\n)\n\n\n\n\nThings to learn from the code chunk above:\n\nto build a facet plot, the only argument needed is grouping.var.\nBehind group_ggcorrmat(), patchwork package is used to create the multiplot. plotgrid.args argument provides a list of additional arguments passed to patchwork::wrap_plots, except for guides argument which is already separately specified earlier.\nLikewise, annotation.args argument is calling plot annotation arguments of patchwork package.\n\n\n\n\nIn this hands-on exercise, we will focus on corrplot. However, you are encouraged to explore the other two packages too.\nBefore getting started, you are required to read An Introduction to corrplot Package in order to gain basic understanding of corrplot package.\n\n\nBefore we can plot a corrgram using corrplot(), we need to compute the correlation matrix of wine data frame.\nIn the code chunk below, cor() of R Stats is used to compute the correlation matrix of wine data frame.\n\nwine.cor &lt;- cor(wine[, 1:11])\n\nNext, corrplot() is used to plot the corrgram by using all the default setting as shown in the code chunk below.\n\ncorrplot(wine.cor)\n\n\n\n\nNotice that the default visual object used to plot the corrgram is circle. The default layout of the corrgram is a symmetric matrix. The default colour scheme is diverging blue-red. Blue colours are used to represent pair variables with positive correlation coefficients and red colours are used to represent pair variables with negative correlation coefficients. The intensity of the colour or also know as saturation is used to represent the strength of the correlation coefficient. Darker colours indicate relatively stronger linear relationship between the paired variables. On the other hand, lighter colours indicates relatively weaker linear relationship.\n\n\n\nIn corrplot package, there are seven visual geometrics (parameter method) can be used to encode the attribute values. They are: circle, square, ellipse, number, shade, color and pie. The default is circle. As shown in the previous section, the default visual geometric of corrplot matrix is circle. However, this default setting can be changed by using the method argument as shown in the code chunk below.\n\nEllipseSquareNumberShadeColorPie\n\n\n\ncorrplot(wine.cor, \n         method = \"ellipse\") \n\n\n\n\n\n\n\ncorrplot(wine.cor, \n         method = \"square\") \n\n\n\n\n\n\n\ncorrplot(wine.cor, \n         method = \"number\") \n\n\n\n\n\n\n\ncorrplot(wine.cor, \n         method = \"shade\") \n\n\n\n\n\n\n\ncorrplot(wine.cor, \n         method = \"color\") \n\n\n\n\n\n\n\ncorrplot(wine.cor, \n         method = \"pie\") \n\n\n\n\n\n\n\nFeel free to change the method argument to other supported visual geometrics.\n\n\n\ncorrplor() supports three layout types, namely: “full”, “upper” or “lower”. The default is “full” which display full matrix. The default setting can be changed by using the type argument of corrplot().\n\nFullUpperLower\n\n\n\ncorrplot(wine.cor, \n         method = \"ellipse\", \n         type=\"full\")\n\n\n\n\n\n\n\ncorrplot(wine.cor, \n         method = \"ellipse\", \n         type=\"upper\")\n\n\n\n\n\n\n\ncorrplot(wine.cor, \n         method = \"ellipse\", \n         type=\"lower\")\n\n\n\n\n\n\n\nThe default layout of the corrgram can be further customised. For example, arguments diag and tl.col are used to turn off the diagonal cells and to change the axis text label colour to black colour respectively as shown in the code chunk and figure below.\n\ncorrplot(wine.cor, \n         method = \"ellipse\", \n         type=\"lower\",\n         diag = FALSE,\n         tl.col = \"black\")\n\n\n\n\nPlease feel free to experiment with other layout design argument such as tl.pos, tl.cex, tl.offset, cl.pos, cl.cex and cl.offset, just to mention a few of them.\n\ncorrplot(wine.cor, \n         method = \"ellipse\", \n         type=\"lower\",\n         diag = FALSE,\n         tl.col = \"black\",\n         tl.pos = \"lt\",\n         tl.cex = 0.6,\n         tl.offset = 0.2,\n         cl.pos = \"r\",\n         cl.cex = 0.6,\n         cl.offset = 5,\n         order = \"hclust\",\n         hclust.method = \"centroid\")\n\n\n\n\n\n\n\nWith corrplot package, it is possible to design corrgram with mixed visual matrix of one half and numerical matrix on the other half. In order to create a coorgram with mixed layout, the corrplot.mixed(), a wrapped function for mixed visualisation style will be used.\nFigure below shows a mixed layout corrgram plotted using wine quality data.\n\ncorrplot.mixed(wine.cor, \n               lower = \"ellipse\", \n               upper = \"number\",\n               tl.pos = \"lt\",\n               diag = \"l\",\n               tl.col = \"black\")\n\n\n\n\nThe code chunk used to plot the corrgram are shown below.\n\ncorrplot.mixed(wine.cor, \n               lower = \"ellipse\", \n               upper = \"pie\",\n               tl.pos = \"lt\",\n               diag = \"l\",\n               tl.col = \"red\")\n\n\n\n\nNotice that argument lower and upper are used to define the visualisation method used. In this case ellipse is used to map the lower half of the corrgram and numerical matrix (i.e. number) is used to map the upper half of the corrgram. The argument tl.pos, on the other, is used to specify the placement of the axis label. Lastly, the diag argument is used to specify the glyph on the principal diagonal of the corrgram.\n\n\n\nIn statistical analysis, we are also interested to know which pair of variables their correlation coefficients are statistically significant.\nFigure below shows a corrgram combined with the significant test. The corrgram reveals that not all correlation pairs are statistically significant. For example the correlation between total sulfur dioxide and free surfur dioxide is statistically significant at significant level of 0.1 but not the pair between total sulfur dioxide and citric acid.\n\nWith corrplot package, we can use the cor.mtest() to compute the p-values and confidence interval for each pair of variables.\n\nwine.sig = cor.mtest(wine.cor, conf.level= .95)\n\nWe can then use the p.mat argument of corrplot function as shown in the code chunk below.\n\ncorrplot(wine.cor,\n         method = \"number\",\n         type = \"lower\",\n         diag = FALSE,\n         tl.col = \"black\",\n         tl.srt = 45,\n         p.mat = wine.sig$p,\n         sig.level = .05)\n\n\n\n\n\n\n\nMatrix reorder is very important for mining the hiden structure and pattern in a corrgram. By default, the order of attributes of a corrgram is sorted according to the correlation matrix (i.e. “original”). The default setting can be over-write by using the order argument of corrplot(). Currently, corrplot package support four sorting methods, they are:\n\n“AOE” is for the angular order of the eigenvectors. See Michael Friendly (2002) for details.\n“FPC” for the first principal component order.\n“hclust” for hierarchical clustering order, and “hclust.method” for the agglomeration method to be used.\n\n“hclust.method” should be one of “ward”, “single”, “complete”, “average”, “mcquitty”, “median” or “centroid”.\n\n“alphabet” for alphabetical order.\n\n“AOE”, “FPC”, “hclust”, “alphabet”. More algorithms can be found in seriation package.\n\ncorrplot.mixed(wine.cor, \n               lower = \"ellipse\", \n               upper = \"number\",\n               tl.pos = \"lt\",\n               diag = \"l\",\n               order=\"AOE\",\n               tl.col = \"black\")\n\n\n\n\n\n\n\nIf using hclust, corrplot() can draw rectangles around the corrgram based on the results of hierarchical clustering.\n\ncorrplot(wine.cor, \n         method = \"ellipse\", \n         tl.pos = \"lt\",\n         tl.col = \"black\",\n         order=\"hclust\",\n         hclust.method = \"ward.D\",\n         addrect = 3)\n\n\n\n\n\n\n\n\n\ncorrgram(wine,\n         order = T,\n         lower.panel = panel.bar,\n         upper.panel = panel.ellipse,\n         cex.labels = 0.5)\n\n\n\n\n\n\n\n\nplotcorr(wine.cor,\n         col = c(\"blue\", \"red\"),\n         type = \"lower\",\n         diag = F)\n\n\n\n\n\n\n\nMichael Friendly (2002). “Corrgrams: Exploratory displays for correlation matrices”. The American Statistician, 56, 316–324.\nD.J. Murdoch, E.D. Chow (1996). “A graphical display of large correlation matrices”. The American Statistician, 50, 178–180.\n\n\n\nggcormat() of ggstatsplot package\nggscatmat and ggpairs of GGally.\ncorrplot. A graphical display of a correlation matrix or general matrix. It also contains some algorithms to do matrix reordering. In addition, corrplot is good at details, including choosing color, text labels, color labels, layout, etc.\ncorrgram calculates correlation of variables and displays the results graphically. Included panel functions can display points, shading, ellipses, and correlation values with confidence intervals."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05b/Hands-on_Ex05b.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex05b/Hands-on_Ex05b.html#overview",
    "title": "Hands-on Exercise 5b",
    "section": "",
    "text": "Correlation coefficient is a popular statistic that use to measure the type and strength of the relationship between two variables. The values of a correlation coefficient ranges between -1.0 and 1.0. A correlation coefficient of 1 shows a perfect linear relationship between the two variables, while a -1.0 shows a perfect inverse relationship between the two variables. A correlation coefficient of 0.0 shows no linear relationship between the two variables.\nWhen multivariate data are used, the correlation coefficeints of the pair comparisons are displayed in a table form known as correlation matrix or scatterplot matrix.\nThere are three broad reasons for computing a correlation matrix.\n\nTo reveal the relationship between high-dimensional variables pair-wisely.\nTo input into other analyses. For example, people commonly use correlation matrices as inputs for exploratory factor analysis, confirmatory factor analysis, structural equation models, and linear regression when excluding missing values pairwise.\nAs a diagnostic when checking other analyses. For example, with linear regression a high amount of correlations suggests that the linear regression’s estimates will be unreliable.\n\nWhen the data is large, both in terms of the number of observations and the number of variables, Corrgram tend to be used to visually explore and analyse the structure and the patterns of relations among variables. It is designed based on two main schemes:\n\nRendering the value of a correlation to depict its sign and magnitude, and\nReordering the variables in a correlation matrix so that “similar” variables are positioned adjacently, facilitating perception.\n\nIn this hands-on exercise, you will learn how to plot data visualisation for visualising correlation matrix with R. It consists of three main sections. First, you will learn how to create correlation matrix using pairs() of R Graphics. Next, you will learn how to plot corrgram using corrplot package of R. Lastly, you will learn how to create an interactive correlation matrix using plotly R."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05b/Hands-on_Ex05b.html#installing-and-launching-r-packages",
    "href": "Hands-on_Ex/Hands-on_Ex05b/Hands-on_Ex05b.html#installing-and-launching-r-packages",
    "title": "Hands-on Exercise 5b",
    "section": "",
    "text": "Before you get started, you are required:\n\nto start a new R project, and\nto create a new R Markdown document.\n\nNext, you will use the code chunk below to install and launch corrplot, ggpubr, plotly and tidyverse in RStudio.\n\npacman::p_load(corrplot, ggstatsplot, tidyverse, corrgram, ellipse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05b/Hands-on_Ex05b.html#importing-and-preparing-the-data-set",
    "href": "Hands-on_Ex/Hands-on_Ex05b/Hands-on_Ex05b.html#importing-and-preparing-the-data-set",
    "title": "Hands-on Exercise 5b",
    "section": "",
    "text": "In this hands-on exercise, the Wine Quality Data Set of UCI Machine Learning Repository will be used. The data set consists of 13 variables and 6497 observations. For the purpose of this exercise, we have combined the red wine and white wine data into one data file. It is called wine_quality and is in csv file format.\n\n\nFirst, let us import the data into R by using read_csv() of readr package.\n\nwine &lt;- read_csv(\"data/wine_quality.csv\")\n\nNotice that beside quality and type, the rest of the variables are numerical and continuous data type."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05b/Hands-on_Ex05b.html#building-correlation-matrix-pairs-method",
    "href": "Hands-on_Ex/Hands-on_Ex05b/Hands-on_Ex05b.html#building-correlation-matrix-pairs-method",
    "title": "Hands-on Exercise 5b",
    "section": "",
    "text": "There are more than one way to build scatterplot matrix with R. In this section, you will learn how to create a scatterplot matrix by using the pairs function of R Graphics.\nBefore you continue to the next step, you should read the syntax description of pairsfunction.\n\n\nFigure below shows the scatter plot matrix of Wine Quality Data. It is a 11 by 11 matrix.\n\npairs(wine[,1:11])\n\n\n\n\nThe required input of pairs() can be a matrix or data frame. The code chunk used to create the scatterplot matrix is relatively simple. It uses the default pairs function. Columns 2 to 12 of wine dataframe is used to build the scatterplot matrix. The variables are: fixed acidity, volatile acidity, citric acid, residual sugar, chlorides, free sulfur dioxide, total sulfur dioxide, density, pH, sulphates and alcohol.\n\npairs(wine[,2:12])\n\n\n\n\n\n\n\npairs function of R Graphics provided many customisation arguments. For example, it is a common practice to show either the upper half or lower half of the correlation matrix instead of both. This is because a correlation matrix is symmetric.\nTo show the lower half of the correlation matrix, the upper.panel argument will be used as shown in the code chunk below.\n\npairs(wine[,2:12], upper.panel = NULL)\n\n\n\n\nSimilarly, you can display the upper half of the correlation matrix by using the code chun below.\n\npairs(wine[,2:12], lower.panel = NULL)\n\n\n\n\n\n\n\nTo show the correlation coefficient of each pair of variables instead of a scatter plot, panel.cor function will be used. This will also show higher correlations in a larger font.\nDon’t worry about the details for now-just type this code into your R session or script. Let’s have more fun way to display the correlation matrix.\n\npanel.cor &lt;- function(x, y, digits=2, prefix=\"\", cex.cor, ...) {\nusr &lt;- par(\"usr\")\non.exit(par(usr))\npar(usr = c(0, 1, 0, 1))\nr &lt;- abs(cor(x, y, use=\"complete.obs\"))\ntxt &lt;- format(c(r, 0.123456789), digits=digits)[1]\ntxt &lt;- paste(prefix, txt, sep=\"\")\nif(missing(cex.cor)) cex.cor &lt;- 0.8/strwidth(txt)\ntext(0.5, 0.5, txt, cex = cex.cor * (1 + r) / 2)\n}\n\npairs(wine[,2:12], \n      upper.panel = panel.cor)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05b/Hands-on_Ex05b.html#visualising-correlation-matrix-ggcormat",
    "href": "Hands-on_Ex/Hands-on_Ex05b/Hands-on_Ex05b.html#visualising-correlation-matrix-ggcormat",
    "title": "Hands-on Exercise 5b",
    "section": "",
    "text": "One of the major limitation of the correlation matrix is that the scatter plots appear very cluttered when the number of observations is relatively large (i.e. more than 500 observations). To over come this problem, Corrgram data visualisation technique suggested by D. J. Murdoch and E. D. Chow (1996) and Friendly, M (2002) and will be used.\nThe are at least three R packages provide function to plot corrgram, they are:\n\ncorrgram\nellipse\ncorrplot\n\nOn top that, some R package like ggstatsplot package also provides functions for building corrgram.\nIn this section, you will learn how to visualising correlation matrix by using ggcorrmat() of ggstatsplot package.\n\n\nOne of the advantage of using ggcorrmat() over many other methods to visualise a correlation matrix is it’s ability to provide a comprehensive and yet professional statistical report as shown in the figure below.\n\nggcorrmat(\n  data = wine, \n  cor.vars = 1:11)\n\n\n\n\n\nggcorrmat(\n  data = wine, \n  cor.vars = 1:11,\n  ggcorrplot.args = list(outline.color = \"black\", \n                         hc.order = TRUE,\n                         tl.cex = 10),\n  title    = \"Correlogram for wine dataset\",\n  subtitle = \"Four pairs are not significant at p &lt; 0.05\"\n)\n\n\n\n\nThings to learn from the code chunk above:\n\ncor.vars argument is used to compute the correlation matrix needed to build the corrgram.\nggcorrplot.args argument provide additional (mostly aesthetic) arguments that will be passed to ggcorrplot::ggcorrplot function. The list should avoid any of the following arguments since they are already internally being used: corr, method, p.mat, sig.level, ggtheme, colors, lab, pch, legend.title, digits.\n\nThe sample sub-code chunk can be used to control specific component of the plot such as the font size of the x-axis, y-axis, and the statistical report.\n\nggcorrmat(\n  data = wine, \n  cor.vars = 1:11,\n  ggcorrplot.args = list(outline.color = \"black\", \n                         hc.order = TRUE,\n                         tl.cex = 10),\n  ggplot.component = list(\n    theme(text=element_text(size=5),\n      axis.text.x = element_text(size = 8),\n      axis.text.y = element_text(size = 8))),\n  title    = \"Correlogram for wine dataset\",\n  subtitle = \"Four pairs are not significant at p &lt; 0.05\"\n)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05b/Hands-on_Ex05b.html#building-multiple-plots",
    "href": "Hands-on_Ex/Hands-on_Ex05b/Hands-on_Ex05b.html#building-multiple-plots",
    "title": "Hands-on Exercise 5b",
    "section": "",
    "text": "Since ggstasplot is an extension of ggplot2, it also supports faceting. However the feature is not available in ggcorrmat() but in the grouped_ggcorrmat() of ggstatsplot.\n\ngrouped_ggcorrmat(\n  data = wine,\n  cor.vars = 1:11,\n  grouping.var = type,\n  type = \"robust\",\n  p.adjust.method = \"holm\",\n  plotgrid.args = list(ncol = 2),\n  ggcorrplot.args = list(outline.color = \"black\", \n                         hc.order = TRUE,\n                         tl.cex = 1),\n  annotation.args = list(\n    tag_levels = \"a\",\n    title = \"Correlogram for wine dataset\",\n    subtitle = \"The measures are: alcohol, sulphates, fixed acidity, citric acid, chlorides, residual sugar, density, free sulfur dioxide and volatile acidity\",\n    caption = \"Dataset: UCI Machine Learning Repository\"\n  )\n)\n\n\n\n\nThings to learn from the code chunk above:\n\nto build a facet plot, the only argument needed is grouping.var.\nBehind group_ggcorrmat(), patchwork package is used to create the multiplot. plotgrid.args argument provides a list of additional arguments passed to patchwork::wrap_plots, except for guides argument which is already separately specified earlier.\nLikewise, annotation.args argument is calling plot annotation arguments of patchwork package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05b/Hands-on_Ex05b.html#visualising-correlation-matrix-using-corrplot-package",
    "href": "Hands-on_Ex/Hands-on_Ex05b/Hands-on_Ex05b.html#visualising-correlation-matrix-using-corrplot-package",
    "title": "Hands-on Exercise 5b",
    "section": "",
    "text": "In this hands-on exercise, we will focus on corrplot. However, you are encouraged to explore the other two packages too.\nBefore getting started, you are required to read An Introduction to corrplot Package in order to gain basic understanding of corrplot package.\n\n\nBefore we can plot a corrgram using corrplot(), we need to compute the correlation matrix of wine data frame.\nIn the code chunk below, cor() of R Stats is used to compute the correlation matrix of wine data frame.\n\nwine.cor &lt;- cor(wine[, 1:11])\n\nNext, corrplot() is used to plot the corrgram by using all the default setting as shown in the code chunk below.\n\ncorrplot(wine.cor)\n\n\n\n\nNotice that the default visual object used to plot the corrgram is circle. The default layout of the corrgram is a symmetric matrix. The default colour scheme is diverging blue-red. Blue colours are used to represent pair variables with positive correlation coefficients and red colours are used to represent pair variables with negative correlation coefficients. The intensity of the colour or also know as saturation is used to represent the strength of the correlation coefficient. Darker colours indicate relatively stronger linear relationship between the paired variables. On the other hand, lighter colours indicates relatively weaker linear relationship.\n\n\n\nIn corrplot package, there are seven visual geometrics (parameter method) can be used to encode the attribute values. They are: circle, square, ellipse, number, shade, color and pie. The default is circle. As shown in the previous section, the default visual geometric of corrplot matrix is circle. However, this default setting can be changed by using the method argument as shown in the code chunk below.\n\nEllipseSquareNumberShadeColorPie\n\n\n\ncorrplot(wine.cor, \n         method = \"ellipse\") \n\n\n\n\n\n\n\ncorrplot(wine.cor, \n         method = \"square\") \n\n\n\n\n\n\n\ncorrplot(wine.cor, \n         method = \"number\") \n\n\n\n\n\n\n\ncorrplot(wine.cor, \n         method = \"shade\") \n\n\n\n\n\n\n\ncorrplot(wine.cor, \n         method = \"color\") \n\n\n\n\n\n\n\ncorrplot(wine.cor, \n         method = \"pie\") \n\n\n\n\n\n\n\nFeel free to change the method argument to other supported visual geometrics.\n\n\n\ncorrplor() supports three layout types, namely: “full”, “upper” or “lower”. The default is “full” which display full matrix. The default setting can be changed by using the type argument of corrplot().\n\nFullUpperLower\n\n\n\ncorrplot(wine.cor, \n         method = \"ellipse\", \n         type=\"full\")\n\n\n\n\n\n\n\ncorrplot(wine.cor, \n         method = \"ellipse\", \n         type=\"upper\")\n\n\n\n\n\n\n\ncorrplot(wine.cor, \n         method = \"ellipse\", \n         type=\"lower\")\n\n\n\n\n\n\n\nThe default layout of the corrgram can be further customised. For example, arguments diag and tl.col are used to turn off the diagonal cells and to change the axis text label colour to black colour respectively as shown in the code chunk and figure below.\n\ncorrplot(wine.cor, \n         method = \"ellipse\", \n         type=\"lower\",\n         diag = FALSE,\n         tl.col = \"black\")\n\n\n\n\nPlease feel free to experiment with other layout design argument such as tl.pos, tl.cex, tl.offset, cl.pos, cl.cex and cl.offset, just to mention a few of them.\n\ncorrplot(wine.cor, \n         method = \"ellipse\", \n         type=\"lower\",\n         diag = FALSE,\n         tl.col = \"black\",\n         tl.pos = \"lt\",\n         tl.cex = 0.6,\n         tl.offset = 0.2,\n         cl.pos = \"r\",\n         cl.cex = 0.6,\n         cl.offset = 5,\n         order = \"hclust\",\n         hclust.method = \"centroid\")\n\n\n\n\n\n\n\nWith corrplot package, it is possible to design corrgram with mixed visual matrix of one half and numerical matrix on the other half. In order to create a coorgram with mixed layout, the corrplot.mixed(), a wrapped function for mixed visualisation style will be used.\nFigure below shows a mixed layout corrgram plotted using wine quality data.\n\ncorrplot.mixed(wine.cor, \n               lower = \"ellipse\", \n               upper = \"number\",\n               tl.pos = \"lt\",\n               diag = \"l\",\n               tl.col = \"black\")\n\n\n\n\nThe code chunk used to plot the corrgram are shown below.\n\ncorrplot.mixed(wine.cor, \n               lower = \"ellipse\", \n               upper = \"pie\",\n               tl.pos = \"lt\",\n               diag = \"l\",\n               tl.col = \"red\")\n\n\n\n\nNotice that argument lower and upper are used to define the visualisation method used. In this case ellipse is used to map the lower half of the corrgram and numerical matrix (i.e. number) is used to map the upper half of the corrgram. The argument tl.pos, on the other, is used to specify the placement of the axis label. Lastly, the diag argument is used to specify the glyph on the principal diagonal of the corrgram.\n\n\n\nIn statistical analysis, we are also interested to know which pair of variables their correlation coefficients are statistically significant.\nFigure below shows a corrgram combined with the significant test. The corrgram reveals that not all correlation pairs are statistically significant. For example the correlation between total sulfur dioxide and free surfur dioxide is statistically significant at significant level of 0.1 but not the pair between total sulfur dioxide and citric acid.\n\nWith corrplot package, we can use the cor.mtest() to compute the p-values and confidence interval for each pair of variables.\n\nwine.sig = cor.mtest(wine.cor, conf.level= .95)\n\nWe can then use the p.mat argument of corrplot function as shown in the code chunk below.\n\ncorrplot(wine.cor,\n         method = \"number\",\n         type = \"lower\",\n         diag = FALSE,\n         tl.col = \"black\",\n         tl.srt = 45,\n         p.mat = wine.sig$p,\n         sig.level = .05)\n\n\n\n\n\n\n\nMatrix reorder is very important for mining the hiden structure and pattern in a corrgram. By default, the order of attributes of a corrgram is sorted according to the correlation matrix (i.e. “original”). The default setting can be over-write by using the order argument of corrplot(). Currently, corrplot package support four sorting methods, they are:\n\n“AOE” is for the angular order of the eigenvectors. See Michael Friendly (2002) for details.\n“FPC” for the first principal component order.\n“hclust” for hierarchical clustering order, and “hclust.method” for the agglomeration method to be used.\n\n“hclust.method” should be one of “ward”, “single”, “complete”, “average”, “mcquitty”, “median” or “centroid”.\n\n“alphabet” for alphabetical order.\n\n“AOE”, “FPC”, “hclust”, “alphabet”. More algorithms can be found in seriation package.\n\ncorrplot.mixed(wine.cor, \n               lower = \"ellipse\", \n               upper = \"number\",\n               tl.pos = \"lt\",\n               diag = \"l\",\n               order=\"AOE\",\n               tl.col = \"black\")\n\n\n\n\n\n\n\nIf using hclust, corrplot() can draw rectangles around the corrgram based on the results of hierarchical clustering.\n\ncorrplot(wine.cor, \n         method = \"ellipse\", \n         tl.pos = \"lt\",\n         tl.col = \"black\",\n         order=\"hclust\",\n         hclust.method = \"ward.D\",\n         addrect = 3)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05b/Hands-on_Ex05b.html#visualising-correlation-matrix-using-corrgram-package",
    "href": "Hands-on_Ex/Hands-on_Ex05b/Hands-on_Ex05b.html#visualising-correlation-matrix-using-corrgram-package",
    "title": "Hands-on Exercise 5b",
    "section": "",
    "text": "corrgram(wine,\n         order = T,\n         lower.panel = panel.bar,\n         upper.panel = panel.ellipse,\n         cex.labels = 0.5)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05b/Hands-on_Ex05b.html#visualising-correlation-matrix-using-ellipse-package",
    "href": "Hands-on_Ex/Hands-on_Ex05b/Hands-on_Ex05b.html#visualising-correlation-matrix-using-ellipse-package",
    "title": "Hands-on Exercise 5b",
    "section": "",
    "text": "plotcorr(wine.cor,\n         col = c(\"blue\", \"red\"),\n         type = \"lower\",\n         diag = F)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05b/Hands-on_Ex05b.html#reference",
    "href": "Hands-on_Ex/Hands-on_Ex05b/Hands-on_Ex05b.html#reference",
    "title": "Hands-on Exercise 5b",
    "section": "",
    "text": "Michael Friendly (2002). “Corrgrams: Exploratory displays for correlation matrices”. The American Statistician, 56, 316–324.\nD.J. Murdoch, E.D. Chow (1996). “A graphical display of large correlation matrices”. The American Statistician, 50, 178–180.\n\n\n\nggcormat() of ggstatsplot package\nggscatmat and ggpairs of GGally.\ncorrplot. A graphical display of a correlation matrix or general matrix. It also contains some algorithms to do matrix reordering. In addition, corrplot is good at details, including choosing color, text labels, color labels, layout, etc.\ncorrgram calculates correlation of variables and displays the results graphically. Included panel functions can display points, shading, ellipses, and correlation values with confidence intervals."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04d/Hands-on_Ex04d.html",
    "href": "Hands-on_Ex/Hands-on_Ex04d/Hands-on_Ex04d.html",
    "title": "Hands-on Exercise 4d",
    "section": "",
    "text": "Funnel plot is a specially designed data visualisation for conducting unbiased comparison between outlets, stores or business entities. By the end of this hands-on exercise, you will gain hands-on experience on:\n\nplotting funnel plots by using funnelPlotR package,\nplotting static funnel plot by using ggplot2 package, and\nplotting interactive funnel plot by using both plotly R and ggplot2 packages.\n\n\n\n\nIn this exercise, four R packages will be used. They are:\n\nreadr for importing csv into R.\nFunnelPlotR for creating funnel plot.\nggplot2 for creating funnel plot manually.\nknitr for building static html table.\nplotly for creating interactive funnel plot.\n\n\npacman::p_load(tidyverse, FunnelPlotR, plotly, knitr)\n\n\n\n\nIn this section, COVID-19_DKI_Jakarta will be used. The data was downloaded from Open Data Covid-19 Provinsi DKI Jakarta portal. For this hands-on exercise, we are going to compare the cumulative COVID-19 cases and death by sub-district (i.e. kelurahan) as at 31st July 2021, DKI Jakarta.\nThe code chunk below imports the data into R and save it into a tibble data frame object called covid19.\n\ncovid19 &lt;- read_csv(\"data/COVID-19_DKI_Jakarta.csv\") %&gt;% \n  mutate_if(is.character, as.factor)\n\n\n\n\nFunnelPlotR package uses ggplot to generate funnel plots. It requires a numerator (events of interest), denominator (population to be considered) and group. The key arguments selected for customisation are:\n\nlimit: plot limits (95 or 99).\nlabel_outliers: to label outliers (true or false).\nPoisson_limits: to add Poisson limits to the plot.\nOD_adjust: to add overdispersed limits to the plot.\nxrange and yrange: to specify the range to display for axes, acts like a zoom function.\nOther aesthetic components such as graph title, axis labels etc.\n\n\n\nThe code chunk below plots a funnel plot.\n\nfunnel_plot(\n  numerator=covid19$Positive,\n  denominator = covid19$Death,\n  group=covid19$`Sub-district`\n)\n\n\n\n\nA funnel plot object with 267 points of which 0 are outliers. \nPlot is adjusted for overdispersion. \n\n\nA funnel plot object with 267 points of which 0 are outliers. Plot is adjusted for overdispersion.\nThings to learn from the code chunk above.\n\ngroup in this function is different from the scatterplot. Here, it defines the level of the points to be plotted i.e. Sub-district, District or City. If Cityc is chosen, there are only six data points.\nBy default, data_typeargument is “SR”.\nlimit: Plot limits, accepted values are: 95 or 99, corresponding to 95% or 99.8% quantiles of the distribution.\n\n\n\n\nThe code chunk below plots a funnel plot.\n\nfunnel_plot(\n  numerator=covid19$Death,\n  denominator=covid19$Positive,\n  group=covid19$`Sub-district`,\n  data_type=\"PR\",    #&lt;&lt;\n  x_range=c(0,6500),  #&lt;&lt;\n  y_range=c(0, 0.05) #&lt;&lt;\n)\n\n\n\n\nA funnel plot object with 267 points of which 7 are outliers. \nPlot is adjusted for overdispersion. \n\n\nThings to learn from the code chunk above. + data_type argument is used to change from default “SR” to “PR” (i.e. proportions). + xrange and yrange are used to set the range of x-axis and y-axis\n\n\n\nThe code chunk below plots a funnel plot.\n\nfunnel_plot(\n  numerator=covid19$Death,\n  denominator = covid19$Positive,\n  group = covid19$`Sub-district`,\n  data_type = \"PR\",\n  x_range = c(0,6500),\n  y_range = c(0,0.05),\n  label = NA,\n  title = \"Cumulative COVID-19 Fatality Rate by Cumulative Total Number of Covid-19 Positive cases\",    #&lt;&lt;\n  x_label = \"Cumulative COVID-19 Positive Cases\",   #&lt;&lt;\n  y_label = \"Cumulative Fatality Rate\"   #&lt;&lt;\n)\n\n\n\n\nA funnel plot object with 267 points of which 7 are outliers. \nPlot is adjusted for overdispersion. \n\n\nThings to learn from the code chunk above.\n\nlabel = NA argument is to removed the default label outliers feature.\ntitle argument is used to add plot title.\nx_label and y_label arguments are used to add/edit x-axis and y-axis titles.\n\n\n\n\n\nIn this section, you will gain hands-on experience on building funnel plots step-by-step by using ggplot2. It aims to enhance you working experience of ggplot2 to customise speciallised data visualisation like funnel plot.\n\n\nTo plot the funnel plot from scratch, we need to derive cumulative death rate and standard error of cumulative death rate.\n\ndf &lt;- covid19 %&gt;% \n  mutate(rate = Death/Positive) %&gt;% \n  mutate(rate.se = sqrt((rate*(1-rate))/(Positive))) %&gt;% \n  filter(rate&gt;0)\n\nNext, the fit.mean is computed by using the code chunk below.\n\nfit.mean &lt;- weighted.mean(df$rate, 1/df$rate.se^2)\n\n\n\n\nThe code chunk below is used to compute the lower and upper limits for 95% confidence interval.\n\nnumber.seq &lt;- seq(1, max(df$Positive), 1)\nnumber.ll95 &lt;- fit.mean - 1.96 * sqrt((fit.mean*(1-fit.mean)) / (number.seq))\nnumber.ul95 &lt;- fit.mean + 1.96 * sqrt((fit.mean*(1-fit.mean)) / (number.seq))\nnumber.ll999 &lt;- fit.mean - 3.29 * sqrt((fit.mean*(1-fit.mean)) / (number.seq))\nnumber.ul999 &lt;- fit.mean + 3.29 * sqrt((fit.mean*(1-fit.mean)) / (number.seq))\ndfCI &lt;- data.frame(number.ll95, number.ul95, number.ll999, number.ul999, number.seq, fit.mean)\n\n\n\n\nIn the code chunk below, ggplot2 functions are used to plot a static funnel plot.\n\np &lt;- ggplot(df,\n            aes(x=Positive, y=rate)) +\n  geom_point(aes(label=`Sub-district`),\n             alpha=0.4) +\n  geom_line(data = dfCI,\n            aes(x=number.seq,\n                y=number.ll95),\n            size = 0.4,\n            color = \"grey40\",\n            linetype = \"dashed\") +\n  geom_line(data = dfCI,\n            aes(x=number.seq,\n                y=number.ul95),\n            size = 0.4,\n            color = \"grey40\",\n            linetype = \"dashed\") +\n  geom_line(data=dfCI,\n            aes(x=number.seq,\n                y=number.ll999),\n            size=0.4,\n            color=\"grey40\") +\n  geom_line(data=dfCI,\n            aes(x=number.seq,\n                y=number.ul999),\n            size=0.4,\n            color=\"grey40\") +\n  geom_hline(data=dfCI,\n             aes(yintercept=fit.mean),\n             size=0.4,\n             color=\"grey40\") +\n  coord_cartesian(ylim=c(0,0.05)) +\n  annotate(\"text\", x = 1, y = -0.13, label=\"95%\", size=3, color = \"grey40\") +\n  annotate(\"text\", x = 4.5, y = -0.18, label=\"99.9%\", size=3, color=\"grey40\") +\n  ggtitle(\"Cumulative Fatality Rate by Cumulative Number of COVID-19 Cases\") +\n  xlab(\"Cumulative Number of COVID-19 Cases\") +\n  ylab(\"Cumulative Fatality Rate\") +\n  theme_light() +\n  theme(plot.title = element_text(size=12),\n        legend.position = c(0.91, 0.85),\n        legend.title = element_text(size=7),\n        legend.text = element_text(size=7),\n        legend.background = element_rect(color = \"grey60\", linetype = \"dotted\"),\n        legend.key.height = unit(0.3, \"cm\"))\n\np\n\n\n\n\n\n\n\nThe funnel plot created using ggplot2 functions can be made interactive with ggplotly() of plotly r package.\n\nfp_ggplotly &lt;- ggplotly(p,\n                        tooltip = c(\"label\", \n                                    \"x\", \n                                    \"y\"))\n\nfp_ggplotly\n\n\n\n\n\n\n\n\n\n\nfunnelPlotR package.\nFunnel Plots for Indirectly-standardised ratios.\nChanging funnel plot options\nggplot2 package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04d/Hands-on_Ex04d.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex04d/Hands-on_Ex04d.html#overview",
    "title": "Hands-on Exercise 4d",
    "section": "",
    "text": "Funnel plot is a specially designed data visualisation for conducting unbiased comparison between outlets, stores or business entities. By the end of this hands-on exercise, you will gain hands-on experience on:\n\nplotting funnel plots by using funnelPlotR package,\nplotting static funnel plot by using ggplot2 package, and\nplotting interactive funnel plot by using both plotly R and ggplot2 packages."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04d/Hands-on_Ex04d.html#installing-and-launching-r-packages",
    "href": "Hands-on_Ex/Hands-on_Ex04d/Hands-on_Ex04d.html#installing-and-launching-r-packages",
    "title": "Hands-on Exercise 4d",
    "section": "",
    "text": "In this exercise, four R packages will be used. They are:\n\nreadr for importing csv into R.\nFunnelPlotR for creating funnel plot.\nggplot2 for creating funnel plot manually.\nknitr for building static html table.\nplotly for creating interactive funnel plot.\n\n\npacman::p_load(tidyverse, FunnelPlotR, plotly, knitr)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04d/Hands-on_Ex04d.html#importing-data",
    "href": "Hands-on_Ex/Hands-on_Ex04d/Hands-on_Ex04d.html#importing-data",
    "title": "Hands-on Exercise 4d",
    "section": "",
    "text": "In this section, COVID-19_DKI_Jakarta will be used. The data was downloaded from Open Data Covid-19 Provinsi DKI Jakarta portal. For this hands-on exercise, we are going to compare the cumulative COVID-19 cases and death by sub-district (i.e. kelurahan) as at 31st July 2021, DKI Jakarta.\nThe code chunk below imports the data into R and save it into a tibble data frame object called covid19.\n\ncovid19 &lt;- read_csv(\"data/COVID-19_DKI_Jakarta.csv\") %&gt;% \n  mutate_if(is.character, as.factor)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04d/Hands-on_Ex04d.html#funnelplotr-methods",
    "href": "Hands-on_Ex/Hands-on_Ex04d/Hands-on_Ex04d.html#funnelplotr-methods",
    "title": "Hands-on Exercise 4d",
    "section": "",
    "text": "FunnelPlotR package uses ggplot to generate funnel plots. It requires a numerator (events of interest), denominator (population to be considered) and group. The key arguments selected for customisation are:\n\nlimit: plot limits (95 or 99).\nlabel_outliers: to label outliers (true or false).\nPoisson_limits: to add Poisson limits to the plot.\nOD_adjust: to add overdispersed limits to the plot.\nxrange and yrange: to specify the range to display for axes, acts like a zoom function.\nOther aesthetic components such as graph title, axis labels etc.\n\n\n\nThe code chunk below plots a funnel plot.\n\nfunnel_plot(\n  numerator=covid19$Positive,\n  denominator = covid19$Death,\n  group=covid19$`Sub-district`\n)\n\n\n\n\nA funnel plot object with 267 points of which 0 are outliers. \nPlot is adjusted for overdispersion. \n\n\nA funnel plot object with 267 points of which 0 are outliers. Plot is adjusted for overdispersion.\nThings to learn from the code chunk above.\n\ngroup in this function is different from the scatterplot. Here, it defines the level of the points to be plotted i.e. Sub-district, District or City. If Cityc is chosen, there are only six data points.\nBy default, data_typeargument is “SR”.\nlimit: Plot limits, accepted values are: 95 or 99, corresponding to 95% or 99.8% quantiles of the distribution.\n\n\n\n\nThe code chunk below plots a funnel plot.\n\nfunnel_plot(\n  numerator=covid19$Death,\n  denominator=covid19$Positive,\n  group=covid19$`Sub-district`,\n  data_type=\"PR\",    #&lt;&lt;\n  x_range=c(0,6500),  #&lt;&lt;\n  y_range=c(0, 0.05) #&lt;&lt;\n)\n\n\n\n\nA funnel plot object with 267 points of which 7 are outliers. \nPlot is adjusted for overdispersion. \n\n\nThings to learn from the code chunk above. + data_type argument is used to change from default “SR” to “PR” (i.e. proportions). + xrange and yrange are used to set the range of x-axis and y-axis\n\n\n\nThe code chunk below plots a funnel plot.\n\nfunnel_plot(\n  numerator=covid19$Death,\n  denominator = covid19$Positive,\n  group = covid19$`Sub-district`,\n  data_type = \"PR\",\n  x_range = c(0,6500),\n  y_range = c(0,0.05),\n  label = NA,\n  title = \"Cumulative COVID-19 Fatality Rate by Cumulative Total Number of Covid-19 Positive cases\",    #&lt;&lt;\n  x_label = \"Cumulative COVID-19 Positive Cases\",   #&lt;&lt;\n  y_label = \"Cumulative Fatality Rate\"   #&lt;&lt;\n)\n\n\n\n\nA funnel plot object with 267 points of which 7 are outliers. \nPlot is adjusted for overdispersion. \n\n\nThings to learn from the code chunk above.\n\nlabel = NA argument is to removed the default label outliers feature.\ntitle argument is used to add plot title.\nx_label and y_label arguments are used to add/edit x-axis and y-axis titles."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04d/Hands-on_Ex04d.html#funnel-plot-for-fair-visual-comparison-ggplot2-methods",
    "href": "Hands-on_Ex/Hands-on_Ex04d/Hands-on_Ex04d.html#funnel-plot-for-fair-visual-comparison-ggplot2-methods",
    "title": "Hands-on Exercise 4d",
    "section": "",
    "text": "In this section, you will gain hands-on experience on building funnel plots step-by-step by using ggplot2. It aims to enhance you working experience of ggplot2 to customise speciallised data visualisation like funnel plot.\n\n\nTo plot the funnel plot from scratch, we need to derive cumulative death rate and standard error of cumulative death rate.\n\ndf &lt;- covid19 %&gt;% \n  mutate(rate = Death/Positive) %&gt;% \n  mutate(rate.se = sqrt((rate*(1-rate))/(Positive))) %&gt;% \n  filter(rate&gt;0)\n\nNext, the fit.mean is computed by using the code chunk below.\n\nfit.mean &lt;- weighted.mean(df$rate, 1/df$rate.se^2)\n\n\n\n\nThe code chunk below is used to compute the lower and upper limits for 95% confidence interval.\n\nnumber.seq &lt;- seq(1, max(df$Positive), 1)\nnumber.ll95 &lt;- fit.mean - 1.96 * sqrt((fit.mean*(1-fit.mean)) / (number.seq))\nnumber.ul95 &lt;- fit.mean + 1.96 * sqrt((fit.mean*(1-fit.mean)) / (number.seq))\nnumber.ll999 &lt;- fit.mean - 3.29 * sqrt((fit.mean*(1-fit.mean)) / (number.seq))\nnumber.ul999 &lt;- fit.mean + 3.29 * sqrt((fit.mean*(1-fit.mean)) / (number.seq))\ndfCI &lt;- data.frame(number.ll95, number.ul95, number.ll999, number.ul999, number.seq, fit.mean)\n\n\n\n\nIn the code chunk below, ggplot2 functions are used to plot a static funnel plot.\n\np &lt;- ggplot(df,\n            aes(x=Positive, y=rate)) +\n  geom_point(aes(label=`Sub-district`),\n             alpha=0.4) +\n  geom_line(data = dfCI,\n            aes(x=number.seq,\n                y=number.ll95),\n            size = 0.4,\n            color = \"grey40\",\n            linetype = \"dashed\") +\n  geom_line(data = dfCI,\n            aes(x=number.seq,\n                y=number.ul95),\n            size = 0.4,\n            color = \"grey40\",\n            linetype = \"dashed\") +\n  geom_line(data=dfCI,\n            aes(x=number.seq,\n                y=number.ll999),\n            size=0.4,\n            color=\"grey40\") +\n  geom_line(data=dfCI,\n            aes(x=number.seq,\n                y=number.ul999),\n            size=0.4,\n            color=\"grey40\") +\n  geom_hline(data=dfCI,\n             aes(yintercept=fit.mean),\n             size=0.4,\n             color=\"grey40\") +\n  coord_cartesian(ylim=c(0,0.05)) +\n  annotate(\"text\", x = 1, y = -0.13, label=\"95%\", size=3, color = \"grey40\") +\n  annotate(\"text\", x = 4.5, y = -0.18, label=\"99.9%\", size=3, color=\"grey40\") +\n  ggtitle(\"Cumulative Fatality Rate by Cumulative Number of COVID-19 Cases\") +\n  xlab(\"Cumulative Number of COVID-19 Cases\") +\n  ylab(\"Cumulative Fatality Rate\") +\n  theme_light() +\n  theme(plot.title = element_text(size=12),\n        legend.position = c(0.91, 0.85),\n        legend.title = element_text(size=7),\n        legend.text = element_text(size=7),\n        legend.background = element_rect(color = \"grey60\", linetype = \"dotted\"),\n        legend.key.height = unit(0.3, \"cm\"))\n\np\n\n\n\n\n\n\n\nThe funnel plot created using ggplot2 functions can be made interactive with ggplotly() of plotly r package.\n\nfp_ggplotly &lt;- ggplotly(p,\n                        tooltip = c(\"label\", \n                                    \"x\", \n                                    \"y\"))\n\nfp_ggplotly"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04d/Hands-on_Ex04d.html#references",
    "href": "Hands-on_Ex/Hands-on_Ex04d/Hands-on_Ex04d.html#references",
    "title": "Hands-on Exercise 4d",
    "section": "",
    "text": "funnelPlotR package.\nFunnel Plots for Indirectly-standardised ratios.\nChanging funnel plot options\nggplot2 package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04b/Hands-on_Ex04b.html",
    "href": "Hands-on_Ex/Hands-on_Ex04b/Hands-on_Ex04b.html",
    "title": "Hands-on Exercise 4b",
    "section": "",
    "text": "In this hands-on exercise, you will gain hands-on experience on using:\n\nggstatsplot package to create visual graphics with rich statistical information,\nperformance package to visualise model diagnostics, and\nparameters package to visualise model parameters\n\n\n\n\n\nggstatsplot is an extension of ggplot2 package for creating graphics with details from statistical tests included in the information-rich plots themselves.\n\nTo provide alternative statistical inference methods by default.\nTo follow best practices for statistical reporting. For all statistical tests reported in the plots, the default template abides by the APA gold standard for statistical reporting. For example, here are results from a robust t-test:\n\n\n\n\n\n\n\nIn this exercise, ggstatsplot and tidyverse will be used.\n\npacman::p_load(ggstatsplot, tidyverse)\n\n\n\n\n\nexam = read_csv(\"data/Exam_data.csv\")\n\n\n\n\nIn the code chunk below, gghistostats() is used to to build an visual of one-sample test on English scores.\n\nset.seed(1234)\n\ngghistostats(data=exam,\n             x=ENGLISH,\n             type=\"bayes\",\n             test.value=60,\n             xlab=\"English scores\")\n\n\n\n\nDefault information: - statistical details - Bayes Factor - sample sizes - distribution summary\n\n\n\n\nA Bayes factor is the ratio of the likelihood of one particular hypothesis to the likelihood of another. It can be interpreted as a measure of the strength of evidence in favor of one theory among two competing theories.\nThat’s because the Bayes factor gives us a way to evaluate the data in favor of a null hypothesis, and to use external information to do so. It tells us what the weight of the evidence is in favor of a given hypothesis.\nWhen we are comparing two hypotheses, H1 (the alternate hypothesis) and H0 (the null hypothesis), the Bayes Factor is often written as B10. It can be defined mathematically as\n\n\n\nThe Schwarz criterion is one of the easiest ways to calculate rough approximation of the Bayes Factor.\n\n\n\n\nA Bayes Factor can be any positive number. One of the most common interpretations is this one—first proposed by Harold Jeffereys (1961) and slightly modified by Lee and Wagenmakers in 2013:\n\n\n\nIn the code chunk below, ggbetweenstats() is used to build a visual for two-sample mean test of Maths scores by gender.\n\nggbetweenstats(data=exam,\n               x=GENDER,\n               y=MATHS,\n               type=\"np\",\n               messages=FALSE)\n\n\n\n\nDefault information: - statistical details - Bayes Factor - sample sizes - distribution summary\n\n\n\nIn the code chunk below, ggbetweenstats() is used to build a visual for One-way ANOVA test on English score by race.\n\nggbetweenstats(data=exam,\n               x=RACE,\n               y=ENGLISH,\n               type=\"p\",\n               mean.ci=T,\n               pairwise_comparisons=T,\n               pairwise.display=\"s\",\n               p.adjust.method=\"fdr\",\n               messages=F)\n\n\n\n\n3.7.1 ggbetweenstats - Summary of tests\n{Missing links}\n\n\n\nIn the code chunk below, ggscatterstats() is used to build a visual for Significant Test of Correlation between Maths scores and English scores.\n\nggscatterstats(data=exam,\n               x=MATHS,\n               y=ENGLISH,\n               marginal=F\n)\n\n\n\n\n\n\n\nIn the code chunk below, the Maths scores is binned into a 4-class variable by using cut().\n\nexam1 &lt;- exam %&gt;% \n  mutate(MATHS_bins = \n           cut(MATHS,\n               breaks = c(0,60,75,85,100)))\n\nIn this code chunk below ggbarstats() is used to build a visual for Significant Test of Association.\n\nggbarstats(exam1,\n           x=MATHS_bins,\n           y=GENDER)\n\n\n\n\n\n\n\n\nIn this section, you will learn how to visualise model diagnostic and model parameters by using parameters package.\n\nToyota Corolla case study will be used. The purpose of study is to build a model to discover factors affecting prices of used-cars by taking into consideration a set of explanatory variables.\n\n\n\n\n\n\n\npacman::p_load(readxl, performance, parameters, see)\n\n\n\n\nIn the code chunk below, read_xls() of readxl package is used to import the data worksheet of ToyotaCorolla.xls workbook into R.\n\ncar_resale &lt;- read_xls(\"data/ToyotaCorolla.xls\", \n                       \"data\")\ncar_resale\n\n# A tibble: 1,436 × 38\n      Id Model    Price Age_08_04 Mfg_Month Mfg_Year     KM Quarterly_Tax Weight\n   &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;         &lt;dbl&gt;  &lt;dbl&gt;\n 1    81 TOYOTA … 18950        25         8     2002  20019           100   1180\n 2     1 TOYOTA … 13500        23        10     2002  46986           210   1165\n 3     2 TOYOTA … 13750        23        10     2002  72937           210   1165\n 4     3  TOYOTA… 13950        24         9     2002  41711           210   1165\n 5     4 TOYOTA … 14950        26         7     2002  48000           210   1165\n 6     5 TOYOTA … 13750        30         3     2002  38500           210   1170\n 7     6 TOYOTA … 12950        32         1     2002  61000           210   1170\n 8     7  TOYOTA… 16900        27         6     2002  94612           210   1245\n 9     8 TOYOTA … 18600        30         3     2002  75889           210   1245\n10    44 TOYOTA … 16950        27         6     2002 110404           234   1255\n# ℹ 1,426 more rows\n# ℹ 29 more variables: Guarantee_Period &lt;dbl&gt;, HP_Bin &lt;chr&gt;, CC_bin &lt;chr&gt;,\n#   Doors &lt;dbl&gt;, Gears &lt;dbl&gt;, Cylinders &lt;dbl&gt;, Fuel_Type &lt;chr&gt;, Color &lt;chr&gt;,\n#   Met_Color &lt;dbl&gt;, Automatic &lt;dbl&gt;, Mfr_Guarantee &lt;dbl&gt;,\n#   BOVAG_Guarantee &lt;dbl&gt;, ABS &lt;dbl&gt;, Airbag_1 &lt;dbl&gt;, Airbag_2 &lt;dbl&gt;,\n#   Airco &lt;dbl&gt;, Automatic_airco &lt;dbl&gt;, Boardcomputer &lt;dbl&gt;, CD_Player &lt;dbl&gt;,\n#   Central_Lock &lt;dbl&gt;, Powered_Windows &lt;dbl&gt;, Power_Steering &lt;dbl&gt;, …\n\n\n\n\n\nThe code chunk below is used to calibrate a multiple linear regression model by using lm() of Base Stats of R.\n\nmodel &lt;- lm(Price~Age_08_04 + Mfg_Year + KM + Weight + Guarantee_Period, data = car_resale)\nmodel\n\n\nCall:\nlm(formula = Price ~ Age_08_04 + Mfg_Year + KM + Weight + Guarantee_Period, \n    data = car_resale)\n\nCoefficients:\n     (Intercept)         Age_08_04          Mfg_Year                KM  \n      -2.637e+06        -1.409e+01         1.315e+03        -2.323e-02  \n          Weight  Guarantee_Period  \n       1.903e+01         2.770e+01  \n\n\n\n\n\nIn the code chunk, check_collinearity() of performance package.\n\ncheck_collinearity(model)\n\n# Check for Multicollinearity\n\nLow Correlation\n\n             Term  VIF     VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n               KM 1.46 [ 1.37,  1.57]         1.21      0.68     [0.64, 0.73]\n           Weight 1.41 [ 1.32,  1.51]         1.19      0.71     [0.66, 0.76]\n Guarantee_Period 1.04 [ 1.01,  1.17]         1.02      0.97     [0.86, 0.99]\n\nHigh Correlation\n\n      Term   VIF     VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n Age_08_04 31.07 [28.08, 34.38]         5.57      0.03     [0.03, 0.04]\n  Mfg_Year 31.16 [28.16, 34.48]         5.58      0.03     [0.03, 0.04]\n\n\n\ncheck_c &lt;- check_collinearity(model)\nplot(check_c)\n\n\n\n\n\n\n\nIn the code chunk, check_normality() of performance package.\n\nmodel1 &lt;- lm(Price ~ Age_08_04 + KM + Weight + Guarantee_Period, data = car_resale)\n\n\ncheck_n &lt;- check_normality(model1)\nplot(check_n)\n\n\n\n\n\n\n\nIn the code chunk, check_heteroscedasticity() of performance package.\n\ncheck_h &lt;- check_heteroscedasticity(model1)\nplot(check_h)\n\n\n\n\n\n\n\n\ncheck_model(model1)\n\n\n\n\n\n\n\nIn the code below, plot() of see package and parameters() of parameters package is used to visualise the parameters of a regression model.\n\nplot(parameters(model1))\n\n\n\n\n\n\n\n\nggcoefstats(model1,\n            output = \"plot\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04b/Hands-on_Ex04b.html#learning-outcome",
    "href": "Hands-on_Ex/Hands-on_Ex04b/Hands-on_Ex04b.html#learning-outcome",
    "title": "Hands-on Exercise 4b",
    "section": "",
    "text": "In this hands-on exercise, you will gain hands-on experience on using:\n\nggstatsplot package to create visual graphics with rich statistical information,\nperformance package to visualise model diagnostics, and\nparameters package to visualise model parameters"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04b/Hands-on_Ex04b.html#visual-statistical-analysis-with-ggstatsplot",
    "href": "Hands-on_Ex/Hands-on_Ex04b/Hands-on_Ex04b.html#visual-statistical-analysis-with-ggstatsplot",
    "title": "Hands-on Exercise 4b",
    "section": "",
    "text": "ggstatsplot is an extension of ggplot2 package for creating graphics with details from statistical tests included in the information-rich plots themselves.\n\nTo provide alternative statistical inference methods by default.\nTo follow best practices for statistical reporting. For all statistical tests reported in the plots, the default template abides by the APA gold standard for statistical reporting. For example, here are results from a robust t-test:"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04b/Hands-on_Ex04b.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex04b/Hands-on_Ex04b.html#getting-started",
    "title": "Hands-on Exercise 4b",
    "section": "",
    "text": "In this exercise, ggstatsplot and tidyverse will be used.\n\npacman::p_load(ggstatsplot, tidyverse)\n\n\n\n\n\nexam = read_csv(\"data/Exam_data.csv\")\n\n\n\n\nIn the code chunk below, gghistostats() is used to to build an visual of one-sample test on English scores.\n\nset.seed(1234)\n\ngghistostats(data=exam,\n             x=ENGLISH,\n             type=\"bayes\",\n             test.value=60,\n             xlab=\"English scores\")\n\n\n\n\nDefault information: - statistical details - Bayes Factor - sample sizes - distribution summary\n\n\n\n\nA Bayes factor is the ratio of the likelihood of one particular hypothesis to the likelihood of another. It can be interpreted as a measure of the strength of evidence in favor of one theory among two competing theories.\nThat’s because the Bayes factor gives us a way to evaluate the data in favor of a null hypothesis, and to use external information to do so. It tells us what the weight of the evidence is in favor of a given hypothesis.\nWhen we are comparing two hypotheses, H1 (the alternate hypothesis) and H0 (the null hypothesis), the Bayes Factor is often written as B10. It can be defined mathematically as\n\n\n\nThe Schwarz criterion is one of the easiest ways to calculate rough approximation of the Bayes Factor.\n\n\n\n\nA Bayes Factor can be any positive number. One of the most common interpretations is this one—first proposed by Harold Jeffereys (1961) and slightly modified by Lee and Wagenmakers in 2013:\n\n\n\nIn the code chunk below, ggbetweenstats() is used to build a visual for two-sample mean test of Maths scores by gender.\n\nggbetweenstats(data=exam,\n               x=GENDER,\n               y=MATHS,\n               type=\"np\",\n               messages=FALSE)\n\n\n\n\nDefault information: - statistical details - Bayes Factor - sample sizes - distribution summary\n\n\n\nIn the code chunk below, ggbetweenstats() is used to build a visual for One-way ANOVA test on English score by race.\n\nggbetweenstats(data=exam,\n               x=RACE,\n               y=ENGLISH,\n               type=\"p\",\n               mean.ci=T,\n               pairwise_comparisons=T,\n               pairwise.display=\"s\",\n               p.adjust.method=\"fdr\",\n               messages=F)\n\n\n\n\n3.7.1 ggbetweenstats - Summary of tests\n{Missing links}\n\n\n\nIn the code chunk below, ggscatterstats() is used to build a visual for Significant Test of Correlation between Maths scores and English scores.\n\nggscatterstats(data=exam,\n               x=MATHS,\n               y=ENGLISH,\n               marginal=F\n)\n\n\n\n\n\n\n\nIn the code chunk below, the Maths scores is binned into a 4-class variable by using cut().\n\nexam1 &lt;- exam %&gt;% \n  mutate(MATHS_bins = \n           cut(MATHS,\n               breaks = c(0,60,75,85,100)))\n\nIn this code chunk below ggbarstats() is used to build a visual for Significant Test of Association.\n\nggbarstats(exam1,\n           x=MATHS_bins,\n           y=GENDER)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04b/Hands-on_Ex04b.html#visualising-models",
    "href": "Hands-on_Ex/Hands-on_Ex04b/Hands-on_Ex04b.html#visualising-models",
    "title": "Hands-on Exercise 4b",
    "section": "",
    "text": "In this section, you will learn how to visualise model diagnostic and model parameters by using parameters package.\n\nToyota Corolla case study will be used. The purpose of study is to build a model to discover factors affecting prices of used-cars by taking into consideration a set of explanatory variables."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04b/Hands-on_Ex04b.html#getting-started-1",
    "href": "Hands-on_Ex/Hands-on_Ex04b/Hands-on_Ex04b.html#getting-started-1",
    "title": "Hands-on Exercise 4b",
    "section": "",
    "text": "pacman::p_load(readxl, performance, parameters, see)\n\n\n\n\nIn the code chunk below, read_xls() of readxl package is used to import the data worksheet of ToyotaCorolla.xls workbook into R.\n\ncar_resale &lt;- read_xls(\"data/ToyotaCorolla.xls\", \n                       \"data\")\ncar_resale\n\n# A tibble: 1,436 × 38\n      Id Model    Price Age_08_04 Mfg_Month Mfg_Year     KM Quarterly_Tax Weight\n   &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;         &lt;dbl&gt;  &lt;dbl&gt;\n 1    81 TOYOTA … 18950        25         8     2002  20019           100   1180\n 2     1 TOYOTA … 13500        23        10     2002  46986           210   1165\n 3     2 TOYOTA … 13750        23        10     2002  72937           210   1165\n 4     3  TOYOTA… 13950        24         9     2002  41711           210   1165\n 5     4 TOYOTA … 14950        26         7     2002  48000           210   1165\n 6     5 TOYOTA … 13750        30         3     2002  38500           210   1170\n 7     6 TOYOTA … 12950        32         1     2002  61000           210   1170\n 8     7  TOYOTA… 16900        27         6     2002  94612           210   1245\n 9     8 TOYOTA … 18600        30         3     2002  75889           210   1245\n10    44 TOYOTA … 16950        27         6     2002 110404           234   1255\n# ℹ 1,426 more rows\n# ℹ 29 more variables: Guarantee_Period &lt;dbl&gt;, HP_Bin &lt;chr&gt;, CC_bin &lt;chr&gt;,\n#   Doors &lt;dbl&gt;, Gears &lt;dbl&gt;, Cylinders &lt;dbl&gt;, Fuel_Type &lt;chr&gt;, Color &lt;chr&gt;,\n#   Met_Color &lt;dbl&gt;, Automatic &lt;dbl&gt;, Mfr_Guarantee &lt;dbl&gt;,\n#   BOVAG_Guarantee &lt;dbl&gt;, ABS &lt;dbl&gt;, Airbag_1 &lt;dbl&gt;, Airbag_2 &lt;dbl&gt;,\n#   Airco &lt;dbl&gt;, Automatic_airco &lt;dbl&gt;, Boardcomputer &lt;dbl&gt;, CD_Player &lt;dbl&gt;,\n#   Central_Lock &lt;dbl&gt;, Powered_Windows &lt;dbl&gt;, Power_Steering &lt;dbl&gt;, …\n\n\n\n\n\nThe code chunk below is used to calibrate a multiple linear regression model by using lm() of Base Stats of R.\n\nmodel &lt;- lm(Price~Age_08_04 + Mfg_Year + KM + Weight + Guarantee_Period, data = car_resale)\nmodel\n\n\nCall:\nlm(formula = Price ~ Age_08_04 + Mfg_Year + KM + Weight + Guarantee_Period, \n    data = car_resale)\n\nCoefficients:\n     (Intercept)         Age_08_04          Mfg_Year                KM  \n      -2.637e+06        -1.409e+01         1.315e+03        -2.323e-02  \n          Weight  Guarantee_Period  \n       1.903e+01         2.770e+01  \n\n\n\n\n\nIn the code chunk, check_collinearity() of performance package.\n\ncheck_collinearity(model)\n\n# Check for Multicollinearity\n\nLow Correlation\n\n             Term  VIF     VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n               KM 1.46 [ 1.37,  1.57]         1.21      0.68     [0.64, 0.73]\n           Weight 1.41 [ 1.32,  1.51]         1.19      0.71     [0.66, 0.76]\n Guarantee_Period 1.04 [ 1.01,  1.17]         1.02      0.97     [0.86, 0.99]\n\nHigh Correlation\n\n      Term   VIF     VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n Age_08_04 31.07 [28.08, 34.38]         5.57      0.03     [0.03, 0.04]\n  Mfg_Year 31.16 [28.16, 34.48]         5.58      0.03     [0.03, 0.04]\n\n\n\ncheck_c &lt;- check_collinearity(model)\nplot(check_c)\n\n\n\n\n\n\n\nIn the code chunk, check_normality() of performance package.\n\nmodel1 &lt;- lm(Price ~ Age_08_04 + KM + Weight + Guarantee_Period, data = car_resale)\n\n\ncheck_n &lt;- check_normality(model1)\nplot(check_n)\n\n\n\n\n\n\n\nIn the code chunk, check_heteroscedasticity() of performance package.\n\ncheck_h &lt;- check_heteroscedasticity(model1)\nplot(check_h)\n\n\n\n\n\n\n\n\ncheck_model(model1)\n\n\n\n\n\n\n\nIn the code below, plot() of see package and parameters() of parameters package is used to visualise the parameters of a regression model.\n\nplot(parameters(model1))\n\n\n\n\n\n\n\n\nggcoefstats(model1,\n            output = \"plot\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03b/Hands-on_Ex03b.html",
    "href": "Hands-on_Ex/Hands-on_Ex03b/Hands-on_Ex03b.html",
    "title": "Hands-on Exercise 3b - Off we go (Part II)",
    "section": "",
    "text": "When telling a visually-driven data story, animated graphics tends to attract the interest of the audience and make deeper impression than static graphics. In this hands-on exercise, we will learn how to create animated data visualisation by using gganimate and plotly r packages. At the same time, you will also learn how to (i) reshape data by using tidyr package, and (ii) process, wrangle and transform data by using dplyr package.\n\n\nWhen creating animations, the plot does not actually move. Instead, many individual plots are built and then stitched together as movie frames, just like an old-school flip book or cartoon. Each frame is a different plot when conveying motion, which is built using some relevant subset of the aggregate data. The subset drives the flow of the animation when stitched back together.\n\n\n\n\nBefore we dive into the steps for creating an animated statistical graph, it’s important to understand some of the key concepts and terminology related to this type of visualization.\n\nFrame: In an animated line graph, each frame represents a different point in time or a different category. When the frame changes, the data points on the graph are updated to reflect the new data.\nAnimation Attributes: The animation attributes are the settings that control how the animation behaves. For example, you can specify the duration of each frame, the easing function used to transition between frames, and whether to start the animation from the current frame or from the beginning.\n\n\n\n\n\n\n\nTip\n\n\n\nBefore you start making animated graphs, you should first ask yourself: Does it makes sense to go through the effort? If you are conducting an exploratory data analysis, a animated graphic may not be worth the time investment. However, if you are giving a presentation, a few well-placed animated graphics can help an audience connect with your topic remarkably better than static counterparts.\n\n\n\n\n\n\n\n\nFirst, write a code chunk to check, install and load the following R packages:\n\nplotly, R library for plotting interactive statistical graphs.\ngganimate, an ggplot extension for creating animated statistical graphs.\ngifski converts video frames to GIF animations using pngquant’s fancy features for efficient cross-frame palettes and temporal dithering. It produces animated GIFs that use thousands of colors per frame.\ngapminder: An excerpt of the data available at Gapminder.org. We just want to use its country_colors scheme.\ntidyverse, a family of modern R packages specially designed to support data science, analysis and communication task including creating static statistical graphs.\n\n\npacman::p_load(readxl, gifski, gapminder,\n               plotly, gganimate, tidyverse)\n\n\n\n\nIn this hands-on exercise, the Data worksheet from GlobalPopulation Excel workbook will be used.\nWrite a code chunk to import Data worksheet from GlobalPopulation Excel workbook by using appropriate R package from tidyverse family.\n\ncol &lt;- c(\"Country\", \"Continent\")\nglobalPop &lt;- read_xls(\"data/GlobalPopulation.xls\",\n                      sheet=\"Data\") %&gt;% \n  mutate_each_(funs(factor(.)), col) %&gt;% \n  mutate(Year = as.integer(Year))\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\n\nread_xls() of readxl package is used to import the Excel worksheet.\nmutate_each_() of dplyr package is used to convert all character data type into factor.\nmutate of dplyr package is used to convert data values of Year field into integer.\n\n\n\nUnfortunately, mutate_each_() was deprecated in dplyr 0.7.0. and funs() was deprecated in dplyr 0.8.0. In view of this, we will re-write the code by using mutate_at() as shown in the code chunk below.\n\ncol &lt;- c(\"Country\", \"Continent\")\nglobalPop &lt;- read_xls(\"data/GlobalPopulation.xls\",\n                      sheet=\"Data\") %&gt;% \n  mutate_at(col, as.factor) %&gt;% \n  mutate(Year = as.integer(Year))\n\nInstead of using mutate_at(), across() can also be used to derive the same outputs.\n\ncol &lt;- c(\"Country\", \"Continent\")\nglobalPop &lt;- read_xls(\"data/GlobalPopulation.xls\",\n                      sheet=\"Data\") %&gt;%\n  mutate(across(any_of(col), as.factor)) %&gt;%\n  mutate(Year = as.integer(Year))\n\n\n\n\n\ngganimate extends the grammar of graphics as implemented by ggplot2 to include the description of animation. It does this by providing a range of new grammar classes that can be added to the plot object in order to customise how it should change with time.\n\ntransition_*() defines how the data should be spread out and how it relates to itself across time.\nview_*() defines how the positional scales should change along the animation.\nshadow_*() defines how data from other points in time should be presented in the given point in time.\nenter_*()/exit_*() defines how new data should appear and how old data should disappear during the course of the animation.\nease_aes() defines how different aesthetics should be eased during transitions.\n\n\n\nIn the code chunk below, the basic ggplot2 functions are used to create a static bubble plot.\n\nggplot(globalPop,\n       aes(x=Old,\n           y=Young,\n           size = Population,\n           colour = Country)) +\n  geom_point(alpha=0.7,\n             show.legend=FALSE) +\n  scale_colour_manual(values=country_colors) +\n  scale_size(range = c(2,12)) +\n  labs(title = \"Year: {frame_time}\",\n       x = \"% Aged\",\n       y = \"% Young\")\n\n\n\n\n\n\n\nIn the code chunk below,\n\ntransition_time() of gganimate is used to create transition through distinct states in time (i.e. Year).\nease_aes() is used to control easing of aesthetics. The default is linear. Other methods are: quadratic, cubic, quartic, quintic, sine, circular, exponential, elastic, back, and bounce.\n\n\nggplot(globalPop,\n       aes(x=Old,\n           y=Young,\n           size=Population,\n           colour=Country)) +\n  geom_point(alpha=0.7,\n             show.legend=F) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range=c(2,12)) +\n  labs(title = \"Year: {frame_time}\",\n       x = \"% Aged\",\n       y = \"% Young\") +\n  transition_time(Year) +\n  ease_aes('linear')\n\n\n\n\n\n\n\n\nIn Plotly R package, both ggplotly() and plot_ly() support key frame animations through the frame argument/aesthetic. They also support an ids argument/aesthetic to ensure smooth transitions between objects with the same id (which helps facilitate object constancy).\n\n\nIn this sub-section, you will learn how to create an animated bubble plot by using ggplotly() method.\n\nThe plotThe code chunk\n\n\n\n\n\n\n\n\nThe animated bubble plot above includes a play/pause button and a slider component for controlling the animation\n\n\n\ngg &lt;- ggplot(globalPop,\n             aes(x=Old,\n                 y=Young,\n                 size=Population,\n                 colour=Country)) +\n  geom_point(aes(size=Population,\n                 frame=Year),\n             alpha=0.7,\n             show.legend=F) +\n  scale_colour_manual(values=country_colors) +\n  scale_size(range=c(2,12)) +\n  labs(x=\"% Aged\",\n       y=\"% Young\")\n\nggplotly(gg)\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\n\nAppropriate ggplot2 functions are used to create a static bubble plot. The output is then saved as an R object called gg.\nggplotly() is then used to convert the R graphic object into an animated svg object.\n\n\n\n\n\n\nNotice that although show.legend = FALSE argument was used, the legend still appears on the plot. To overcome this problem, theme(legend.position='none') should be used as shown in the plot and code chunk below.\n\nThe plotThe code chunk\n\n\n\n\n\n\n\n\n\n\n\ngg &lt;- ggplot(globalPop,\n             aes(x=Old,\n                 y=Young,\n                 size=Population,\n                 colour=Country)) +\n  geom_point(aes(size=Population,\n                 frame=Year),\n             alpha=0.7) +\n  scale_colour_manual(values=country_colors) +\n  scale_size(range=c(2,12)) +\n  labs(x=\"% Aged\",\n       y=\"% Young\") +\n  theme(legend.position = \"none\")\n\nggplotly(gg)\n\n\n\n\n\n\n\nIn this sub-section, you will learn how to create an animated bubble plot by using plot_ly() method.\n\nThe plotThe code chunk\n\n\n\n\n\n\n\n\n\n\n\nbp &lt;- globalPop %&gt;% \n  plot_ly(x=~Old,\n          y=~Young,\n          size=~Population,\n          color=~Continent,\n          sizes=c(2,100),\n          frame=~Year,\n          text=~Country,\n          hoverinfo=\"text\",\n          type=\"scatter\",\n          mode=\"markers\") %&gt;% \n  layout(showlegend=F)\nbp\n\n\n\n\n\n\n\n\n\nGetting Started\nVisit this link for a very interesting implementation of gganimate by your senior.\nBuilding an animation step-by-step with gganimate.\nCreating a composite gif with multiple gganimate panels"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03b/Hands-on_Ex03b.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex03b/Hands-on_Ex03b.html#overview",
    "title": "Hands-on Exercise 3b - Off we go (Part II)",
    "section": "",
    "text": "When telling a visually-driven data story, animated graphics tends to attract the interest of the audience and make deeper impression than static graphics. In this hands-on exercise, we will learn how to create animated data visualisation by using gganimate and plotly r packages. At the same time, you will also learn how to (i) reshape data by using tidyr package, and (ii) process, wrangle and transform data by using dplyr package.\n\n\nWhen creating animations, the plot does not actually move. Instead, many individual plots are built and then stitched together as movie frames, just like an old-school flip book or cartoon. Each frame is a different plot when conveying motion, which is built using some relevant subset of the aggregate data. The subset drives the flow of the animation when stitched back together.\n\n\n\n\nBefore we dive into the steps for creating an animated statistical graph, it’s important to understand some of the key concepts and terminology related to this type of visualization.\n\nFrame: In an animated line graph, each frame represents a different point in time or a different category. When the frame changes, the data points on the graph are updated to reflect the new data.\nAnimation Attributes: The animation attributes are the settings that control how the animation behaves. For example, you can specify the duration of each frame, the easing function used to transition between frames, and whether to start the animation from the current frame or from the beginning.\n\n\n\n\n\n\n\nTip\n\n\n\nBefore you start making animated graphs, you should first ask yourself: Does it makes sense to go through the effort? If you are conducting an exploratory data analysis, a animated graphic may not be worth the time investment. However, if you are giving a presentation, a few well-placed animated graphics can help an audience connect with your topic remarkably better than static counterparts."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03b/Hands-on_Ex03b.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex03b/Hands-on_Ex03b.html#getting-started",
    "title": "Hands-on Exercise 3b - Off we go (Part II)",
    "section": "",
    "text": "First, write a code chunk to check, install and load the following R packages:\n\nplotly, R library for plotting interactive statistical graphs.\ngganimate, an ggplot extension for creating animated statistical graphs.\ngifski converts video frames to GIF animations using pngquant’s fancy features for efficient cross-frame palettes and temporal dithering. It produces animated GIFs that use thousands of colors per frame.\ngapminder: An excerpt of the data available at Gapminder.org. We just want to use its country_colors scheme.\ntidyverse, a family of modern R packages specially designed to support data science, analysis and communication task including creating static statistical graphs.\n\n\npacman::p_load(readxl, gifski, gapminder,\n               plotly, gganimate, tidyverse)\n\n\n\n\nIn this hands-on exercise, the Data worksheet from GlobalPopulation Excel workbook will be used.\nWrite a code chunk to import Data worksheet from GlobalPopulation Excel workbook by using appropriate R package from tidyverse family.\n\ncol &lt;- c(\"Country\", \"Continent\")\nglobalPop &lt;- read_xls(\"data/GlobalPopulation.xls\",\n                      sheet=\"Data\") %&gt;% \n  mutate_each_(funs(factor(.)), col) %&gt;% \n  mutate(Year = as.integer(Year))\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\n\nread_xls() of readxl package is used to import the Excel worksheet.\nmutate_each_() of dplyr package is used to convert all character data type into factor.\nmutate of dplyr package is used to convert data values of Year field into integer.\n\n\n\nUnfortunately, mutate_each_() was deprecated in dplyr 0.7.0. and funs() was deprecated in dplyr 0.8.0. In view of this, we will re-write the code by using mutate_at() as shown in the code chunk below.\n\ncol &lt;- c(\"Country\", \"Continent\")\nglobalPop &lt;- read_xls(\"data/GlobalPopulation.xls\",\n                      sheet=\"Data\") %&gt;% \n  mutate_at(col, as.factor) %&gt;% \n  mutate(Year = as.integer(Year))\n\nInstead of using mutate_at(), across() can also be used to derive the same outputs.\n\ncol &lt;- c(\"Country\", \"Continent\")\nglobalPop &lt;- read_xls(\"data/GlobalPopulation.xls\",\n                      sheet=\"Data\") %&gt;%\n  mutate(across(any_of(col), as.factor)) %&gt;%\n  mutate(Year = as.integer(Year))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03b/Hands-on_Ex03b.html#animated-data-visualisation-gganimate-methods",
    "href": "Hands-on_Ex/Hands-on_Ex03b/Hands-on_Ex03b.html#animated-data-visualisation-gganimate-methods",
    "title": "Hands-on Exercise 3b - Off we go (Part II)",
    "section": "",
    "text": "gganimate extends the grammar of graphics as implemented by ggplot2 to include the description of animation. It does this by providing a range of new grammar classes that can be added to the plot object in order to customise how it should change with time.\n\ntransition_*() defines how the data should be spread out and how it relates to itself across time.\nview_*() defines how the positional scales should change along the animation.\nshadow_*() defines how data from other points in time should be presented in the given point in time.\nenter_*()/exit_*() defines how new data should appear and how old data should disappear during the course of the animation.\nease_aes() defines how different aesthetics should be eased during transitions.\n\n\n\nIn the code chunk below, the basic ggplot2 functions are used to create a static bubble plot.\n\nggplot(globalPop,\n       aes(x=Old,\n           y=Young,\n           size = Population,\n           colour = Country)) +\n  geom_point(alpha=0.7,\n             show.legend=FALSE) +\n  scale_colour_manual(values=country_colors) +\n  scale_size(range = c(2,12)) +\n  labs(title = \"Year: {frame_time}\",\n       x = \"% Aged\",\n       y = \"% Young\")\n\n\n\n\n\n\n\nIn the code chunk below,\n\ntransition_time() of gganimate is used to create transition through distinct states in time (i.e. Year).\nease_aes() is used to control easing of aesthetics. The default is linear. Other methods are: quadratic, cubic, quartic, quintic, sine, circular, exponential, elastic, back, and bounce.\n\n\nggplot(globalPop,\n       aes(x=Old,\n           y=Young,\n           size=Population,\n           colour=Country)) +\n  geom_point(alpha=0.7,\n             show.legend=F) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range=c(2,12)) +\n  labs(title = \"Year: {frame_time}\",\n       x = \"% Aged\",\n       y = \"% Young\") +\n  transition_time(Year) +\n  ease_aes('linear')"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03b/Hands-on_Ex03b.html#animated-data-visualisation-plotly",
    "href": "Hands-on_Ex/Hands-on_Ex03b/Hands-on_Ex03b.html#animated-data-visualisation-plotly",
    "title": "Hands-on Exercise 3b - Off we go (Part II)",
    "section": "",
    "text": "In Plotly R package, both ggplotly() and plot_ly() support key frame animations through the frame argument/aesthetic. They also support an ids argument/aesthetic to ensure smooth transitions between objects with the same id (which helps facilitate object constancy).\n\n\nIn this sub-section, you will learn how to create an animated bubble plot by using ggplotly() method.\n\nThe plotThe code chunk\n\n\n\n\n\n\n\n\nThe animated bubble plot above includes a play/pause button and a slider component for controlling the animation\n\n\n\ngg &lt;- ggplot(globalPop,\n             aes(x=Old,\n                 y=Young,\n                 size=Population,\n                 colour=Country)) +\n  geom_point(aes(size=Population,\n                 frame=Year),\n             alpha=0.7,\n             show.legend=F) +\n  scale_colour_manual(values=country_colors) +\n  scale_size(range=c(2,12)) +\n  labs(x=\"% Aged\",\n       y=\"% Young\")\n\nggplotly(gg)\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\n\nAppropriate ggplot2 functions are used to create a static bubble plot. The output is then saved as an R object called gg.\nggplotly() is then used to convert the R graphic object into an animated svg object.\n\n\n\n\n\n\nNotice that although show.legend = FALSE argument was used, the legend still appears on the plot. To overcome this problem, theme(legend.position='none') should be used as shown in the plot and code chunk below.\n\nThe plotThe code chunk\n\n\n\n\n\n\n\n\n\n\n\ngg &lt;- ggplot(globalPop,\n             aes(x=Old,\n                 y=Young,\n                 size=Population,\n                 colour=Country)) +\n  geom_point(aes(size=Population,\n                 frame=Year),\n             alpha=0.7) +\n  scale_colour_manual(values=country_colors) +\n  scale_size(range=c(2,12)) +\n  labs(x=\"% Aged\",\n       y=\"% Young\") +\n  theme(legend.position = \"none\")\n\nggplotly(gg)\n\n\n\n\n\n\n\nIn this sub-section, you will learn how to create an animated bubble plot by using plot_ly() method.\n\nThe plotThe code chunk\n\n\n\n\n\n\n\n\n\n\n\nbp &lt;- globalPop %&gt;% \n  plot_ly(x=~Old,\n          y=~Young,\n          size=~Population,\n          color=~Continent,\n          sizes=c(2,100),\n          frame=~Year,\n          text=~Country,\n          hoverinfo=\"text\",\n          type=\"scatter\",\n          mode=\"markers\") %&gt;% \n  layout(showlegend=F)\nbp"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03b/Hands-on_Ex03b.html#reference",
    "href": "Hands-on_Ex/Hands-on_Ex03b/Hands-on_Ex03b.html#reference",
    "title": "Hands-on Exercise 3b - Off we go (Part II)",
    "section": "",
    "text": "Getting Started\nVisit this link for a very interesting implementation of gganimate by your senior.\nBuilding an animation step-by-step with gganimate.\nCreating a composite gif with multiple gganimate panels"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#getting-started",
    "title": "Hands-on Exercise 2 - Preparing to set sail",
    "section": "1. Getting Started",
    "text": "1. Getting Started\n\n1.1 Installing and loading the required libraries\nIn this hands-on exercise, besides tidyverse, four R packages will be used. They are:\n\nggrepel: an R package provides geoms for ggplot2 to repel overlapping text labels.\nggthemes: an R package provides some extra themes, geoms, and scales for ‘ggplot2’.\nhrbrthemes: an R package provides typography-centric themes and theme components for ggplot2.\npatchwork: an R package for preparing composite figure created using ggplot2.\n\nCode chunk below will be used to check if these packages have been installed and also will load them onto your working R environment.\n\npacman::p_load(ggrepel, patchwork, ggthemes, hrbrthemes, tidyverse)\n\n\n\n1.2 Importing data\nFor the purpose of this exercise, a data file called Exam_data will be used. It consists of year end examination grades of a cohort of primary 3 students from a local school. It is in csv file format.\nThe code chunk below imports exam_data.csv into R environment by using read_csv() function of readr package. readr is one of the tidyverse package.\n\nexam_data &lt;- read_csv(\"data/Exam_data.csv\")\n\n\nsummary(exam_data)\n\n      ID               CLASS              GENDER              RACE          \n Length:322         Length:322         Length:322         Length:322        \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n    ENGLISH          MATHS          SCIENCE     \n Min.   :21.00   Min.   : 9.00   Min.   :15.00  \n 1st Qu.:59.00   1st Qu.:58.00   1st Qu.:49.25  \n Median :70.00   Median :74.00   Median :65.00  \n Mean   :67.18   Mean   :69.33   Mean   :61.16  \n 3rd Qu.:78.00   3rd Qu.:85.00   3rd Qu.:74.75  \n Max.   :96.00   Max.   :99.00   Max.   :96.00  \n\n\nThere are a total of seven attributes in the exam_data tibble data frame. Four of them are categorical data type and the other three are in continuous data type.\n\nThe categorical attributes are: ID, CLASS, GENDER and RACE.\nThe continuous attributes are: MATHS, ENGLISH and SCIENCE."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#beyond-ggplot2-annotation-ggrepel",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#beyond-ggplot2-annotation-ggrepel",
    "title": "Hands-on Exercise 2 - Preparing to set sail",
    "section": "2. Beyond ggplot2 Annotation: ggrepel",
    "text": "2. Beyond ggplot2 Annotation: ggrepel\n\nOne of the challenge in plotting statistical graph is annotation, especially with large number of data points.\n\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data,\n       aes(x=MATHS,\n           y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm,\n              linewidth=0.5) +\n  geom_label(aes(label=ID),\n             hjust = .5, \n             vjust = -.5) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100)) +\n  ggtitle(\"English scores versus Maths scores for Primary 3\") +\n  theme_minimal()\n\n\n\n\n\nggrepel  is an extension of ggplot2 package which provides geoms for ggplot2 to repel overlapping text as in our examples on the right.\n\n\n\n\n\n\n\nWe simply replace geom_text() by geom_text_repel() and geom_label() by geom_label_repel.\n\n\n2.1 Working with ggrepel\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data,\n       aes(x=MATHS,\n           y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm,\n              linewidth=0.5) +\n  geom_label_repel(aes(label=ID),\n                   fontface=\"bold\") +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100)) +\n  ggtitle(\"English scores versus Maths scores for Primary 3\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#beyond-ggplot2-themes",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#beyond-ggplot2-themes",
    "title": "Hands-on Exercise 2 - Preparing to set sail",
    "section": "3. Beyond ggplot2 Themes",
    "text": "3. Beyond ggplot2 Themes\n\nggplot2 comes with eight built-in themes, they are: theme_gray(), theme_bw(), theme_classic(), theme_dark(), theme_light(), theme_linedraw(), theme_minimal(), and theme_void().\n\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data,\n       aes(x=MATHS)) +\n  geom_histogram(bins=20,\n                 boundary=100,\n                 color=\"grey25\",\n                 fill=\"grey90\")  +\n  theme_gray() +\n  ggtitle(\"Distribution of Maths scores\")\n\n\n\n\n\nRefer to this link to learn more about ggplot2 Themes\n\n\n3.1 Working with ggtheme package\nggthemes provides ‘ggplot2’ themes that replicate the look of plots by Edward Tufte, Stephen Few, Fivethirtyeight, The Economist, ‘Stata’, ‘Excel’, and The Wall Street Journal, among others.\nIn the example below, The Economist theme is used.\n\nThe Economist themeExcel themeEdward Tufte themeFivethirtyeight theme\n\n\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data,\n       aes(x=MATHS)) +\n  geom_histogram(bins=20,\n                 boundary=100,\n                 color=\"grey25\",\n                 fill=\"grey90\") +\n  ggtitle(\"Distribution of Maths scores\") +\n  theme_economist()\n\n\n\n\n\n\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data,\n       aes(x=MATHS)) +\n  geom_histogram(bins=20,\n                 boundary=100,\n                 color=\"grey25\",\n                 fill=\"grey90\") +\n  ggtitle(\"Distribution of Maths scores\") +\n  theme_excel()\n\n\n\n\n\n\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data,\n       aes(x=MATHS)) +\n  geom_histogram(bins=20,\n                 boundary=100,\n                 color=\"grey25\",\n                 fill=\"grey90\") +\n  ggtitle(\"Distribution of Maths scores\") +\n  theme_tufte()\n\n\n\n\n\n\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data,\n       aes(x=MATHS)) +\n  geom_histogram(bins=20,\n                 boundary=100,\n                 color=\"grey25\",\n                 fill=\"grey90\") +\n  ggtitle(\"Distribution of Maths scores\") +\n  theme_fivethirtyeight()\n\n\n\n\n\n\n\n\nIt also provides some extra geoms and scales for ‘ggplot2’. Consult this vignette to learn more.\n\n\n\n3.2 Working with hrbthems package\n\nhrbrthemes package provides a base theme that focuses on typographic elements, including where various labels are placed as well as the fonts that are used.\n\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data,\n       aes(x=MATHS)) +\n    geom_histogram(bins=20,\n                   boundary=100,\n                   color=\"grey25\",\n                   fill=\"grey90\") +\n    ggtitle(\"Distribution of Maths scores\") +\n    theme_ipsum()\n\n\n\n\n\nThe second goal centers around productivity for a production workflow. In fact, this “production workflow” is the context for where the elements of hrbrthemes should be used. Consult this vignette to learn more.\n\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data,\n       aes(x=MATHS)) +\n  geom_histogram(bins=20,\n                 boundary=100,\n                 color=\"grey25\",\n                 fill=\"grey90\") +\n  ggtitle(\"Distribution of Maths scores\") +\n  theme_ipsum(axis_title_size=18,\n              base_size=15,\n              grid=\"Y\")\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nWhat can we learn from the code chunk above?\n\naxis_title_size argument is used to increase the font size of the axis title to 18,\nbase_size argument is used to increase the default axis label to 15, and\ngrid argument is used to remove the x-axis grid lines."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#beyond-single-graph",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#beyond-single-graph",
    "title": "Hands-on Exercise 2 - Preparing to set sail",
    "section": "4 Beyond Single Graph",
    "text": "4 Beyond Single Graph\n\nIt is not unusual that multiple graphs are required to tell a compelling visual story. There are several ggplot2 extensions provide functions to compose figure with multiple graphs. In this section, you will learn how to create composite plot by combining multiple graphs. First, let us create three statistical graphics by using the code chunks below.\n\n\nMaths scoresEnglish scoresEnglish scores vs Maths scores\n\n\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\np1 &lt;- ggplot(data=exam_data,\n             aes(x=MATHS)) +\n  geom_histogram(bins=20,\n                 boundary=100,\n                 color=\"grey25\",\n                 fill=\"grey90\") +\n  coord_cartesian(xlim=c(0,100)) +\n  ggtitle(\"Distribution of Maths scores\")\n\n\n\n\n\n\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\np2 &lt;- ggplot(data=exam_data,\n             aes(x=ENGLISH)) +\n  geom_histogram(bins=20,\n                 boundary=100,\n                 color=\"grey25\",\n                 fill=\"grey90\") +\n  coord_cartesian(xlim=c(0,100)) +\n  ggtitle(\"Distribution of English scores\")\n\n\n\n\n\n\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\np3 &lt;- ggplot(data=exam_data,\n             aes(x=MATHS,\n                 y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm,\n              linewidth=0.5) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100)) +\n  ggtitle(\"English scores versus Maths scores for Primary 3\")\n\n\n\n\n\n\n\n\n4.1 Creating Composite Graphics: pathwork methods \n\nThere are several ggplot2 extension’s functions support the needs to prepare composite figure by combining several graphs such as grid.arrange() of gridExtra package and plot_grid() of cowplot package. In this section, I am going to shared with you an ggplot2 extension called patchwork which is specially designed for combining separate ggplot2 graphs into a single figure.\nPatchwork package has a very simple syntax where we can create layouts super easily. Here’s the general syntax that combines:\n\nTwo-Column Layout using the Plus Sign +.\nParenthesis () to create a subplot group.\nTwo-Row Layout using the Division Sign /\n\n\n\n\n4.2 Combining two ggplot2 graphs\n\nFigure in the tabset below shows a composite of two histograms created using patchwork. Note how simple the syntax used to create the plot!\n\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\np1 + p2\n\n\n\n\n\n\n4.3 Combining three ggplot2 graphs\n\nWe can plot more complex composite by using appropriate operators. For example, the composite figure below is plotted by using:\n\n“/” operator to stack two ggplot2 graphs,\n“|” operator to place the plots beside each other,\n“()” operator the define the sequence of the plotting.\n\n\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n(p1 / p2) | p3\n\n\n\n\n\nTo learn more about, refer to Plot Assembly.\n\n\n\n4.4 Creating a composite figure with tag\n\nIn order to identify subplots in text, patchwork also provides auto-tagging capabilities as shown in the figure below.\n\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\n((p1 / p2) | p3) + \n  plot_annotation(tag_levels = 'I')\n\n\n\n\n\n\n4.5 Creating figure with insert\n\nBeside providing functions to place plots next to each other based on the provided layout. With inset_element() of patchwork, we can place one or several plots or graphic elements freely on top or below another plot.\n\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\np3 + inset_element(p2,\n                   left = 0.02,\n                   bottom = 0.7,\n                   right = 0.5,\n                   top = 1)\n\n\n\n\n\n\n4.6 Creating a composite figure by using patchwork and ggtheme\nFigure below is created by combining patchwork and theme_economist() of ggthemes package discussed earlier.\n\nThe plotThe code\n\n\n\n\n\n\n\n\n\n\npatchwork &lt;- (p1 / p2) | p3\npatchwork & theme_economist()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#reference",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#reference",
    "title": "Hands-on Exercise 2 - Preparing to set sail",
    "section": "5. Reference",
    "text": "5. Reference\n\nPatchwork R package goes nerd viral\nggrepel\nggthemes\nhrbrthemes\nggplot tips: Arranging plots\nggplot2 Theme Elements Demonstration\nggplot2 Theme Elements Reference Sheet"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n\n\n\n\nThis website is created with the purpose of detailing the “destinations” in the voyage of ISSS608 - Visual Analytics and Applications module, part of the SMU MITB programme, AY2023-24.\nMany thanks to captain, Prof. Kam Tin Seong, in navigating us through the world of Visual Analytics.\n\n\n\n Back to top"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html",
    "title": "Hands-on Exercise 1 - At the Home-port",
    "section": "",
    "text": "In this chapter, you will learn the basic principles and essential components of ggplot2. At the same time, you will gain hands-on experience on using these components to plot statistical graphics based on the principle of Layered Grammar of Graphics. By then end of this chapter you will be able to apply the essential graphical elements provided by ggplot2 to create elegant and yet functional statistical graphics.\n\n\n\n\n\n\n\n\n\nThe code chunk below uses p_load() of pacman package to check if tidyverse packages are installed in the computer. If they are, then they will be launched into R.\n\npacman::p_load(tidyverse)\n\n\n\n\nThe code chunk below imports exam_data.csv into R environment by using read_csv() function of readr package.\n\nexam_data &lt;- read_csv(\"data/Exam_data.csv\")\n\nSummary of data imported\n\nsummary(exam_data)\n\n      ID               CLASS              GENDER              RACE          \n Length:322         Length:322         Length:322         Length:322        \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n    ENGLISH          MATHS          SCIENCE     \n Min.   :21.00   Min.   : 9.00   Min.   :15.00  \n 1st Qu.:59.00   1st Qu.:58.00   1st Qu.:49.25  \n Median :70.00   Median :74.00   Median :65.00  \n Mean   :67.18   Mean   :69.33   Mean   :61.16  \n 3rd Qu.:78.00   3rd Qu.:85.00   3rd Qu.:74.75  \n Max.   :96.00   Max.   :99.00   Max.   :96.00  \n\n\n\n\n\n\n\nggplot(data = exam_data, \n       aes(x = RACE)) +\n  geom_bar()+\n  labs(x = \"RACE\", y = \"Number of students\", title = \"Distribution of students by RACE\") +\n  theme_minimal() + \n  theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\n\n\n\nBase Rggplot2\n\n\n\nhist(exam_data$MATHS)\n\n\n\n\n\n\n\nggplot(data=exam_data, aes(x = MATHS)) +\n  geom_histogram(bins=10, \n                 boundary = 100,\n                 color=\"black\", \n                 fill=\"grey\") +\n  ggtitle(\"Distribution of Maths scores\")\n\n\n\n\n\n\n\n\n\n\n\n\nBefore we getting started using ggplot2, it is important for us to understand the principles of Grammer of Graphics.\nGrammar of Graphics is a general scheme for data visualization which breaks up graphs into semantic components such as scales and layers. It was introduced by Leland Wilkinson (1999) Grammar of Graphics, Springer. The grammar of graphics is an answer to a question:\nWhat is a statistical graphic?\nIn the nutshell, Grammar of Graphics defines the rules of structuring mathematical and aesthetic elements into a meaningful graph.\nThere are two principles in Grammar of Graphics, they are:\n\nGraphics = distinct layers of grammatical elements\nMeaningful plots through aesthetic mapping\n\nA good grammar of graphics will allow us to gain insight into the composition of complicated graphics, and reveal unexpected connections between seemingly different graphics (Cox 1978). It also provides a strong foundation for understanding a diverse range of graphics. Furthermore, it may also help guide us on what a well-formed or correct graphic looks like, but there will still be many grammatically correct but nonsensical graphics.\nggplot2 is an implementation of Leland Wilkinson’s Grammar of Graphics. Figure below shows the seven grammars of ggplot2.\n\n\n\n\nReference: Hadley Wickham (2010) “A layered grammar of graphics.” Journal of Computational and Graphical Statistics, vol. 19, no. 1, pp. 3–28.\n\n\n\nA short description of each building block are as follows:\n\nData: The dataset being plotted.\nAesthetics take attributes of the data and use them to influence visual characteristics, such as position, colours, size, shape, or transparency.\nGeometrics: The visual elements used for our data, such as point, bar or line.\nFacets split the data into subsets to create multiple variations of the same graph (paneling, multiple plots).\nStatistics, statiscal transformations that summarise data (e.g. mean, confidence intervals).\nCoordinate systems define the plane on which data are mapped on the graphic.\nThemes modify all non-data components of a plot, such as main title, sub-title, y-aixs title, or legend background.\n\n\n\n\n\n\nCall the ggplot() function using the code chunk below.\n\nA blank canvas appears.\nggplot() initializes a ggplot object.\nThe data argument defines the dataset to be used for plotting.\nIf the dataset is not already a data.frame, it will be converted to one by fortify().\n\n\n\nggplot(data=exam_data)\n\n\n\n\n\n\n\n\nThe aesthetic mappings take attributes of the data and and use them to influence visual characteristics, such as position, colour, size, shape, or transparency. Each visual characteristic can thus encode an aspect of the data and be used to convey information.\nAll aesthetics of a plot are specified in the aes() function call (in later part of this lesson, you will see that each geom layer can have its own aes specification)\nCode chunk below adds the aesthetic element into the plot.\n\n\nggplot(data=exam_data, \n       aes(x= MATHS))\n\n\n\n\n\n\n\n\nThe geom layer combines data, aesthetic mapping, a geom (geometric object), a stat (statistical transformation), and a position adjustment. Some examples of geom objects are shown below.\nExamples include:\n\ngeom_point for drawing individual points (e.g., a scatter plot)\ngeom_line for drawing lines (e.g., for a line charts)\ngeom_smooth for drawing smoothed lines (e.g., for simple trends or approximations)\ngeom_bar for drawing bars (e.g., for bar charts)\ngeom_histogram for drawing binned values (e.g. a histogram)\ngeom_polygon for drawing arbitrary shapes\ngeom_map for drawing polygons in the shape of a map! (You can access the data to use for these maps by using the map_data() function).\n\nA plot must have at least one geom; there is no upper limit. You can add a geom to a plot using the + operator.\n\nFor complete list, please refer to here.\n\n\n\n\n\nThe code chunk below plots a bar chart by using geom_bar().\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar(fill = \"lightblue\", width = 0.6, color = \"darkblue\") + \n  labs(x = \"RACE\", y = \"Number of students\", title = \"Distribution of students by RACE\") +\n  theme_minimal() + \n  theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\nIn a dot plot, the width of a dot corresponds to the bin width (or maximum width, depending on the binning algorithm), and dots are stacked, with each dot representing one observation.\nIn the code chunk below, geom_dotplot() of ggplot2 is used to plot a dot plot.\n\nggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot(binwidth = 2.5, \n               dotsize = 0.5, fill = \"lightblue\") +\n  scale_y_continuous(NULL, breaks = NULL)+\n  labs(x = \"MATHS score\", title = \"Distribution of MATHS score\") +\n  theme_minimal() +\n  theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\nIn the code chunk below, geom_histogram() is used to create a simple histogram by using values in MATHS field of exam_data.\n\nggplot(data=exam_data, aes(x = MATHS)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"darkblue\", \n                 fill=\"lightblue\") +\n  ggtitle(\"Distribution of Maths scores\") + \n  theme_minimal() + \n  theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\nIn the code chunk below,\n\nbins argument is used to change the number of bins to 20,\nfill argument is used to change the interior colour of the histogram by using sub-group of aesthetic(), and\ncolor argument is used to change the outline colour of the bars in grey\n\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           fill = GENDER)) +\n  geom_histogram(bins=20, \n                 color=\"grey30\") +\n  ggtitle(\"Distribution of Maths scores\") +\n  theme_minimal() + \n  theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\ngeom-density() computes and plots kernel density estimate, which is a smoothed version of the histogram.\nIt is a useful alternative to the histogram for continuous data that comes from an underlying smooth distribution.\nThe code chunk below plots two kernel density lines by using colour or fill arguments of aes().\n\nggplot(data=exam_data, \n       aes(x = MATHS, color = GENDER)) +\n  geom_density() + \n  ggtitle(\"Density Distribution of Maths scores by Gender\") +\n  theme_minimal() + \n  theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\ngeom_boxplot() displays continuous value list. It visualises five summary statistics (the median, two hinges and two whiskers), and all “outlying” points individually.\nThe code chunk below plots boxplots by using geom_boxplot().\n\nggplot(data=exam_data, \n       aes(y = MATHS,       \n           x= GENDER)) +    \n  geom_boxplot(color = \"blue\", fill = \"grey95\") +\n  stat_summary(geom = \"point\",       \n               fun=\"mean\",         \n               colour =\"red\",        \n               size=4) +\n  ggtitle(\"Box Plot of Maths Score by Gender\") +\n  theme_minimal() + \n  theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\nNotches are used in box plots to help visually assess whether the medians of distributions differ. If the notches do not overlap, this is evidence that the medians are different.\nThe code chunk below plots the distribution of Maths scores by gender in notched plot instead of boxplot.\n\nggplot(data=exam_data, \n       aes(y = MATHS,       \n           x= GENDER)) +    \n  geom_boxplot(notch = TRUE, color = \"blue\", fill = \"grey95\") +\n  stat_summary(geom = \"point\",       \n               fun=\"mean\",         \n               colour =\"red\",        \n               size=4) +\n  ggtitle(\"Box Plot of Maths Score by Gender\") +\n  theme_minimal() + \n  theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\ngeom_violin is designed for creating violin plot. Violin plots are a way of comparing multiple data distributions. With ordinary density curves, it is difficult to compare more than just a few distributions because the lines visually interfere with each other. With a violin plot, it’s easier to compare several distributions since they’re placed side by side.\nThe code below plot the distribution of Maths score by gender in violin plot.\n\nggplot(data=exam_data, \n       aes(y = MATHS, \n           x = GENDER)) +\n  geom_violin(color = \"blue\") + \n  ggtitle(\"Violin Plot of Maths Score by Gender\") +\n  theme_minimal() + \n  theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\ngeom_point() is especially useful for creating scatterplot.\nThe code chunk below plots a scatterplot showing the Maths and English grades of pupils by using geom_point().\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           y = ENGLISH, shape = GENDER, color = GENDER)) +\n  geom_point() + \n  geom_smooth(linewidth = 0.5) +\n  ggtitle(\"Scatter Plot of Maths Score by Gender\") +\n  theme_minimal() + \n  theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\nThe code chunk below plots the data points on the boxplots by using both geom_boxplot() and geom_point().\n\nggplot(data=exam_data, \n       aes(y = MATHS, \n           x= GENDER)) +\n  geom_boxplot(color = \"blue\") +                    \n  geom_point(position=\"jitter\", \n             size = 0.5) +\n  ggtitle(\"Combination Plot of Maths Score by Gender\") +\n  theme_minimal() + \n  theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\nThe Statistics functions statistically transform data, usually as some form of summary. For example:\n\nfrequency of values of a variable (bar graph)\n\na mean\na confidence limit\n\nThere are two ways to use these functions:\n\nadd a stat_() function and override the default geom, or\nadd a geom_() function and override the default stat.\n\n\nUsing stat_summary()\nThe code chunk below adds mean values by using stat_summary() function and overriding the default geom.\n\nggplot(data=exam_data, \n       aes(y = MATHS, x= GENDER)) +\n  geom_boxplot() +\n  stat_summary(geom = \"point\",       \n               fun.y=\"mean\",         \n               colour =\"red\",        \n               size=4) +\n  ggtitle(\"Box Plot of Maths Score by Gender\") +\n  theme_minimal() + \n  theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\nUsing geom_() function to override default stat.\nThe code chunk below adding mean values by using geom_() function and overriding the default stat.\n\nggplot(data=exam_data, \n       aes(y = MATHS, x= GENDER)) +\n  geom_boxplot() +\n  geom_point(stat = \"summary\",       \n             fun=\"mean\",         \n             colour =\"red\",        \n             size=4) +\n  ggtitle(\"Box Plot of Maths Score by Gender\") +\n  theme_minimal() + \n  theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\nThe scatterplot below shows the relationship of Maths and English grades of pupils. The interpretability of this graph can be improved by adding a best fit curve.\nIn the code chunk below, geom_smooth() is used to plot a best fit curve on the scatterplot.\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           y = ENGLISH)) +\n  geom_point() + \n  geom_smooth(linewidth=0.5, \n              color = \"red\") + \n  geom_smooth(method = lm,\n              linewidth=0.5, \n              color = \"blue\") +\n  ggtitle(\"Scatter Plot of Maths Score by Gender\") +\n  theme_minimal() + \n  theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\n\n\nFacetting generates small multiples (sometimes also called trellis plot), each displaying a different subset of the data. They are an alternative to aesthetics for displaying additional discrete variables. ggplot2 supports two types of factes, namely: facet_grid() and facet_wrap.\n\n\n\nfacet_wrap wraps a 1d sequence of panels into 2d. This is generally a better use of screen space than facet_grid because most displays are roughly rectangular.\nThe code chunk below plots a trellis plot using facet-wrap().\n\nggplot(data=exam_data, \n       aes(x= MATHS)) +\n  geom_histogram(bins=20) +\n    facet_wrap(~ CLASS) +\n  ggtitle(\"Distribution of Maths Score by Class\") +\n  theme_minimal() + \n  theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\nfacet_grid() forms a matrix of panels defined by row and column facetting variables. It is most useful when you have two discrete variables, and all combinations of the variables exist in the data.\nThe code chunk below plots a trellis plot using facet_grid().\n\nggplot(data=exam_data, \n       aes(x= MATHS)) +\n  geom_histogram(bins=20) +\n    facet_grid(~ CLASS) +\n  ggtitle(\"Distribution of Maths Score by Class\") +\n  theme_minimal() + \n  theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\nSelf-practice: Below code chunks shows the use of geom_boxplot() with facet_wrap() to produce a Trellis Box Plot.\n\nggplot(data = exam_data, \n       aes(x=CLASS, \n           y=MATHS)) +\n  geom_boxplot() +\n  facet_wrap(~ GENDER) +\n  ggtitle(\"Trellis Box Plot of Maths scores\") +\n  theme_minimal() +\n  theme(plot.title = element_text(hjust=0.5))\n\n\n\n\n\nggplot(data = exam_data, \n       aes(x=CLASS, \n           y=MATHS)) +\n  geom_boxplot() +\n  facet_wrap(~ GENDER, nrow = 2, strip.position = \"left\") +\n  ggtitle(\"Trellis Box Plot of Maths scores\") +\n  theme_minimal() +\n  theme(plot.title = element_text(hjust=0.5))\n\n\n\n\n\n\n\n\n\nThe Coordinates functions map the position of objects onto the plane of the plot. There are a number of different possible coordinate systems to use, they are:\n\n-   [`coord_cartesian()`](https://ggplot2.tidyverse.org/reference/coord_cartesian.html): the default cartesian coordinate systems, where you specify x and y values (e.g. allows you to zoom in or out). \n-   [`coord_flip()`](https://ggplot2.tidyverse.org/reference/coord_flip.html): a cartesian system with the x and y flipped. \n-   [`coord_fixed()`](https://ggplot2.tidyverse.org/reference/coord_fixed.html): a cartesian system with a \"fixed\" aspect ratio (e.g. 1.78 for a \"widescreen\" plot). \n-   [`coord_quickmap()`](https://ggplot2.tidyverse.org/reference/coord_map.html): a coordinate system that approximates a good aspect ratio for maps.\n\n\nThe code chunk below flips the horizontal bar chart into vertical bar chart by using coord_flip().\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar(fill = \"lightblue\") +\n  coord_flip() +\n  ggtitle(\"Distribution of students by Race\") +\n  theme_minimal() + \n  theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\nThe code chunk below fixed both the y-axis and x-axis range from 0-100.\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           y = ENGLISH)) +\n  geom_point() + \n  geom_smooth(method = lm,\n              linewidth=0.5, \n              color = \"blue\") +\n  coord_cartesian(xlim = c(0,100),\n                  ylim = c(0,100)) +\n  ggtitle(\"Scatter Plot of Maths Score by Gender\") +\n  theme_minimal() + \n  theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\n\n\nThemes control elements of the graph not related to the data. For example:\n\nbackground colour\nsize of fonts\ngridlines\ncolour of labels\n\nBuilt-in themes include: - theme_gray() (default) - theme_bw() - theme_classic()\nA list of theme can be found at this link. Each theme element can be conceived of as either a line (e.g. x-axis), a rectangle (e.g. graph background), or text (e.g. axis title).\n\n\n\n\ntheme_graytheme_minimaltheme_bwtheme_classic\n\n\n\nggplot(data = exam_data, \n       aes(x = RACE)) +\n  geom_bar(fill = \"yellow\") +\n  coord_flip() +\n  theme_gray() +\n  ggtitle(\"Distribution of students by Race\") + \n  theme(plot.title = element_text(hjust = 0.5, color = \"blue\"))\n\n\n\n\n\n\n\nggplot(data = exam_data, \n       aes(x = RACE)) +\n  geom_bar(fill = \"yellow\") +\n  coord_flip() +\n  theme_minimal() +\n  ggtitle(\"Distribution of students by Race\") + \n  theme(plot.title = element_text(hjust = 0.5, color = \"blue\"))\n\n\n\n\n\n\n\nggplot(data = exam_data, \n       aes(x = RACE)) +\n  geom_bar(fill = \"yellow\") +\n  coord_flip() +\n  theme_bw() +\n  ggtitle(\"Distribution of students by Race\") + \n  theme(plot.title = element_text(hjust = 0.5, color = \"blue\"))\n\n\n\n\n\n\n\nggplot(data = exam_data, \n       aes(x = RACE)) +\n  geom_bar(fill = \"yellow\") +\n  coord_flip() +\n  theme_classic() +\n  ggtitle(\"Distribution of students by Race\") + \n  theme(plot.title = element_text(hjust = 0.5, color = \"blue\"))\n\n\n\n\n\n\n\n\n\n\n\n\n\nHadley Wickham (2023) ggplot2: Elegant Graphics for Data Analysis. Online 3rd edition.\nWinston Chang (2013) R Graphics Cookbook 2nd edition. Online version.\nHealy, Kieran (2019) Data Visualization: A practical introduction. Online version\nLearning ggplot2 on Paper – Components\nLearning ggplot2 on Paper – Layer\nLearning ggplot2 on Paper – Scale"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#getting-started",
    "title": "Hands-on Exercise 1 - At the Home-port",
    "section": "",
    "text": "The code chunk below uses p_load() of pacman package to check if tidyverse packages are installed in the computer. If they are, then they will be launched into R.\n\npacman::p_load(tidyverse)\n\n\n\n\nThe code chunk below imports exam_data.csv into R environment by using read_csv() function of readr package.\n\nexam_data &lt;- read_csv(\"data/Exam_data.csv\")\n\nSummary of data imported\n\nsummary(exam_data)\n\n      ID               CLASS              GENDER              RACE          \n Length:322         Length:322         Length:322         Length:322        \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n    ENGLISH          MATHS          SCIENCE     \n Min.   :21.00   Min.   : 9.00   Min.   :15.00  \n 1st Qu.:59.00   1st Qu.:58.00   1st Qu.:49.25  \n Median :70.00   Median :74.00   Median :65.00  \n Mean   :67.18   Mean   :69.33   Mean   :61.16  \n 3rd Qu.:78.00   3rd Qu.:85.00   3rd Qu.:74.75  \n Max.   :96.00   Max.   :99.00   Max.   :96.00"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#plotting-a-simple-bar-chart",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#plotting-a-simple-bar-chart",
    "title": "Hands-on Exercise 1 - At the Home-port",
    "section": "",
    "text": "ggplot(data = exam_data, \n       aes(x = RACE)) +\n  geom_bar()+\n  labs(x = \"RACE\", y = \"Number of students\", title = \"Distribution of students by RACE\") +\n  theme_minimal() + \n  theme(plot.title = element_text(hjust = 0.5))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#initial-exploration-of-ggplot2",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#initial-exploration-of-ggplot2",
    "title": "Hands-on Exercise 1 - At the Home-port",
    "section": "",
    "text": "Base Rggplot2\n\n\n\nhist(exam_data$MATHS)\n\n\n\n\n\n\n\nggplot(data=exam_data, aes(x = MATHS)) +\n  geom_histogram(bins=10, \n                 boundary = 100,\n                 color=\"black\", \n                 fill=\"grey\") +\n  ggtitle(\"Distribution of Maths scores\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#grammar-of-graphics",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#grammar-of-graphics",
    "title": "Hands-on Exercise 1 - At the Home-port",
    "section": "",
    "text": "Before we getting started using ggplot2, it is important for us to understand the principles of Grammer of Graphics.\nGrammar of Graphics is a general scheme for data visualization which breaks up graphs into semantic components such as scales and layers. It was introduced by Leland Wilkinson (1999) Grammar of Graphics, Springer. The grammar of graphics is an answer to a question:\nWhat is a statistical graphic?\nIn the nutshell, Grammar of Graphics defines the rules of structuring mathematical and aesthetic elements into a meaningful graph.\nThere are two principles in Grammar of Graphics, they are:\n\nGraphics = distinct layers of grammatical elements\nMeaningful plots through aesthetic mapping\n\nA good grammar of graphics will allow us to gain insight into the composition of complicated graphics, and reveal unexpected connections between seemingly different graphics (Cox 1978). It also provides a strong foundation for understanding a diverse range of graphics. Furthermore, it may also help guide us on what a well-formed or correct graphic looks like, but there will still be many grammatically correct but nonsensical graphics.\nggplot2 is an implementation of Leland Wilkinson’s Grammar of Graphics. Figure below shows the seven grammars of ggplot2.\n\n\n\n\nReference: Hadley Wickham (2010) “A layered grammar of graphics.” Journal of Computational and Graphical Statistics, vol. 19, no. 1, pp. 3–28.\n\n\n\nA short description of each building block are as follows:\n\nData: The dataset being plotted.\nAesthetics take attributes of the data and use them to influence visual characteristics, such as position, colours, size, shape, or transparency.\nGeometrics: The visual elements used for our data, such as point, bar or line.\nFacets split the data into subsets to create multiple variations of the same graph (paneling, multiple plots).\nStatistics, statiscal transformations that summarise data (e.g. mean, confidence intervals).\nCoordinate systems define the plane on which data are mapped on the graphic.\nThemes modify all non-data components of a plot, such as main title, sub-title, y-aixs title, or legend background."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-data",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-data",
    "title": "Hands-on Exercise 1 - At the Home-port",
    "section": "",
    "text": "Call the ggplot() function using the code chunk below.\n\nA blank canvas appears.\nggplot() initializes a ggplot object.\nThe data argument defines the dataset to be used for plotting.\nIf the dataset is not already a data.frame, it will be converted to one by fortify().\n\n\n\nggplot(data=exam_data)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-aesthetic-mappings",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-aesthetic-mappings",
    "title": "Hands-on Exercise 1 - At the Home-port",
    "section": "",
    "text": "The aesthetic mappings take attributes of the data and and use them to influence visual characteristics, such as position, colour, size, shape, or transparency. Each visual characteristic can thus encode an aspect of the data and be used to convey information.\nAll aesthetics of a plot are specified in the aes() function call (in later part of this lesson, you will see that each geom layer can have its own aes specification)\nCode chunk below adds the aesthetic element into the plot.\n\n\nggplot(data=exam_data, \n       aes(x= MATHS))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-geom",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#essential-grammatical-elements-in-ggplot2-geom",
    "title": "Hands-on Exercise 1 - At the Home-port",
    "section": "",
    "text": "The geom layer combines data, aesthetic mapping, a geom (geometric object), a stat (statistical transformation), and a position adjustment. Some examples of geom objects are shown below.\nExamples include:\n\ngeom_point for drawing individual points (e.g., a scatter plot)\ngeom_line for drawing lines (e.g., for a line charts)\ngeom_smooth for drawing smoothed lines (e.g., for simple trends or approximations)\ngeom_bar for drawing bars (e.g., for bar charts)\ngeom_histogram for drawing binned values (e.g. a histogram)\ngeom_polygon for drawing arbitrary shapes\ngeom_map for drawing polygons in the shape of a map! (You can access the data to use for these maps by using the map_data() function).\n\nA plot must have at least one geom; there is no upper limit. You can add a geom to a plot using the + operator.\n\nFor complete list, please refer to here.\n\n\n\n\n\nThe code chunk below plots a bar chart by using geom_bar().\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar(fill = \"lightblue\", width = 0.6, color = \"darkblue\") + \n  labs(x = \"RACE\", y = \"Number of students\", title = \"Distribution of students by RACE\") +\n  theme_minimal() + \n  theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\nIn a dot plot, the width of a dot corresponds to the bin width (or maximum width, depending on the binning algorithm), and dots are stacked, with each dot representing one observation.\nIn the code chunk below, geom_dotplot() of ggplot2 is used to plot a dot plot.\n\nggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot(binwidth = 2.5, \n               dotsize = 0.5, fill = \"lightblue\") +\n  scale_y_continuous(NULL, breaks = NULL)+\n  labs(x = \"MATHS score\", title = \"Distribution of MATHS score\") +\n  theme_minimal() +\n  theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\nIn the code chunk below, geom_histogram() is used to create a simple histogram by using values in MATHS field of exam_data.\n\nggplot(data=exam_data, aes(x = MATHS)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"darkblue\", \n                 fill=\"lightblue\") +\n  ggtitle(\"Distribution of Maths scores\") + \n  theme_minimal() + \n  theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\nIn the code chunk below,\n\nbins argument is used to change the number of bins to 20,\nfill argument is used to change the interior colour of the histogram by using sub-group of aesthetic(), and\ncolor argument is used to change the outline colour of the bars in grey\n\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           fill = GENDER)) +\n  geom_histogram(bins=20, \n                 color=\"grey30\") +\n  ggtitle(\"Distribution of Maths scores\") +\n  theme_minimal() + \n  theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\ngeom-density() computes and plots kernel density estimate, which is a smoothed version of the histogram.\nIt is a useful alternative to the histogram for continuous data that comes from an underlying smooth distribution.\nThe code chunk below plots two kernel density lines by using colour or fill arguments of aes().\n\nggplot(data=exam_data, \n       aes(x = MATHS, color = GENDER)) +\n  geom_density() + \n  ggtitle(\"Density Distribution of Maths scores by Gender\") +\n  theme_minimal() + \n  theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\ngeom_boxplot() displays continuous value list. It visualises five summary statistics (the median, two hinges and two whiskers), and all “outlying” points individually.\nThe code chunk below plots boxplots by using geom_boxplot().\n\nggplot(data=exam_data, \n       aes(y = MATHS,       \n           x= GENDER)) +    \n  geom_boxplot(color = \"blue\", fill = \"grey95\") +\n  stat_summary(geom = \"point\",       \n               fun=\"mean\",         \n               colour =\"red\",        \n               size=4) +\n  ggtitle(\"Box Plot of Maths Score by Gender\") +\n  theme_minimal() + \n  theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\nNotches are used in box plots to help visually assess whether the medians of distributions differ. If the notches do not overlap, this is evidence that the medians are different.\nThe code chunk below plots the distribution of Maths scores by gender in notched plot instead of boxplot.\n\nggplot(data=exam_data, \n       aes(y = MATHS,       \n           x= GENDER)) +    \n  geom_boxplot(notch = TRUE, color = \"blue\", fill = \"grey95\") +\n  stat_summary(geom = \"point\",       \n               fun=\"mean\",         \n               colour =\"red\",        \n               size=4) +\n  ggtitle(\"Box Plot of Maths Score by Gender\") +\n  theme_minimal() + \n  theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\ngeom_violin is designed for creating violin plot. Violin plots are a way of comparing multiple data distributions. With ordinary density curves, it is difficult to compare more than just a few distributions because the lines visually interfere with each other. With a violin plot, it’s easier to compare several distributions since they’re placed side by side.\nThe code below plot the distribution of Maths score by gender in violin plot.\n\nggplot(data=exam_data, \n       aes(y = MATHS, \n           x = GENDER)) +\n  geom_violin(color = \"blue\") + \n  ggtitle(\"Violin Plot of Maths Score by Gender\") +\n  theme_minimal() + \n  theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\ngeom_point() is especially useful for creating scatterplot.\nThe code chunk below plots a scatterplot showing the Maths and English grades of pupils by using geom_point().\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           y = ENGLISH, shape = GENDER, color = GENDER)) +\n  geom_point() + \n  geom_smooth(linewidth = 0.5) +\n  ggtitle(\"Scatter Plot of Maths Score by Gender\") +\n  theme_minimal() + \n  theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\nThe code chunk below plots the data points on the boxplots by using both geom_boxplot() and geom_point().\n\nggplot(data=exam_data, \n       aes(y = MATHS, \n           x= GENDER)) +\n  geom_boxplot(color = \"blue\") +                    \n  geom_point(position=\"jitter\", \n             size = 0.5) +\n  ggtitle(\"Combination Plot of Maths Score by Gender\") +\n  theme_minimal() + \n  theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\nThe Statistics functions statistically transform data, usually as some form of summary. For example:\n\nfrequency of values of a variable (bar graph)\n\na mean\na confidence limit\n\nThere are two ways to use these functions:\n\nadd a stat_() function and override the default geom, or\nadd a geom_() function and override the default stat.\n\n\nUsing stat_summary()\nThe code chunk below adds mean values by using stat_summary() function and overriding the default geom.\n\nggplot(data=exam_data, \n       aes(y = MATHS, x= GENDER)) +\n  geom_boxplot() +\n  stat_summary(geom = \"point\",       \n               fun.y=\"mean\",         \n               colour =\"red\",        \n               size=4) +\n  ggtitle(\"Box Plot of Maths Score by Gender\") +\n  theme_minimal() + \n  theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\nUsing geom_() function to override default stat.\nThe code chunk below adding mean values by using geom_() function and overriding the default stat.\n\nggplot(data=exam_data, \n       aes(y = MATHS, x= GENDER)) +\n  geom_boxplot() +\n  geom_point(stat = \"summary\",       \n             fun=\"mean\",         \n             colour =\"red\",        \n             size=4) +\n  ggtitle(\"Box Plot of Maths Score by Gender\") +\n  theme_minimal() + \n  theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\nThe scatterplot below shows the relationship of Maths and English grades of pupils. The interpretability of this graph can be improved by adding a best fit curve.\nIn the code chunk below, geom_smooth() is used to plot a best fit curve on the scatterplot.\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           y = ENGLISH)) +\n  geom_point() + \n  geom_smooth(linewidth=0.5, \n              color = \"red\") + \n  geom_smooth(method = lm,\n              linewidth=0.5, \n              color = \"blue\") +\n  ggtitle(\"Scatter Plot of Maths Score by Gender\") +\n  theme_minimal() + \n  theme(plot.title = element_text(hjust = 0.5))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#exploring-ggplot2-facet-objects",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#exploring-ggplot2-facet-objects",
    "title": "Hands-on Exercise 1 - At the Home-port",
    "section": "",
    "text": "Facetting generates small multiples (sometimes also called trellis plot), each displaying a different subset of the data. They are an alternative to aesthetics for displaying additional discrete variables. ggplot2 supports two types of factes, namely: facet_grid() and facet_wrap.\n\n\n\nfacet_wrap wraps a 1d sequence of panels into 2d. This is generally a better use of screen space than facet_grid because most displays are roughly rectangular.\nThe code chunk below plots a trellis plot using facet-wrap().\n\nggplot(data=exam_data, \n       aes(x= MATHS)) +\n  geom_histogram(bins=20) +\n    facet_wrap(~ CLASS) +\n  ggtitle(\"Distribution of Maths Score by Class\") +\n  theme_minimal() + \n  theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\nfacet_grid() forms a matrix of panels defined by row and column facetting variables. It is most useful when you have two discrete variables, and all combinations of the variables exist in the data.\nThe code chunk below plots a trellis plot using facet_grid().\n\nggplot(data=exam_data, \n       aes(x= MATHS)) +\n  geom_histogram(bins=20) +\n    facet_grid(~ CLASS) +\n  ggtitle(\"Distribution of Maths Score by Class\") +\n  theme_minimal() + \n  theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\nSelf-practice: Below code chunks shows the use of geom_boxplot() with facet_wrap() to produce a Trellis Box Plot.\n\nggplot(data = exam_data, \n       aes(x=CLASS, \n           y=MATHS)) +\n  geom_boxplot() +\n  facet_wrap(~ GENDER) +\n  ggtitle(\"Trellis Box Plot of Maths scores\") +\n  theme_minimal() +\n  theme(plot.title = element_text(hjust=0.5))\n\n\n\n\n\nggplot(data = exam_data, \n       aes(x=CLASS, \n           y=MATHS)) +\n  geom_boxplot() +\n  facet_wrap(~ GENDER, nrow = 2, strip.position = \"left\") +\n  ggtitle(\"Trellis Box Plot of Maths scores\") +\n  theme_minimal() +\n  theme(plot.title = element_text(hjust=0.5))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#exploring-ggplot2-coordinates",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#exploring-ggplot2-coordinates",
    "title": "Hands-on Exercise 1 - At the Home-port",
    "section": "",
    "text": "The Coordinates functions map the position of objects onto the plane of the plot. There are a number of different possible coordinate systems to use, they are:\n\n-   [`coord_cartesian()`](https://ggplot2.tidyverse.org/reference/coord_cartesian.html): the default cartesian coordinate systems, where you specify x and y values (e.g. allows you to zoom in or out). \n-   [`coord_flip()`](https://ggplot2.tidyverse.org/reference/coord_flip.html): a cartesian system with the x and y flipped. \n-   [`coord_fixed()`](https://ggplot2.tidyverse.org/reference/coord_fixed.html): a cartesian system with a \"fixed\" aspect ratio (e.g. 1.78 for a \"widescreen\" plot). \n-   [`coord_quickmap()`](https://ggplot2.tidyverse.org/reference/coord_map.html): a coordinate system that approximates a good aspect ratio for maps.\n\n\nThe code chunk below flips the horizontal bar chart into vertical bar chart by using coord_flip().\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar(fill = \"lightblue\") +\n  coord_flip() +\n  ggtitle(\"Distribution of students by Race\") +\n  theme_minimal() + \n  theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\nThe code chunk below fixed both the y-axis and x-axis range from 0-100.\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           y = ENGLISH)) +\n  geom_point() + \n  geom_smooth(method = lm,\n              linewidth=0.5, \n              color = \"blue\") +\n  coord_cartesian(xlim = c(0,100),\n                  ylim = c(0,100)) +\n  ggtitle(\"Scatter Plot of Maths Score by Gender\") +\n  theme_minimal() + \n  theme(plot.title = element_text(hjust = 0.5))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#exploring-ggplot2-themes",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#exploring-ggplot2-themes",
    "title": "Hands-on Exercise 1 - At the Home-port",
    "section": "",
    "text": "Themes control elements of the graph not related to the data. For example:\n\nbackground colour\nsize of fonts\ngridlines\ncolour of labels\n\nBuilt-in themes include: - theme_gray() (default) - theme_bw() - theme_classic()\nA list of theme can be found at this link. Each theme element can be conceived of as either a line (e.g. x-axis), a rectangle (e.g. graph background), or text (e.g. axis title).\n\n\n\n\ntheme_graytheme_minimaltheme_bwtheme_classic\n\n\n\nggplot(data = exam_data, \n       aes(x = RACE)) +\n  geom_bar(fill = \"yellow\") +\n  coord_flip() +\n  theme_gray() +\n  ggtitle(\"Distribution of students by Race\") + \n  theme(plot.title = element_text(hjust = 0.5, color = \"blue\"))\n\n\n\n\n\n\n\nggplot(data = exam_data, \n       aes(x = RACE)) +\n  geom_bar(fill = \"yellow\") +\n  coord_flip() +\n  theme_minimal() +\n  ggtitle(\"Distribution of students by Race\") + \n  theme(plot.title = element_text(hjust = 0.5, color = \"blue\"))\n\n\n\n\n\n\n\nggplot(data = exam_data, \n       aes(x = RACE)) +\n  geom_bar(fill = \"yellow\") +\n  coord_flip() +\n  theme_bw() +\n  ggtitle(\"Distribution of students by Race\") + \n  theme(plot.title = element_text(hjust = 0.5, color = \"blue\"))\n\n\n\n\n\n\n\nggplot(data = exam_data, \n       aes(x = RACE)) +\n  geom_bar(fill = \"yellow\") +\n  coord_flip() +\n  theme_classic() +\n  ggtitle(\"Distribution of students by Race\") + \n  theme(plot.title = element_text(hjust = 0.5, color = \"blue\"))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#reference",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#reference",
    "title": "Hands-on Exercise 1 - At the Home-port",
    "section": "",
    "text": "Hadley Wickham (2023) ggplot2: Elegant Graphics for Data Analysis. Online 3rd edition.\nWinston Chang (2013) R Graphics Cookbook 2nd edition. Online version.\nHealy, Kieran (2019) Data Visualization: A practical introduction. Online version\nLearning ggplot2 on Paper – Components\nLearning ggplot2 on Paper – Layer\nLearning ggplot2 on Paper – Scale"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03a/Hands-on_Ex03a.html",
    "href": "Hands-on_Ex/Hands-on_Ex03a/Hands-on_Ex03a.html",
    "title": "Hands-on Exercise 3a - Off we go (Part I)",
    "section": "",
    "text": "In this hands-on exercise, we will learn how to create interactive data visualisation by using functions provided by ggiraph and plotlyr packages.\n\n\n\nFirst, write a code chunk to check, install and launch the following R packages:\n\nggiraph for making ‘ggplot’ graphics interactive.\nplotly, R library for plotting interactive statistical graphs.\nDT provides an R interface to the JavaScript library DataTables that create interactive table on html page.\ntidyverse, a family of modern R packages specially designed to support data science, analysis and communication task including creating static statistical graphs.\npatchwork for combining multiple ggplot2 graphs into one figure.\n\nThe code chunk below will be used to accomplish the task.\n\npacman::p_load(ggiraph, plotly, patchwork, DT, tidyverse)\n\n\n\n\nIn this section,  read_csv() of readr package was used to import the provided dataset, Exam_data.csv, into R.\nThe code chunk below read_csv() of readr package is used to import Exam_data.csv data file into R and save it as an tibble data frame called exam_data.\n\nexam_data &lt;- read_csv(\"data/Exam_data.csv\")\n\nThe code chunk below uses summary() and head() function to take an initial look at the dataset.\n\nsummary(exam_data)\n\n      ID               CLASS              GENDER              RACE          \n Length:322         Length:322         Length:322         Length:322        \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n    ENGLISH          MATHS          SCIENCE     \n Min.   :21.00   Min.   : 9.00   Min.   :15.00  \n 1st Qu.:59.00   1st Qu.:58.00   1st Qu.:49.25  \n Median :70.00   Median :74.00   Median :65.00  \n Mean   :67.18   Mean   :69.33   Mean   :61.16  \n 3rd Qu.:78.00   3rd Qu.:85.00   3rd Qu.:74.75  \n Max.   :96.00   Max.   :99.00   Max.   :96.00  \n\n\n\nhead(exam_data,5)\n\n# A tibble: 5 × 7\n  ID         CLASS GENDER RACE    ENGLISH MATHS SCIENCE\n  &lt;chr&gt;      &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt;     &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;\n1 Student321 3I    Male   Malay        21     9      15\n2 Student305 3I    Female Malay        24    22      16\n3 Student289 3H    Male   Chinese      26    16      16\n4 Student227 3F    Male   Chinese      27    77      31\n5 Student318 3I    Male   Malay        27    11      25\n\n\n\n\n\nggiraph  is an htmlwidget and a ggplot2 extension. It allows ggplot graphics to be interactive.\nInteractive is made with ggplot geometries that can understand three arguments:\n\nTooltip: a column of data-sets that contain tooltips to be displayed when the mouse is over elements.\nOnclick: a column of data-sets that contain a JavaScript function to be executed when elements are clicked.\nData_id: a column of data-sets that contain an id to be associated with elements.\n\nIf it used within a shiny application, elements associated with an id (data_id) can be selected and manipulated on client and server sides. Refer to this article for more detail explanation.\n\n\nBelow shows a typical code chunk to plot an interactive statistical graph by using ggiraph package. Notice that the code chunk consists of two parts. First, an ggplot object will be created. Next, girafe() of ggiraph will be used to create an interactive svg object.\n\np &lt;- ggplot(data=exam_data,\n            aes(x = MATHS)) +\n  geom_dotplot_interactive(\n    aes(tooltip = ID),\n    stackgroups = TRUE,\n    binwidth = 1,\n    method = \"histodot\") +\n  scale_y_continuous(NULL,\n                     breaks = NULL)\n\ngirafe(\n  ggobj = p,\n  width_svg = 6,\n  height_svg = 6*0.618\n)\n\n\n\n\n\nNotice that two steps are involved. First, an interactive version of ggplot2 geom (i.e. geom_dotplot_interactive()) will be used to create the basic graph. Then, girafe() will be used to generate an svg object to be displayed on an html page.\n\n\n\n\nBy hovering the mouse pointer on an data point of interest, the student’s ID will be displayed.\n\n\n\n\n\n\n\n\nThe content of the tooltip can be customised by including a list object as shown in the code chunk below.\n\nexam_data$tooltip &lt;- c(paste0(\n  \"Name = \", exam_data$ID,\n  \"\\n Class = \", exam_data$CLASS))\n\np &lt;- ggplot(data = exam_data,\n            aes(x=MATHS)) +\n  geom_dotplot_interactive(\n    aes(tooltip = exam_data$tooltip),\n    stackgroups = TRUE,\n    binwidth = 1,\n    method = \"histodot\") +\n  scale_y_continuous(NULL,\n                     breaks=NULL)\n\ngirafe(ggobj = p,\n       width_svg = 8,\n       height_svg = 8*0.618)\n\n\n\n\n\nThe first three lines of codes in the code chunk create a new field called tooltip. At the same time, it populates text in ID and CLASS fields into the newly created field. Next, this newly created field is used as tooltip field as shown in the code of line 7.\n\n\n\n\nBy hovering the mouse pointer on an data point of interest, the student’s ID and Class will be displayed.\n\n\n\n\n\n\n\n\nCode chunk below uses opts_tooltip() of ggiraph to customize tooltip rendering by add css declarations.\n\ntooltip_css &lt;- \"background-color:black;\nfont-style:bold; color:white;\" #&lt;&lt;\n\np &lt;- ggplot(data=exam_data,\n            aes(x=MATHS)) +\n  geom_dotplot_interactive(aes(tooltip = ID),\n                           stackgroups = TRUE,\n                           binwidth = 1,\n                           method = \"histodot\") +\n  scale_y_continuous(NULL,\n                     breaks = NULL)\n\ngirafe(ggobj = p,\n       width_svg = 6,\n       height_svg = 6*0.618,\n       options = list(    #&lt;&lt;\n         opts_tooltip(    #&lt;&lt;\n           css = tooltip_css)) #&lt;&lt;\n)\n\nNotice that the background colour of the tooltip is black and the font colour is white and bold.\n\n\n\n\n\n\n\nRefer to Customizing girafe objects to learn more about how to customise ggiraph objects.\n\n\n\n\nCode chunk below shows an advanced way to customise tooltip. In this example, a function is used to compute 90% confident interval of the mean. The derived statistics are then displayed in the tooltip.\n\ntooltip &lt;- function(y, ymax, accuracy = 0.01) {\n  mean &lt;- scales::number(y, accuracy = accuracy)\n  sem &lt;- scales::number(ymax - y, accuracy = accuracy)\n  paste(\"Mean maths scores:\", mean, \"+/-\", sem)\n}\n\ngg_point &lt;- ggplot(data=exam_data,\n                   aes(x = RACE)) +\n  stat_summary(aes(y = MATHS,\n                   tooltip = after_stat(\n                     tooltip(y, ymax))),\n               fun.data = \"mean_se\",\n               geom = GeomInteractiveCol,\n               fill = \"light blue\") +\n  stat_summary(aes(y=MATHS),\n               fun.data = mean_se,\n               geom = \"errorbar\", width = 0.2, linewidth = 0.2)\n\ngirafe(ggobj = gg_point,\n       width_svg = 8,\n       height_svg = 8*0.618)\n\n\n\n\n\n\n\n\n\n\nCode chunk below shows the second interactive feature of ggiraph, namely data_id.\n\np &lt;- ggplot(data = exam_data,\n            aes(x = MATHS)) +\n  geom_dotplot_interactive(aes(data_id = CLASS, tooltip = paste0(\"Class: \", CLASS)),\n                           stackgroups = TRUE,\n                           binwidth = 1,\n                           method = \"histodot\") +\n  scale_y_continuous(NULL,\n                     breaks = NULL)\n\ngirafe(\n  ggobj = p,\n  width_svg = 6,\n  height_svg = 6*0.618\n)\n\nInteractivity: Elements associated with a data_id (i.e CLASS) will be highlighted upon mouse over.\n\n\n\n\n\n\nNote that the default value of the hover css is hover_css = “fill:orange;”.\n\n\n\nIn the code chunk below, css codes are used to change the highlighting effect.\n\np &lt;- ggplot(data = exam_data,\n            aes(x = MATHS)) +\n  geom_dotplot_interactive(\n    aes(data_id = CLASS),\n    stackgroups = TRUE,\n    binwidth = 1,\n    method = \"histodot\") +\n  scale_y_continuous(NULL,\n                     breaks = NULL)\n\ngirafe(ggobj = p,\n       width_svg = 6,\n       height_svg = 6*0.618,\n       options = list(\n         opts_hover(css = \"fill: #202020;\"),\n         opts_hover_inv(css = \"opacity:0.2;\")\n         )\n       )\n\nNote: Different from previous example, in this example the css customisation request are encoded directly.\n\n\n\n\n\n\n\n\n\nThere are time that we want to combine tooltip and hover effect on the interactive statistical graph as shown in the code chunk below.\n\np &lt;- ggplot(data = exam_data,\n            aes(x = MATHS)) +\n  geom_dotplot_interactive(\n    aes(tooltip = CLASS,\n        data_id = CLASS),\n    stackgroups = TRUE,\n    binwidth = 1,\n    method = \"histodot\") +\n  scale_y_continuous(NULL,\n                     breaks = NULL)\n\ngirafe(ggobj = p,\n       width_svg = 6,\n       height_svg = 6*0.618,\n       options = list(\n         opts_hover(css = \"fill: #202020;\"),\n         opts_hover_inv(css = \"opacity:0.2;\")\n       ))\n\nInteractivity: Elements associated with a data_id (i.e CLASS) will be highlighted upon mouse over. At the same time, the tooltip will show the CLASS.\n\n\n\n\n\n\n\n\n\nonclick argument of ggiraph provides hotlink interactivity on the web.\nThe code chunk below shown an example of onclick.\n\nexam_data$onclick &lt;- sprintf(\"window.open(\\\"%s%s\\\")\",\n                             \"https://www.moe.gov.sg/schoolfinder?journey=Primary%20school\", as.character(exam_data$ID))\n\np &lt;- ggplot(data = exam_data,\n            aes(x = MATHS)) +\n  geom_dotplot_interactive(\n    aes(onclick = onclick),\n    stackgroups = TRUE,\n    binwidth = 1,\n    method  = \"histodot\") +\n  scale_y_continuous(NULL,\n                     breaks = NULL)\n\ngirafe(ggobj = p,\n       width_svg = 6,\n       height_svg = 6*0.618)\n\nInteractivity: Web document link with a data object will be displayed on the web browser upon mouse click.\n\n\n\n\n\n\n\n\n\n\n\n\nWarning\n\n\n\nNote that click actions must be a string column in the dataset containing valid javascript instructions.\n\n\n\n\n\nCoordinated multiple views methods has been implemented in the data visualisation below.\n\n\n\n\n\n\nNotice that when a data point of one of the dotplot is selected, the corresponding data point ID on the second data visualisation will be highlighted too.\nIn order to build a coordinated multiple views as shown in the example above, the following programming strategy will be used:\n\nAppropriate interactive functions of ggiraph will be used to create the multiple views.\npatchwork function of patchwork package will be used inside girafe function to create the interactive coordinated multiple views.\n\n\np1 &lt;- ggplot(data = exam_data,\n             aes (x=MATHS)) +\n  geom_dotplot_interactive(\n    aes(data_id = ID, tooltip = ID),\n    stackgroups = TRUE,\n    binwidth = 1,\n    method = \"histodot\") +\n  coord_cartesian(xlim=c(0,100)) +\n  scale_y_continuous(NULL,\n                     breaks = NULL)\n\np2 &lt;- ggplot(data = exam_data,\n             aes (x=ENGLISH)) +\n  geom_dotplot_interactive(\n    aes(data_id = ID, tooltip = ID),\n    stackgroups = TRUE,\n    binwidth = 1,\n    method = \"histodot\") +\n  coord_cartesian(xlim=c(0,100)) +\n  scale_y_continuous(NULL,\n                     breaks = NULL)\n\ngirafe(code = print(p1 + p2),\n       width_svg = 6,\n       height_svg = 3,\n       options = list(\n         opts_hover(css = \"fill: #202020;\"),\n         opts_hover_inv(css = \"opacity:0.2\")\n       ))\n\nThe data_id aesthetic is critical to link observations between plots and the tooltip aesthetic is optional but nice to have when mouse over a point.\n\n\n\n\nPlotly’s R graphing library create interactive web graphics from ggplot2 graphs and/or a custom interface to the (MIT-licensed) JavaScript library plotly.js inspired by the grammar of graphics. Different from other plotly platform, plot.R is free and open source.\n\nThere are two ways to create interactive graph by using plotly, they are:\n\nby using plot_ly(), and\nby using ggplotly()\n\n\n\nThe tabset below shows an example a basic interactive plot created by using plot_ly().\n\nThe plotThe code chunk\n\n\n\n\n\n\n\n\n\n\n\nplot_ly(data = exam_data,\n        x = ~MATHS,\n        y = ~ENGLISH)\n\n\n\n\n\n\n\nIn the code chunk below, color argument is mapped to a qualitative visual variable (i.e. RACE).\n\nThe plotThe code chunk\n\n\n\n\n\n\n\n\nInteractive:\n\nClick on the colour symbol at the legend.\n\n\n\n\nplot_ly(data = exam_data,\n        x = ~MATHS,\n        y = ~ENGLISH,\n        color = ~RACE)\n\n\n\n\n\n\n\nThe code chunk below plots an interactive scatter plot by using ggplotly().\n\nThe plotThe code chunk\n\n\n\n#|echo: false\n\np &lt;- ggplot(data = exam_data,\n            aes(x = MATHS,\n                y = ENGLISH)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\n\nggplotly(p)\n\n\n\n\n\n\n\n\n#|eval: false\n\np &lt;- ggplot(data = exam_data,\n            aes(x = MATHS,\n                y = ENGLISH)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\n\nggplotly(p)\n\n\n\n\n\n\n\n\n\n\n\nThe creation of a coordinated linked plot by using plotly involves three steps:\n\nhighlight_key() of plotly package is used as shared data.\ntwo scatterplots will be created by using ggplot2 functions.\nlastly, subplot() of plotly package is used to place them next to each other side-by-side.\n\n\nThe plotThe code chunk\n\n\n\n\n\n\n\n\nClick on a data point of one of the scatterplot and see how the corresponding point on the other scatterplot is selected.\n\n\n\nd &lt;- highlight_key(exam_data)\np1 &lt;- ggplot(data=d,\n             aes(x=MATHS,\n                 y=ENGLISH)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\n\np2 &lt;- ggplot(data=d,\n             aes(x=MATHS,\n                 y=SCIENCE)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\n\nsubplot(ggplotly(p1), ggplotly(p2))\n\n\n\n\nThing to learn from the code chunk:\n\nhighlight_key() simply creates an object of class crosstalk::SharedData.\nVisit this link to learn more about crosstalk.\n\n\n\n\n\nCrosstalk is an add-on to the htmlwidgets package. It extends htmlwidgets with a set of classes, functions, and conventions for implementing cross-widget interactions (currently, linked brushing and filtering).\n\n\n\nA wrapper of the JavaScript Library DataTables\nData objects in R can be rendered as HTML tables using the JavaScript library ‘DataTables’ (typically via R Markdown or Shiny).\n\n\nDT::datatable(exam_data, class=\"compact\", style = \"bootstrap\")\n\n\n\n\n\n\n\n\n\n\nThe plotThe code chunk\n\n\nCode chunk below is used to implement the coordinated brushing shown above.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nd &lt;- highlight_key(exam_data)\np &lt;- ggplot(d,\n            aes(ENGLISH,\n                MATHS)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\n\ngg &lt;- highlight(ggplotly(p),\n                \"plotly_selected\")\n\ncrosstalk::bscols(gg,\n                  DT::datatable(d),\n                  widths = 5)\n\nThings to learn from the code chunk:\n\nhighlight() is a function of plotly package. It sets a variety of options for brushing (i.e., highlighting) multiple plots. These options are primarily designed for linking multiple plotly graphs, and may not behave as expected when linking plotly to another htmlwidget package via crosstalk. In some cases, other htmlwidgets will respect these options, such as persistent selection in leaflet.\nbscols() is a helper function of crosstalk package. It makes it easy to put HTML elements side by side. It can be called directly from the console but is especially designed to work in an R Markdown document. Warning: This will bring in all of Bootstrap!.\n\n\n\n\n\n\n\n\n\n\nThis link provides online version of the reference guide and several useful articles. Use this link to download the pdf version of the reference guide.\n\nHow to Plot With Ggiraph\nInteractive map of France with ggiraph\nCustom interactive sunbursts with ggplot in R\nThis link provides code example on how ggiraph is used to interactive graphs for Swiss Olympians - the solo specialists.\n\n\n\n\n\nGetting Started with Plotly in R\nA collection of plotly R graphs are available via this link.\nCarson Sievert (2020) Interactive web-based data visualization with R, plotly, and shiny, Chapman and Hall/CRC is the best resource to learn plotly for R. The online version is available via this link\nPlotly R Figure Reference provides a comprehensive discussion of each visual representations.\nPlotly R Library Fundamentals is a good place to learn the fundamental features of Plotly’s R API.\nGetting Started\nVisit this link for a very interesting implementation of gganimate by your senior.\nBuilding an animation step-by-step with gganimate.\nCreating a composite gif with multiple gganimate panels"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03a/Hands-on_Ex03a.html#learning-outcome",
    "href": "Hands-on_Ex/Hands-on_Ex03a/Hands-on_Ex03a.html#learning-outcome",
    "title": "Hands-on Exercise 3a - Off we go (Part I)",
    "section": "",
    "text": "In this hands-on exercise, we will learn how to create interactive data visualisation by using functions provided by ggiraph and plotlyr packages."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03a/Hands-on_Ex03a.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex03a/Hands-on_Ex03a.html#getting-started",
    "title": "Hands-on Exercise 3a - Off we go (Part I)",
    "section": "",
    "text": "First, write a code chunk to check, install and launch the following R packages:\n\nggiraph for making ‘ggplot’ graphics interactive.\nplotly, R library for plotting interactive statistical graphs.\nDT provides an R interface to the JavaScript library DataTables that create interactive table on html page.\ntidyverse, a family of modern R packages specially designed to support data science, analysis and communication task including creating static statistical graphs.\npatchwork for combining multiple ggplot2 graphs into one figure.\n\nThe code chunk below will be used to accomplish the task.\n\npacman::p_load(ggiraph, plotly, patchwork, DT, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03a/Hands-on_Ex03a.html#importing-data",
    "href": "Hands-on_Ex/Hands-on_Ex03a/Hands-on_Ex03a.html#importing-data",
    "title": "Hands-on Exercise 3a - Off we go (Part I)",
    "section": "",
    "text": "In this section,  read_csv() of readr package was used to import the provided dataset, Exam_data.csv, into R.\nThe code chunk below read_csv() of readr package is used to import Exam_data.csv data file into R and save it as an tibble data frame called exam_data.\n\nexam_data &lt;- read_csv(\"data/Exam_data.csv\")\n\nThe code chunk below uses summary() and head() function to take an initial look at the dataset.\n\nsummary(exam_data)\n\n      ID               CLASS              GENDER              RACE          \n Length:322         Length:322         Length:322         Length:322        \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n    ENGLISH          MATHS          SCIENCE     \n Min.   :21.00   Min.   : 9.00   Min.   :15.00  \n 1st Qu.:59.00   1st Qu.:58.00   1st Qu.:49.25  \n Median :70.00   Median :74.00   Median :65.00  \n Mean   :67.18   Mean   :69.33   Mean   :61.16  \n 3rd Qu.:78.00   3rd Qu.:85.00   3rd Qu.:74.75  \n Max.   :96.00   Max.   :99.00   Max.   :96.00  \n\n\n\nhead(exam_data,5)\n\n# A tibble: 5 × 7\n  ID         CLASS GENDER RACE    ENGLISH MATHS SCIENCE\n  &lt;chr&gt;      &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt;     &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;\n1 Student321 3I    Male   Malay        21     9      15\n2 Student305 3I    Female Malay        24    22      16\n3 Student289 3H    Male   Chinese      26    16      16\n4 Student227 3F    Male   Chinese      27    77      31\n5 Student318 3I    Male   Malay        27    11      25"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03a/Hands-on_Ex03a.html#interactive-data-visualisation---ggiraph-methods",
    "href": "Hands-on_Ex/Hands-on_Ex03a/Hands-on_Ex03a.html#interactive-data-visualisation---ggiraph-methods",
    "title": "Hands-on Exercise 3a - Off we go (Part I)",
    "section": "",
    "text": "ggiraph  is an htmlwidget and a ggplot2 extension. It allows ggplot graphics to be interactive.\nInteractive is made with ggplot geometries that can understand three arguments:\n\nTooltip: a column of data-sets that contain tooltips to be displayed when the mouse is over elements.\nOnclick: a column of data-sets that contain a JavaScript function to be executed when elements are clicked.\nData_id: a column of data-sets that contain an id to be associated with elements.\n\nIf it used within a shiny application, elements associated with an id (data_id) can be selected and manipulated on client and server sides. Refer to this article for more detail explanation.\n\n\nBelow shows a typical code chunk to plot an interactive statistical graph by using ggiraph package. Notice that the code chunk consists of two parts. First, an ggplot object will be created. Next, girafe() of ggiraph will be used to create an interactive svg object.\n\np &lt;- ggplot(data=exam_data,\n            aes(x = MATHS)) +\n  geom_dotplot_interactive(\n    aes(tooltip = ID),\n    stackgroups = TRUE,\n    binwidth = 1,\n    method = \"histodot\") +\n  scale_y_continuous(NULL,\n                     breaks = NULL)\n\ngirafe(\n  ggobj = p,\n  width_svg = 6,\n  height_svg = 6*0.618\n)\n\n\n\n\n\nNotice that two steps are involved. First, an interactive version of ggplot2 geom (i.e. geom_dotplot_interactive()) will be used to create the basic graph. Then, girafe() will be used to generate an svg object to be displayed on an html page."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03a/Hands-on_Ex03a.html#interactivity",
    "href": "Hands-on_Ex/Hands-on_Ex03a/Hands-on_Ex03a.html#interactivity",
    "title": "Hands-on Exercise 3a - Off we go (Part I)",
    "section": "",
    "text": "By hovering the mouse pointer on an data point of interest, the student’s ID will be displayed.\n\n\n\n\n\n\n\n\nThe content of the tooltip can be customised by including a list object as shown in the code chunk below.\n\nexam_data$tooltip &lt;- c(paste0(\n  \"Name = \", exam_data$ID,\n  \"\\n Class = \", exam_data$CLASS))\n\np &lt;- ggplot(data = exam_data,\n            aes(x=MATHS)) +\n  geom_dotplot_interactive(\n    aes(tooltip = exam_data$tooltip),\n    stackgroups = TRUE,\n    binwidth = 1,\n    method = \"histodot\") +\n  scale_y_continuous(NULL,\n                     breaks=NULL)\n\ngirafe(ggobj = p,\n       width_svg = 8,\n       height_svg = 8*0.618)\n\n\n\n\n\nThe first three lines of codes in the code chunk create a new field called tooltip. At the same time, it populates text in ID and CLASS fields into the newly created field. Next, this newly created field is used as tooltip field as shown in the code of line 7."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03a/Hands-on_Ex03a.html#interactivity-1",
    "href": "Hands-on_Ex/Hands-on_Ex03a/Hands-on_Ex03a.html#interactivity-1",
    "title": "Hands-on Exercise 3a - Off we go (Part I)",
    "section": "",
    "text": "By hovering the mouse pointer on an data point of interest, the student’s ID and Class will be displayed.\n\n\n\n\n\n\n\n\nCode chunk below uses opts_tooltip() of ggiraph to customize tooltip rendering by add css declarations.\n\ntooltip_css &lt;- \"background-color:black;\nfont-style:bold; color:white;\" #&lt;&lt;\n\np &lt;- ggplot(data=exam_data,\n            aes(x=MATHS)) +\n  geom_dotplot_interactive(aes(tooltip = ID),\n                           stackgroups = TRUE,\n                           binwidth = 1,\n                           method = \"histodot\") +\n  scale_y_continuous(NULL,\n                     breaks = NULL)\n\ngirafe(ggobj = p,\n       width_svg = 6,\n       height_svg = 6*0.618,\n       options = list(    #&lt;&lt;\n         opts_tooltip(    #&lt;&lt;\n           css = tooltip_css)) #&lt;&lt;\n)\n\nNotice that the background colour of the tooltip is black and the font colour is white and bold.\n\n\n\n\n\n\n\nRefer to Customizing girafe objects to learn more about how to customise ggiraph objects.\n\n\n\n\nCode chunk below shows an advanced way to customise tooltip. In this example, a function is used to compute 90% confident interval of the mean. The derived statistics are then displayed in the tooltip.\n\ntooltip &lt;- function(y, ymax, accuracy = 0.01) {\n  mean &lt;- scales::number(y, accuracy = accuracy)\n  sem &lt;- scales::number(ymax - y, accuracy = accuracy)\n  paste(\"Mean maths scores:\", mean, \"+/-\", sem)\n}\n\ngg_point &lt;- ggplot(data=exam_data,\n                   aes(x = RACE)) +\n  stat_summary(aes(y = MATHS,\n                   tooltip = after_stat(\n                     tooltip(y, ymax))),\n               fun.data = \"mean_se\",\n               geom = GeomInteractiveCol,\n               fill = \"light blue\") +\n  stat_summary(aes(y=MATHS),\n               fun.data = mean_se,\n               geom = \"errorbar\", width = 0.2, linewidth = 0.2)\n\ngirafe(ggobj = gg_point,\n       width_svg = 8,\n       height_svg = 8*0.618)\n\n\n\n\n\n\n\n\n\n\nCode chunk below shows the second interactive feature of ggiraph, namely data_id.\n\np &lt;- ggplot(data = exam_data,\n            aes(x = MATHS)) +\n  geom_dotplot_interactive(aes(data_id = CLASS, tooltip = paste0(\"Class: \", CLASS)),\n                           stackgroups = TRUE,\n                           binwidth = 1,\n                           method = \"histodot\") +\n  scale_y_continuous(NULL,\n                     breaks = NULL)\n\ngirafe(\n  ggobj = p,\n  width_svg = 6,\n  height_svg = 6*0.618\n)\n\nInteractivity: Elements associated with a data_id (i.e CLASS) will be highlighted upon mouse over.\n\n\n\n\n\n\nNote that the default value of the hover css is hover_css = “fill:orange;”.\n\n\n\nIn the code chunk below, css codes are used to change the highlighting effect.\n\np &lt;- ggplot(data = exam_data,\n            aes(x = MATHS)) +\n  geom_dotplot_interactive(\n    aes(data_id = CLASS),\n    stackgroups = TRUE,\n    binwidth = 1,\n    method = \"histodot\") +\n  scale_y_continuous(NULL,\n                     breaks = NULL)\n\ngirafe(ggobj = p,\n       width_svg = 6,\n       height_svg = 6*0.618,\n       options = list(\n         opts_hover(css = \"fill: #202020;\"),\n         opts_hover_inv(css = \"opacity:0.2;\")\n         )\n       )\n\nNote: Different from previous example, in this example the css customisation request are encoded directly.\n\n\n\n\n\n\n\n\n\nThere are time that we want to combine tooltip and hover effect on the interactive statistical graph as shown in the code chunk below.\n\np &lt;- ggplot(data = exam_data,\n            aes(x = MATHS)) +\n  geom_dotplot_interactive(\n    aes(tooltip = CLASS,\n        data_id = CLASS),\n    stackgroups = TRUE,\n    binwidth = 1,\n    method = \"histodot\") +\n  scale_y_continuous(NULL,\n                     breaks = NULL)\n\ngirafe(ggobj = p,\n       width_svg = 6,\n       height_svg = 6*0.618,\n       options = list(\n         opts_hover(css = \"fill: #202020;\"),\n         opts_hover_inv(css = \"opacity:0.2;\")\n       ))\n\nInteractivity: Elements associated with a data_id (i.e CLASS) will be highlighted upon mouse over. At the same time, the tooltip will show the CLASS.\n\n\n\n\n\n\n\n\n\nonclick argument of ggiraph provides hotlink interactivity on the web.\nThe code chunk below shown an example of onclick.\n\nexam_data$onclick &lt;- sprintf(\"window.open(\\\"%s%s\\\")\",\n                             \"https://www.moe.gov.sg/schoolfinder?journey=Primary%20school\", as.character(exam_data$ID))\n\np &lt;- ggplot(data = exam_data,\n            aes(x = MATHS)) +\n  geom_dotplot_interactive(\n    aes(onclick = onclick),\n    stackgroups = TRUE,\n    binwidth = 1,\n    method  = \"histodot\") +\n  scale_y_continuous(NULL,\n                     breaks = NULL)\n\ngirafe(ggobj = p,\n       width_svg = 6,\n       height_svg = 6*0.618)\n\nInteractivity: Web document link with a data object will be displayed on the web browser upon mouse click.\n\n\n\n\n\n\n\n\n\n\n\n\nWarning\n\n\n\nNote that click actions must be a string column in the dataset containing valid javascript instructions.\n\n\n\n\n\nCoordinated multiple views methods has been implemented in the data visualisation below.\n\n\n\n\n\n\nNotice that when a data point of one of the dotplot is selected, the corresponding data point ID on the second data visualisation will be highlighted too.\nIn order to build a coordinated multiple views as shown in the example above, the following programming strategy will be used:\n\nAppropriate interactive functions of ggiraph will be used to create the multiple views.\npatchwork function of patchwork package will be used inside girafe function to create the interactive coordinated multiple views.\n\n\np1 &lt;- ggplot(data = exam_data,\n             aes (x=MATHS)) +\n  geom_dotplot_interactive(\n    aes(data_id = ID, tooltip = ID),\n    stackgroups = TRUE,\n    binwidth = 1,\n    method = \"histodot\") +\n  coord_cartesian(xlim=c(0,100)) +\n  scale_y_continuous(NULL,\n                     breaks = NULL)\n\np2 &lt;- ggplot(data = exam_data,\n             aes (x=ENGLISH)) +\n  geom_dotplot_interactive(\n    aes(data_id = ID, tooltip = ID),\n    stackgroups = TRUE,\n    binwidth = 1,\n    method = \"histodot\") +\n  coord_cartesian(xlim=c(0,100)) +\n  scale_y_continuous(NULL,\n                     breaks = NULL)\n\ngirafe(code = print(p1 + p2),\n       width_svg = 6,\n       height_svg = 3,\n       options = list(\n         opts_hover(css = \"fill: #202020;\"),\n         opts_hover_inv(css = \"opacity:0.2\")\n       ))\n\nThe data_id aesthetic is critical to link observations between plots and the tooltip aesthetic is optional but nice to have when mouse over a point."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03a/Hands-on_Ex03a.html#interactive-data-visualisation---plotly-methods",
    "href": "Hands-on_Ex/Hands-on_Ex03a/Hands-on_Ex03a.html#interactive-data-visualisation---plotly-methods",
    "title": "Hands-on Exercise 3a - Off we go (Part I)",
    "section": "",
    "text": "Plotly’s R graphing library create interactive web graphics from ggplot2 graphs and/or a custom interface to the (MIT-licensed) JavaScript library plotly.js inspired by the grammar of graphics. Different from other plotly platform, plot.R is free and open source.\n\nThere are two ways to create interactive graph by using plotly, they are:\n\nby using plot_ly(), and\nby using ggplotly()\n\n\n\nThe tabset below shows an example a basic interactive plot created by using plot_ly().\n\nThe plotThe code chunk\n\n\n\n\n\n\n\n\n\n\n\nplot_ly(data = exam_data,\n        x = ~MATHS,\n        y = ~ENGLISH)\n\n\n\n\n\n\n\nIn the code chunk below, color argument is mapped to a qualitative visual variable (i.e. RACE).\n\nThe plotThe code chunk\n\n\n\n\n\n\n\n\nInteractive:\n\nClick on the colour symbol at the legend.\n\n\n\n\nplot_ly(data = exam_data,\n        x = ~MATHS,\n        y = ~ENGLISH,\n        color = ~RACE)\n\n\n\n\n\n\n\nThe code chunk below plots an interactive scatter plot by using ggplotly().\n\nThe plotThe code chunk\n\n\n\n#|echo: false\n\np &lt;- ggplot(data = exam_data,\n            aes(x = MATHS,\n                y = ENGLISH)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\n\nggplotly(p)\n\n\n\n\n\n\n\n\n#|eval: false\n\np &lt;- ggplot(data = exam_data,\n            aes(x = MATHS,\n                y = ENGLISH)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\n\nggplotly(p)\n\n\n\n\n\n\n\n\n\n\n\nThe creation of a coordinated linked plot by using plotly involves three steps:\n\nhighlight_key() of plotly package is used as shared data.\ntwo scatterplots will be created by using ggplot2 functions.\nlastly, subplot() of plotly package is used to place them next to each other side-by-side.\n\n\nThe plotThe code chunk\n\n\n\n\n\n\n\n\nClick on a data point of one of the scatterplot and see how the corresponding point on the other scatterplot is selected.\n\n\n\nd &lt;- highlight_key(exam_data)\np1 &lt;- ggplot(data=d,\n             aes(x=MATHS,\n                 y=ENGLISH)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\n\np2 &lt;- ggplot(data=d,\n             aes(x=MATHS,\n                 y=SCIENCE)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\n\nsubplot(ggplotly(p1), ggplotly(p2))\n\n\n\n\nThing to learn from the code chunk:\n\nhighlight_key() simply creates an object of class crosstalk::SharedData.\nVisit this link to learn more about crosstalk."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03a/Hands-on_Ex03a.html#interactive-data-visualisation---crosstalk-methods",
    "href": "Hands-on_Ex/Hands-on_Ex03a/Hands-on_Ex03a.html#interactive-data-visualisation---crosstalk-methods",
    "title": "Hands-on Exercise 3a - Off we go (Part I)",
    "section": "",
    "text": "Crosstalk is an add-on to the htmlwidgets package. It extends htmlwidgets with a set of classes, functions, and conventions for implementing cross-widget interactions (currently, linked brushing and filtering).\n\n\n\nA wrapper of the JavaScript Library DataTables\nData objects in R can be rendered as HTML tables using the JavaScript library ‘DataTables’ (typically via R Markdown or Shiny).\n\n\nDT::datatable(exam_data, class=\"compact\", style = \"bootstrap\")\n\n\n\n\n\n\n\n\n\n\nThe plotThe code chunk\n\n\nCode chunk below is used to implement the coordinated brushing shown above.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nd &lt;- highlight_key(exam_data)\np &lt;- ggplot(d,\n            aes(ENGLISH,\n                MATHS)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\n\ngg &lt;- highlight(ggplotly(p),\n                \"plotly_selected\")\n\ncrosstalk::bscols(gg,\n                  DT::datatable(d),\n                  widths = 5)\n\nThings to learn from the code chunk:\n\nhighlight() is a function of plotly package. It sets a variety of options for brushing (i.e., highlighting) multiple plots. These options are primarily designed for linking multiple plotly graphs, and may not behave as expected when linking plotly to another htmlwidget package via crosstalk. In some cases, other htmlwidgets will respect these options, such as persistent selection in leaflet.\nbscols() is a helper function of crosstalk package. It makes it easy to put HTML elements side by side. It can be called directly from the console but is especially designed to work in an R Markdown document. Warning: This will bring in all of Bootstrap!."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03a/Hands-on_Ex03a.html#reference",
    "href": "Hands-on_Ex/Hands-on_Ex03a/Hands-on_Ex03a.html#reference",
    "title": "Hands-on Exercise 3a - Off we go (Part I)",
    "section": "",
    "text": "This link provides online version of the reference guide and several useful articles. Use this link to download the pdf version of the reference guide.\n\nHow to Plot With Ggiraph\nInteractive map of France with ggiraph\nCustom interactive sunbursts with ggplot in R\nThis link provides code example on how ggiraph is used to interactive graphs for Swiss Olympians - the solo specialists.\n\n\n\n\n\nGetting Started with Plotly in R\nA collection of plotly R graphs are available via this link.\nCarson Sievert (2020) Interactive web-based data visualization with R, plotly, and shiny, Chapman and Hall/CRC is the best resource to learn plotly for R. The online version is available via this link\nPlotly R Figure Reference provides a comprehensive discussion of each visual representations.\nPlotly R Library Fundamentals is a good place to learn the fundamental features of Plotly’s R API.\nGetting Started\nVisit this link for a very interesting implementation of gganimate by your senior.\nBuilding an animation step-by-step with gganimate.\nCreating a composite gif with multiple gganimate panels"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04a/Hands-on_Ex04a.html",
    "href": "Hands-on_Ex/Hands-on_Ex04a/Hands-on_Ex04a.html",
    "title": "Hands-on Exercise 4a",
    "section": "",
    "text": "Visualising distribution is not new in statistical analysis. In chapter 1 we have shared with you some of the popular statistical graphics methods for visualising distribution are histogram, probability density curve (pdf), boxplot, notch plot and violin plot and how they can be created by using ggplot2. In this chapter, we are going to share with you two relatively new statistical graphic methods for visualising distribution, namely ridgeline plot and raincloud plot by using ggplot2 and its extensions.\n\n\n\n\n\nFor the purpose of this exercise, the following R packages will be used, they are:\n\ntidyverse, a family of R packages for data science process,\nggridges, a ggplot2 extension specially designed for plotting ridgeline plots, and\nggdist for visualising distribution and uncertainty.\n\n\npacman::p_load(ggdist, ggridges, ggthemes,\n               colorspace, tidyverse, plotly, ggplot2, ggiraph)\n\n\n\n\nFor the purpose of this exercise, Exam_data.csv will be used.\n\nexam &lt;- read_csv(\"data/Exam_data.csv\")\n\n\n\n\n\nRidgeline plot (sometimes called Joyplot) is a data visualisation technique for revealing the distribution of a numeric value for several groups. Distribution can be represented using histograms or density plots, all aligned to the same horizontal scale and presented with a slight overlap.\nFigure below is a ridgelines plot showing the distribution of English score by class.\n\n\n\n\n\n\n\nNote\n\n\n\n\nRidgeline plots make sense when the number of group to represent is medium to high, and thus a classic window separation would take to much space. Indeed, the fact that groups overlap each other allows to use space more efficiently. If you have less than 5 groups, dealing with other distribution plots is probably better.\nIt works well when there is a clear pattern in the result, like if there is an obvious ranking in groups. Otherwise group will tend to overlap each other, leading to a messy plot not providing any insight.\n\n\n\n\n\nThere are several ways to plot ridgeline plot with R. In this section, you will learn how to plot ridgeline plot by using ggridges package.\nggridges package provides two main geom to plot gridgeline plots, they are: geom_ridgeline() and geom_density_ridges(). The former takes height values directly to draw the ridgelines, and the latter first estimates data densities and then draws those using ridgelines.\nThe ridgeline plot below is plotted by using  geom_density_ridges().\n\nThe plotThe code chunk\n\n\n\n\n\n\n\n\n\n\nggplot(exam,\n       aes(x=ENGLISH,\n           y=CLASS)) +\n  geom_density_ridges(\n    scale=3,\n    rel_min_height=0.01,\n    bandwidth=3.4,\n    fill=lighten(\"#7097BB\", .3),\n    color=\"white\"\n  ) +\n  scale_x_continuous(\n    name=\"English Grades\",\n    expand=c(0,0)\n  ) +\n  scale_y_discrete(name = NULL, expand = expansion(add = c(0.2,2.6))) +\n  theme_ridges()\n\n\n\n\n\n\n\nSometimes we would like to have the area under a ridgeline not filled with a single solid color but rather with colors that vary in some form along the x axis. This effect can be achieved by using either geom_ridgeline_gradient() or geom_density_ridges_gradient(). Both geoms work just like geom_ridgeline() and geom_density_ridges(), except that they allow for varying fill colors. However, they do not allow for alpha transparency in the fill. For technical reasons, we can have changing fill colors or transparency but not both.\n\nThe plotThe code chunk\n\n\n\n\n\n\n\n\n\n\nggplot(exam,\n       aes(x=ENGLISH,\n           y=CLASS,\n           fill=stat(x))) +\n  geom_density_ridges_gradient(\n    scale=3,\n    rel_min_height=0.01) +\n  scale_fill_viridis_c(name = \"Temp. [F]\",\n                       option = \"C\") +\n  scale_x_continuous(\n    name = \"English grades\",\n    expand = c(0,0)\n  ) +\n  scale_y_discrete(name = NULL,\n                   expand = expansion(add = c(0.2, 2.6))) + \n  theme_ridges()\n\n\n\n\n\n\n\nBeside providing additional geom objects to support the need to plot ridgeline plot, ggridges package also provides a stat function called stat_density_ridges() that replaces stat_density() of ggplot2.\nFigure below is plotted by mapping the probabilities calculated by using stat(ecdf) which represent the empirical cumulative density function for the distribution of English score.\n\nThe plotThe code chunk\n\n\n\n\n\n\n\n\n\n\nggplot(exam,\n       aes(x=ENGLISH,\n           y=CLASS,\n           fill = 0.5-abs(0.5-stat(ecdf)))) +\n  stat_density_ridges(geom = \"density_ridges_gradient\",\n                      calc_ecdf = TRUE) +\n  scale_fill_viridis_c(name = \"Tail probability\",\n                       direction = -1,\n                       option = \"A\") +\n  theme_ridges()\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nIt is important include the argument calc_ecdf = TRUE in stat_density_ridges().\n\n\n\n\n\n\nBy using geom_density_ridges_gradient(), we can colour the ridgeline plot by quantile, via the calculated stat(quantile) aesthetic as shown in the figure below.\n\nThe plotThe code chunk\n\n\n\n\n\n\n\n\n\n\nggplot(exam,\n       aes(x=ENGLISH,\n           y=CLASS,\n           fill=factor(stat(quantile)))) +\n  stat_density_ridges(\n    geom=\"density_ridges_gradient\",\n    calc_ecdf=T,\n    quantiles=4,\n    quantile_lines=T) +\n  scale_fill_viridis_d(name=\"Quartiles\") +\n  theme_ridges()\n\n\n\n\nInstead of using number to define the quantiles, we can also specify quantiles by cut points such as 2.5% and 97.5% tails to colour the ridgeline plot as shown in the figure below.\n\nThe plotThe code chunk\n\n\n\n\n\n\n\n\n\n\nggplot(exam,\n       aes(x=ENGLISH,\n           y=CLASS,\n           fill=factor(stat(quantile)))) +\n  stat_density_ridges(geom = \"density_ridges_gradient\",\n                      calc_ecdf = T,\n                      quantiles = c(0.025, 0.975)) +\n  scale_fill_manual(name = \"Probability\",\n                    values = c(\"#FF0000A0\", \"#A0A0A0A0\", \"#0000FFA0\"),\n                    labels = c(\"(0, 0.025]\", \"(0.025, 0.975]\", \"(0.975, 1]\")) +\n  theme_ridges()\n\n\n\nRaincloud Plot is a data visualisation techniques that produces a half-density to a distribution plot. It gets the name because the density plot is in the shape of a “raincloud”. The raincloud (half-density) plot enhances the traditional box-plot by highlighting multiple modalities (an indicator that groups may exist). The boxplot does not show where densities are clustered, but the raincloud plot does!\nIn this section, you will learn how to create a raincloud plot to visualise the distribution of English score by race. It will be created by using functions provided by ggdist and ggplot2 packages.\n\n\n\n\n\n\nFirst, we will plot a Half-Eye graph by using stat_halfeye() of ggdist package.\nThis produces a Half Eye visualization, which is contains a half-density and a slab-interval.\n\nThe plotThe code chunk\n\n\n\n\n\n\n\n\n\n\nggplot(exam,\n       aes(x=RACE,\n           y=ENGLISH)) +\n  stat_halfeye(adjust=0.5,\n               justification=-0.2,\n               .width=0,\n               point_colour = NA)\n\n\n\n\n\n\n\nNext, we will add the second geometry layer using geom_boxplot() of ggplot2. This produces a narrow boxplot. We reduce the width and adjust the opacity.\n\nThe plotThe code chunk\n\n\n\n\n\n\n\n\n\n\nggplot(exam,\n       aes(x=RACE,\n           y=ENGLISH)) +\n  stat_halfeye(adjust=0.5,\n               justification=-0.2,\n               .width=0,\n               point_colour = NA) +\n  geom_boxplot(width = .20,\n               outlier.shape = NA)\n\n\n\n\n\n\n\nNext, we will add the third geometry layer using stat_dots() of ggdist package. This produces a half-dotplot, which is similar to a histogram that indicates the number of samples (number of dots) in each bin. We select side = “left” to indicate we want it on the left-hand side.\n\nThe plotThe code chunk\n\n\n\n\n\n\n\n\n\n\nggplot(exam,\n       aes(x=RACE,\n           y=ENGLISH)) +\n  stat_halfeye(adjust=0.5,\n               justification=-0.2,\n               .width=0,\n               point_colour = NA) +\n  geom_boxplot(width = .20,\n               outlier.shape = NA) +\n  stat_dots(side = \"left\",\n            justification = 1.2,\n            binwidth = .5,\n            dotsize = 2)\n\n\n\n\n\n\n\nLastly, coord_flip() of ggplot2 package will be used to flip the raincloud chart horizontally to give it the raincloud appearance. At the same time, theme_economist() of ggthemes package is used to give the raincloud chart a professional publishing standard look.\n\nThe plotThe code chunk\n\n\n\n\n\n\n\n\n\n\nggplot(exam,\n       aes(x=RACE,\n           y=ENGLISH)) +\n  stat_halfeye(adjust=0.5,\n               justification=-0.2,\n               .width=0,\n               point_colour = NA) +\n  geom_boxplot_interactive(aes(tooltip = ENGLISH),\n                           width = .20,\n                           outlier.shape = NA) +\n  stat_dots(side = \"left\",\n            justification = 1.2,\n            binwidth = .5,\n            dotsize = 1.5) +\n  coord_flip() +\n  theme_economist()\n\n\n\n\nInteractive version (Using ggiraph):\n\nlibrary(see)\n\ninteractive &lt;- ggplot(exam, aes(x=RACE,\n           y=ENGLISH, color=RACE)) +\n    geom_violinhalf(position = position_nudge(x = .4, y = 0)) +\n    geom_boxplot_interactive(width = .10,\n                           outlier.shape = NA,\n                           position = position_nudge(x = .25, y = 0)) +\n    coord_flip(xlim = c(1.2, 4.3))+\n    geom_jitter_interactive(aes(color = RACE, tooltip = paste0(ID, \"\\nScore: \", ENGLISH)),\n                width=0.15, alpha = 0.6)+\n    theme_economist() +\n    theme(legend.position=\"none\")\n\ngirafe(\n  ggobj = interactive,\n  width_svg = 6,\n  height_svg = 6*0.618)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04a/Hands-on_Ex04a.html#learning-outcome",
    "href": "Hands-on_Ex/Hands-on_Ex04a/Hands-on_Ex04a.html#learning-outcome",
    "title": "Hands-on Exercise 4a",
    "section": "",
    "text": "Visualising distribution is not new in statistical analysis. In chapter 1 we have shared with you some of the popular statistical graphics methods for visualising distribution are histogram, probability density curve (pdf), boxplot, notch plot and violin plot and how they can be created by using ggplot2. In this chapter, we are going to share with you two relatively new statistical graphic methods for visualising distribution, namely ridgeline plot and raincloud plot by using ggplot2 and its extensions."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04a/Hands-on_Ex04a.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex04a/Hands-on_Ex04a.html#getting-started",
    "title": "Hands-on Exercise 4a",
    "section": "",
    "text": "For the purpose of this exercise, the following R packages will be used, they are:\n\ntidyverse, a family of R packages for data science process,\nggridges, a ggplot2 extension specially designed for plotting ridgeline plots, and\nggdist for visualising distribution and uncertainty.\n\n\npacman::p_load(ggdist, ggridges, ggthemes,\n               colorspace, tidyverse, plotly, ggplot2, ggiraph)\n\n\n\n\nFor the purpose of this exercise, Exam_data.csv will be used.\n\nexam &lt;- read_csv(\"data/Exam_data.csv\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04a/Hands-on_Ex04a.html#visualising-distribution-with-ridgeline-plot",
    "href": "Hands-on_Ex/Hands-on_Ex04a/Hands-on_Ex04a.html#visualising-distribution-with-ridgeline-plot",
    "title": "Hands-on Exercise 4a",
    "section": "",
    "text": "Ridgeline plot (sometimes called Joyplot) is a data visualisation technique for revealing the distribution of a numeric value for several groups. Distribution can be represented using histograms or density plots, all aligned to the same horizontal scale and presented with a slight overlap.\nFigure below is a ridgelines plot showing the distribution of English score by class.\n\n\n\n\n\n\n\nNote\n\n\n\n\nRidgeline plots make sense when the number of group to represent is medium to high, and thus a classic window separation would take to much space. Indeed, the fact that groups overlap each other allows to use space more efficiently. If you have less than 5 groups, dealing with other distribution plots is probably better.\nIt works well when there is a clear pattern in the result, like if there is an obvious ranking in groups. Otherwise group will tend to overlap each other, leading to a messy plot not providing any insight.\n\n\n\n\n\nThere are several ways to plot ridgeline plot with R. In this section, you will learn how to plot ridgeline plot by using ggridges package.\nggridges package provides two main geom to plot gridgeline plots, they are: geom_ridgeline() and geom_density_ridges(). The former takes height values directly to draw the ridgelines, and the latter first estimates data densities and then draws those using ridgelines.\nThe ridgeline plot below is plotted by using  geom_density_ridges().\n\nThe plotThe code chunk\n\n\n\n\n\n\n\n\n\n\nggplot(exam,\n       aes(x=ENGLISH,\n           y=CLASS)) +\n  geom_density_ridges(\n    scale=3,\n    rel_min_height=0.01,\n    bandwidth=3.4,\n    fill=lighten(\"#7097BB\", .3),\n    color=\"white\"\n  ) +\n  scale_x_continuous(\n    name=\"English Grades\",\n    expand=c(0,0)\n  ) +\n  scale_y_discrete(name = NULL, expand = expansion(add = c(0.2,2.6))) +\n  theme_ridges()\n\n\n\n\n\n\n\nSometimes we would like to have the area under a ridgeline not filled with a single solid color but rather with colors that vary in some form along the x axis. This effect can be achieved by using either geom_ridgeline_gradient() or geom_density_ridges_gradient(). Both geoms work just like geom_ridgeline() and geom_density_ridges(), except that they allow for varying fill colors. However, they do not allow for alpha transparency in the fill. For technical reasons, we can have changing fill colors or transparency but not both.\n\nThe plotThe code chunk\n\n\n\n\n\n\n\n\n\n\nggplot(exam,\n       aes(x=ENGLISH,\n           y=CLASS,\n           fill=stat(x))) +\n  geom_density_ridges_gradient(\n    scale=3,\n    rel_min_height=0.01) +\n  scale_fill_viridis_c(name = \"Temp. [F]\",\n                       option = \"C\") +\n  scale_x_continuous(\n    name = \"English grades\",\n    expand = c(0,0)\n  ) +\n  scale_y_discrete(name = NULL,\n                   expand = expansion(add = c(0.2, 2.6))) + \n  theme_ridges()\n\n\n\n\n\n\n\nBeside providing additional geom objects to support the need to plot ridgeline plot, ggridges package also provides a stat function called stat_density_ridges() that replaces stat_density() of ggplot2.\nFigure below is plotted by mapping the probabilities calculated by using stat(ecdf) which represent the empirical cumulative density function for the distribution of English score.\n\nThe plotThe code chunk\n\n\n\n\n\n\n\n\n\n\nggplot(exam,\n       aes(x=ENGLISH,\n           y=CLASS,\n           fill = 0.5-abs(0.5-stat(ecdf)))) +\n  stat_density_ridges(geom = \"density_ridges_gradient\",\n                      calc_ecdf = TRUE) +\n  scale_fill_viridis_c(name = \"Tail probability\",\n                       direction = -1,\n                       option = \"A\") +\n  theme_ridges()\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nIt is important include the argument calc_ecdf = TRUE in stat_density_ridges()."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04a/Hands-on_Ex04a.html#ridgeline-plots-with-quantile-lines",
    "href": "Hands-on_Ex/Hands-on_Ex04a/Hands-on_Ex04a.html#ridgeline-plots-with-quantile-lines",
    "title": "Hands-on Exercise 4a",
    "section": "",
    "text": "By using geom_density_ridges_gradient(), we can colour the ridgeline plot by quantile, via the calculated stat(quantile) aesthetic as shown in the figure below.\n\nThe plotThe code chunk\n\n\n\n\n\n\n\n\n\n\nggplot(exam,\n       aes(x=ENGLISH,\n           y=CLASS,\n           fill=factor(stat(quantile)))) +\n  stat_density_ridges(\n    geom=\"density_ridges_gradient\",\n    calc_ecdf=T,\n    quantiles=4,\n    quantile_lines=T) +\n  scale_fill_viridis_d(name=\"Quartiles\") +\n  theme_ridges()\n\n\n\n\nInstead of using number to define the quantiles, we can also specify quantiles by cut points such as 2.5% and 97.5% tails to colour the ridgeline plot as shown in the figure below.\n\nThe plotThe code chunk\n\n\n\n\n\n\n\n\n\n\nggplot(exam,\n       aes(x=ENGLISH,\n           y=CLASS,\n           fill=factor(stat(quantile)))) +\n  stat_density_ridges(geom = \"density_ridges_gradient\",\n                      calc_ecdf = T,\n                      quantiles = c(0.025, 0.975)) +\n  scale_fill_manual(name = \"Probability\",\n                    values = c(\"#FF0000A0\", \"#A0A0A0A0\", \"#0000FFA0\"),\n                    labels = c(\"(0, 0.025]\", \"(0.025, 0.975]\", \"(0.975, 1]\")) +\n  theme_ridges()\n\n\n\nRaincloud Plot is a data visualisation techniques that produces a half-density to a distribution plot. It gets the name because the density plot is in the shape of a “raincloud”. The raincloud (half-density) plot enhances the traditional box-plot by highlighting multiple modalities (an indicator that groups may exist). The boxplot does not show where densities are clustered, but the raincloud plot does!\nIn this section, you will learn how to create a raincloud plot to visualise the distribution of English score by race. It will be created by using functions provided by ggdist and ggplot2 packages.\n\n\n\n\n\n\nFirst, we will plot a Half-Eye graph by using stat_halfeye() of ggdist package.\nThis produces a Half Eye visualization, which is contains a half-density and a slab-interval.\n\nThe plotThe code chunk\n\n\n\n\n\n\n\n\n\n\nggplot(exam,\n       aes(x=RACE,\n           y=ENGLISH)) +\n  stat_halfeye(adjust=0.5,\n               justification=-0.2,\n               .width=0,\n               point_colour = NA)\n\n\n\n\n\n\n\nNext, we will add the second geometry layer using geom_boxplot() of ggplot2. This produces a narrow boxplot. We reduce the width and adjust the opacity.\n\nThe plotThe code chunk\n\n\n\n\n\n\n\n\n\n\nggplot(exam,\n       aes(x=RACE,\n           y=ENGLISH)) +\n  stat_halfeye(adjust=0.5,\n               justification=-0.2,\n               .width=0,\n               point_colour = NA) +\n  geom_boxplot(width = .20,\n               outlier.shape = NA)\n\n\n\n\n\n\n\nNext, we will add the third geometry layer using stat_dots() of ggdist package. This produces a half-dotplot, which is similar to a histogram that indicates the number of samples (number of dots) in each bin. We select side = “left” to indicate we want it on the left-hand side.\n\nThe plotThe code chunk\n\n\n\n\n\n\n\n\n\n\nggplot(exam,\n       aes(x=RACE,\n           y=ENGLISH)) +\n  stat_halfeye(adjust=0.5,\n               justification=-0.2,\n               .width=0,\n               point_colour = NA) +\n  geom_boxplot(width = .20,\n               outlier.shape = NA) +\n  stat_dots(side = \"left\",\n            justification = 1.2,\n            binwidth = .5,\n            dotsize = 2)\n\n\n\n\n\n\n\nLastly, coord_flip() of ggplot2 package will be used to flip the raincloud chart horizontally to give it the raincloud appearance. At the same time, theme_economist() of ggthemes package is used to give the raincloud chart a professional publishing standard look.\n\nThe plotThe code chunk\n\n\n\n\n\n\n\n\n\n\nggplot(exam,\n       aes(x=RACE,\n           y=ENGLISH)) +\n  stat_halfeye(adjust=0.5,\n               justification=-0.2,\n               .width=0,\n               point_colour = NA) +\n  geom_boxplot_interactive(aes(tooltip = ENGLISH),\n                           width = .20,\n                           outlier.shape = NA) +\n  stat_dots(side = \"left\",\n            justification = 1.2,\n            binwidth = .5,\n            dotsize = 1.5) +\n  coord_flip() +\n  theme_economist()\n\n\n\n\nInteractive version (Using ggiraph):\n\nlibrary(see)\n\ninteractive &lt;- ggplot(exam, aes(x=RACE,\n           y=ENGLISH, color=RACE)) +\n    geom_violinhalf(position = position_nudge(x = .4, y = 0)) +\n    geom_boxplot_interactive(width = .10,\n                           outlier.shape = NA,\n                           position = position_nudge(x = .25, y = 0)) +\n    coord_flip(xlim = c(1.2, 4.3))+\n    geom_jitter_interactive(aes(color = RACE, tooltip = paste0(ID, \"\\nScore: \", ENGLISH)),\n                width=0.15, alpha = 0.6)+\n    theme_economist() +\n    theme(legend.position=\"none\")\n\ngirafe(\n  ggobj = interactive,\n  width_svg = 6,\n  height_svg = 6*0.618)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04a/Hands-on_Ex04a.html#visualising-distribution-with-raincloud-plot",
    "href": "Hands-on_Ex/Hands-on_Ex04a/Hands-on_Ex04a.html#visualising-distribution-with-raincloud-plot",
    "title": "Hands-on Exercise 4a",
    "section": "",
    "text": "Raincloud Plot is a data visualisation techniques that produces a half-density to a distribution plot. It gets the name because the density plot is in the shape of a “raincloud”. The raincloud (half-density) plot enhances the traditional box-plot by highlighting multiple modalities (an indicator that groups may exist). The boxplot does not show where densities are clustered, but the raincloud plot does!\nIn this section, you will learn how to create a raincloud plot to visualise the distribution of English score by race. It will be created by using functions provided by ggdist and ggplot2 packages."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04c/Hands-on_Ex04c.html",
    "href": "Hands-on_Ex/Hands-on_Ex04c/Hands-on_Ex04c.html",
    "title": "Hands-on Exercise 4c",
    "section": "",
    "text": "Visualising uncertainty is relatively new in statistical graphics. In this chapter, you will gain hands-on experience on creating statistical graphics for visualising uncertainty. By the end of this chapter you will be able:\n\nto plot statistics error bars by using ggplot2,\nto plot interactive error bars by combining ggplot2, plotly and DT,\nto create advanced by using ggdist, and\nto create hypothetical outcome plots (HOPs) by using ungeviz package.\n\n\n\n\n\n\nFor the purpose of this exercise, the following R packages will be used, they are:\n\ntidyverse, a family of R packages for data science process,\nplotly for creating interactive plot,\ngganimate for creating animation plot,\nDT for displaying interactive html table,\ncrosstalk for for implementing cross-widget interactions (currently, linked brushing and filtering), and\nggdist for visualising distribution and uncertainty.\n\n\ndevtools::install_github(\"wilkelab/ungeviz\")\n\n\npacman::p_load(ungeviz, plotly, crosstalk,\n               DT, ggdist, ggridges,\n               colorspace, gganimate, tidyverse)\n\n\n\n\nFor the purpose of this exercise, Exam_data.csv will be used.\n\nexam &lt;- read_csv(\"data/Exam_Data.csv\")\n\n\n\n\n\nA point estimate is a single number, such as a mean. Uncertainty, on the other hand, is expressed as standard error, confidence interval, or credible interval.\n\n\n\n\n\n\nImportant\n\n\n\n\nDon’t confuse the uncertainty of a point estimate with the variation in the sample\n\n\n\nIn this section, you will learn how to plot error bars of maths scores by race by using data provided in exam tibble data frame.\nFirstly, code chunk below will be used to derive the necessary summary statistics.\n\nmy_sum &lt;- exam %&gt;% \n  group_by(RACE) %&gt;% \n  summarise(\n    n=n(),\n    mean=mean(MATHS),\n    sd=sd(MATHS)\n  ) %&gt;% \n  mutate(se=sd/sqrt(n-1))\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\n\ngroup_by() of dplyr package is used to group the observation by RACE,\nsummarise() is used to compute the count of observations, mean, standard deviation\nmutate() is used to derive standard error of Maths by RACE, and\nthe output is save as a tibble data table called my_sum.\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nFor the mathematical explanation, please refer to Slide 20 of Lesson 4.\n\n\nNext, the code chunk below will be used to display my_sum tibble data frame in an html table format.\n\nThe code chunkThe table\n\n\n\nknitr::kable(head(my_sum), format='html')\n\n\n\n\n\n\n\n\nRACE\nn\nmean\nsd\nse\n\n\n\n\nChinese\n193\n76.50777\n15.69040\n1.132357\n\n\nIndian\n12\n60.66667\n23.35237\n7.041005\n\n\nMalay\n108\n57.44444\n21.13478\n2.043177\n\n\nOthers\n9\n69.66667\n10.72381\n3.791438\n\n\n\n\n\n\n\n\n\n\n\n\nNow we are ready to plot the standard error bars of mean maths score by race as shown below.\n\nThe plotThe code chunk\n\n\n\n\n\n\n\n\n\n\nggplot(my_sum) +\n  geom_errorbar(aes(x=RACE,\n                    ymin=mean-se,\n                    ymax=mean+se),\n                width=0.2,\n                color=\"black\",\n                alpha=0.9,\n                size=0.5) +\n  geom_point(aes(x=RACE,\n                 y=mean),\n             stat=\"identity\",\n             color=\"red\",\n             size=1.5,\n             alpha=1) +\n  ggtitle(\"Standard error of mean maths score by race\")\n\n\n\n\n\n\n\nInstead of plotting the standard error bar of point estimates, we can also plot the confidence intervals of mean maths score by race.\n\nThe plotThe code chunk\n\n\n\n\n\n\n\n\n\n\nggplot(my_sum) +\n  geom_errorbar(aes(x=reorder(RACE, -mean),\n                    ymin=mean-1.96*se,\n                    ymax=mean+1.96*se),\n                width=0.2,\n                colour=\"black\",\n                alpha=0.9,\n                size=0.5) +\n  geom_point(aes(x=RACE,\n                 y=mean),\n             stat=\"identity\",\n             color=\"red\",\n             size=1.5,\n             alpha=1) +\n  labs(x=\"Maths score\",\n       title=\"95% confidence interval of mean maths score by race\")\n\n\n\n\n\n\n\nIn this section, you will learn how to plot interactive error bars for the 99% confidence interval of mean maths score by race as shown in the figure below.\n\nThe plotThe code chunk\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nshared_df = SharedData$new(my_sum)\n\nbscols(widths = c(4,8),\n       ggplotly((ggplot(shared_df) +\n                   geom_errorbar(aes(x=reorder(RACE, -mean),\n                                     ymin=mean-2.58*se,\n                                     ymax=mean+2.58*se),\n                                 width=0.2,\n                                 colour=\"black\",\n                                 alpha=0.9,\n                                 size=0.5) + \n                   geom_point(aes(x=RACE,\n                                  y=mean,\n                                  text=paste(\"Race:\",\n                                             `RACE`,\n                                             \"&lt;br&gt;N:\",\n                                             `n`,\n                                             \"&lt;br&gt;Avg. Scores:\",\n                                             round (mean, digits=2),\n                                             \"&lt;br&gt;95% CI:[\",\n                                             round((mean-2.58*se), digits=2), \",\",\n                                             round((mean+2.58*se), digits=2), \"]\")),\n                              stat = \"identity\",\n                              color=\"red\",\n                              size=1.5,\n                              alpha=1) +\n                   xlab(\"Race\") +\n                   ylab(\"Average Scores\") +\n                   theme_minimal() +\n                   theme(axis.text.x = element_text(angle = 45, vjust=0.5, hjust=1)) +\n                   ggtitle(\"99% confidence \\ninterval of average \\n/&lt;br&gt;maths scores by race\")),\n                tooltip=\"text\"),\n       DT::datatable(shared_df,\n                     rownames=F,\n                     class=\"compact\",\n                     style = \"bulma\",\n                     width=\"100%\",\n                     options=list(pageLength=10,\n                                  scrollX=T),\n                     colnames=c(\"No. of pupils\",\n                                \"Avg Scores\",\n                                \"Std Dev\",\n                                \"Std Error\")) %&gt;%\n         formatStyle(\"RACE\", color = \"red\", backgroundColor = \"white\") %&gt;% \n         formatRound(columns=c(\"mean\", \"sd\", \"se\"),\n                     digits=2))\n\n\n\n\n\n\n\n\n\nggdist is an R package that provides a flexible set of ggplot2 geoms and stats designed especially for visualising distributions and uncertainty.\nIt is designed for both frequentist and Bayesian uncertainty visualization, taking the view that uncertainty visualization can be unified through the perspective of distribution visualization:\n\nfor frequentist models, one visualises confidence distributions or bootstrap distributions (see vignette(“freq-uncertainty-vis”));\nfor Bayesian models, one visualises probability distributions (see the tidybayes package, which builds on top of ggdist).\n\n\n\n\n\nIn the code chunk below, stat_pointinterval() of ggdist is used to build a visual for displaying distribution of maths scores by race.\n\nexam %&gt;% \n  ggplot(aes(x=RACE,\n             y=MATHS)) +\n  stat_pointinterval() +\n  labs(title=\"Visualising confidence intervals of mean math score\",\n       subtitle=\"Mean Point + Multiple-interval plot\")\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThis function comes with many arguments, students are advised to read the syntax reference for more detail.\n\n\nFor example, in the code chunk below the following arguments are used:\n\n.width = 0.95\n.point = median\n.interval = qi\n\n\nexam %&gt;% \n  ggplot(aes(x=RACE,\n             y=MATHS)) +\n  stat_pointinterval(.width = 0.95,\n                     .point = median,\n                     .interval = qi) +\n  labs(title=\"Visualising confidence intervals of median math score\",\n       subtitle=\"Median Point + Multiple-interval plot\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nMakeover\n\n\n\nMakeover the plot on previous slide by showing 95% and 99% confidence intervals.\n\n\n\nexam %&gt;%\n  ggplot(aes(x = RACE, \n             y = MATHS)) +\n  stat_pointinterval(\n    show.legend = FALSE,\n    .point = median,\n    .interval = median_qi,\n    .width = c(0.95, 0.99)\n    ) +   \n  labs(\n    title = \"Visualising confidence intervals of median math score\",\n    subtitle = \"Median Point + Multiple-interval plot\")\n\n\n\n\nGentle advice: This function comes with many arguments, students are advised to read the syntax reference for more detail.\n\n\n\nIn the code chunk below, stat_gradientinterval() of ggdist is used to build a visual for displaying distribution of maths scores by race.\n\nexam %&gt;% \n  ggplot(aes(x=RACE,\n             y=MATHS)) +\n  stat_gradientinterval(fill = \"skyblue\",\n                        show.legend = T) +\n  labs(title=\"Visualising confidence intervals of mean math score\",\n       subtitle=\"Gradient + interval plot\")\n\n\n\n\nGentle advice: This function comes with many arguments, students are advised to read the syntax reference for more detail.\n\n\n\n\nStep 1: Installing ungeviz package\n\ndevtools::install_github(\"wilkelab/ungeviz\")\n\nNote: You only need to perform this step once.\nStep 2: Launch the application in R\n\nlibrary(ungeviz)\n\n\nggplot(data=exam,\n       (aes(x=factor(RACE),\n           y=MATHS))) +\n  geom_point(position = position_jitter(\n    height=0.3, width=0.05),\n    size=0.4, color=\"#0072B2\", alpha=1/2) +\n  geom_hpline(data=sampler(25, group=RACE), height=0.6, color=\"#D55E00\") +\n  theme_bw() +\n# `.draw` is a generated column indicating the sample draw\n  transition_states(.draw, 1, 3)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04c/Hands-on_Ex04c.html#learning-outcome",
    "href": "Hands-on_Ex/Hands-on_Ex04c/Hands-on_Ex04c.html#learning-outcome",
    "title": "Hands-on Exercise 4c",
    "section": "",
    "text": "Visualising uncertainty is relatively new in statistical graphics. In this chapter, you will gain hands-on experience on creating statistical graphics for visualising uncertainty. By the end of this chapter you will be able:\n\nto plot statistics error bars by using ggplot2,\nto plot interactive error bars by combining ggplot2, plotly and DT,\nto create advanced by using ggdist, and\nto create hypothetical outcome plots (HOPs) by using ungeviz package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04c/Hands-on_Ex04c.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex04c/Hands-on_Ex04c.html#getting-started",
    "title": "Hands-on Exercise 4c",
    "section": "",
    "text": "For the purpose of this exercise, the following R packages will be used, they are:\n\ntidyverse, a family of R packages for data science process,\nplotly for creating interactive plot,\ngganimate for creating animation plot,\nDT for displaying interactive html table,\ncrosstalk for for implementing cross-widget interactions (currently, linked brushing and filtering), and\nggdist for visualising distribution and uncertainty.\n\n\ndevtools::install_github(\"wilkelab/ungeviz\")\n\n\npacman::p_load(ungeviz, plotly, crosstalk,\n               DT, ggdist, ggridges,\n               colorspace, gganimate, tidyverse)\n\n\n\n\nFor the purpose of this exercise, Exam_data.csv will be used.\n\nexam &lt;- read_csv(\"data/Exam_Data.csv\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04c/Hands-on_Ex04c.html#visualizing-the-uncertainty-of-point-estimates-ggplot2-methods",
    "href": "Hands-on_Ex/Hands-on_Ex04c/Hands-on_Ex04c.html#visualizing-the-uncertainty-of-point-estimates-ggplot2-methods",
    "title": "Hands-on Exercise 4c",
    "section": "",
    "text": "A point estimate is a single number, such as a mean. Uncertainty, on the other hand, is expressed as standard error, confidence interval, or credible interval.\n\n\n\n\n\n\nImportant\n\n\n\n\nDon’t confuse the uncertainty of a point estimate with the variation in the sample\n\n\n\nIn this section, you will learn how to plot error bars of maths scores by race by using data provided in exam tibble data frame.\nFirstly, code chunk below will be used to derive the necessary summary statistics.\n\nmy_sum &lt;- exam %&gt;% \n  group_by(RACE) %&gt;% \n  summarise(\n    n=n(),\n    mean=mean(MATHS),\n    sd=sd(MATHS)\n  ) %&gt;% \n  mutate(se=sd/sqrt(n-1))\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\n\ngroup_by() of dplyr package is used to group the observation by RACE,\nsummarise() is used to compute the count of observations, mean, standard deviation\nmutate() is used to derive standard error of Maths by RACE, and\nthe output is save as a tibble data table called my_sum.\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nFor the mathematical explanation, please refer to Slide 20 of Lesson 4.\n\n\nNext, the code chunk below will be used to display my_sum tibble data frame in an html table format.\n\nThe code chunkThe table\n\n\n\nknitr::kable(head(my_sum), format='html')\n\n\n\n\n\n\n\n\nRACE\nn\nmean\nsd\nse\n\n\n\n\nChinese\n193\n76.50777\n15.69040\n1.132357\n\n\nIndian\n12\n60.66667\n23.35237\n7.041005\n\n\nMalay\n108\n57.44444\n21.13478\n2.043177\n\n\nOthers\n9\n69.66667\n10.72381\n3.791438\n\n\n\n\n\n\n\n\n\n\n\n\nNow we are ready to plot the standard error bars of mean maths score by race as shown below.\n\nThe plotThe code chunk\n\n\n\n\n\n\n\n\n\n\nggplot(my_sum) +\n  geom_errorbar(aes(x=RACE,\n                    ymin=mean-se,\n                    ymax=mean+se),\n                width=0.2,\n                color=\"black\",\n                alpha=0.9,\n                size=0.5) +\n  geom_point(aes(x=RACE,\n                 y=mean),\n             stat=\"identity\",\n             color=\"red\",\n             size=1.5,\n             alpha=1) +\n  ggtitle(\"Standard error of mean maths score by race\")\n\n\n\n\n\n\n\nInstead of plotting the standard error bar of point estimates, we can also plot the confidence intervals of mean maths score by race.\n\nThe plotThe code chunk\n\n\n\n\n\n\n\n\n\n\nggplot(my_sum) +\n  geom_errorbar(aes(x=reorder(RACE, -mean),\n                    ymin=mean-1.96*se,\n                    ymax=mean+1.96*se),\n                width=0.2,\n                colour=\"black\",\n                alpha=0.9,\n                size=0.5) +\n  geom_point(aes(x=RACE,\n                 y=mean),\n             stat=\"identity\",\n             color=\"red\",\n             size=1.5,\n             alpha=1) +\n  labs(x=\"Maths score\",\n       title=\"95% confidence interval of mean maths score by race\")\n\n\n\n\n\n\n\nIn this section, you will learn how to plot interactive error bars for the 99% confidence interval of mean maths score by race as shown in the figure below.\n\nThe plotThe code chunk\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nshared_df = SharedData$new(my_sum)\n\nbscols(widths = c(4,8),\n       ggplotly((ggplot(shared_df) +\n                   geom_errorbar(aes(x=reorder(RACE, -mean),\n                                     ymin=mean-2.58*se,\n                                     ymax=mean+2.58*se),\n                                 width=0.2,\n                                 colour=\"black\",\n                                 alpha=0.9,\n                                 size=0.5) + \n                   geom_point(aes(x=RACE,\n                                  y=mean,\n                                  text=paste(\"Race:\",\n                                             `RACE`,\n                                             \"&lt;br&gt;N:\",\n                                             `n`,\n                                             \"&lt;br&gt;Avg. Scores:\",\n                                             round (mean, digits=2),\n                                             \"&lt;br&gt;95% CI:[\",\n                                             round((mean-2.58*se), digits=2), \",\",\n                                             round((mean+2.58*se), digits=2), \"]\")),\n                              stat = \"identity\",\n                              color=\"red\",\n                              size=1.5,\n                              alpha=1) +\n                   xlab(\"Race\") +\n                   ylab(\"Average Scores\") +\n                   theme_minimal() +\n                   theme(axis.text.x = element_text(angle = 45, vjust=0.5, hjust=1)) +\n                   ggtitle(\"99% confidence \\ninterval of average \\n/&lt;br&gt;maths scores by race\")),\n                tooltip=\"text\"),\n       DT::datatable(shared_df,\n                     rownames=F,\n                     class=\"compact\",\n                     style = \"bulma\",\n                     width=\"100%\",\n                     options=list(pageLength=10,\n                                  scrollX=T),\n                     colnames=c(\"No. of pupils\",\n                                \"Avg Scores\",\n                                \"Std Dev\",\n                                \"Std Error\")) %&gt;%\n         formatStyle(\"RACE\", color = \"red\", backgroundColor = \"white\") %&gt;% \n         formatRound(columns=c(\"mean\", \"sd\", \"se\"),\n                     digits=2))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04c/Hands-on_Ex04c.html#visualising-uncertainty-ggdist-package",
    "href": "Hands-on_Ex/Hands-on_Ex04c/Hands-on_Ex04c.html#visualising-uncertainty-ggdist-package",
    "title": "Hands-on Exercise 4c",
    "section": "",
    "text": "ggdist is an R package that provides a flexible set of ggplot2 geoms and stats designed especially for visualising distributions and uncertainty.\nIt is designed for both frequentist and Bayesian uncertainty visualization, taking the view that uncertainty visualization can be unified through the perspective of distribution visualization:\n\nfor frequentist models, one visualises confidence distributions or bootstrap distributions (see vignette(“freq-uncertainty-vis”));\nfor Bayesian models, one visualises probability distributions (see the tidybayes package, which builds on top of ggdist).\n\n\n\n\n\nIn the code chunk below, stat_pointinterval() of ggdist is used to build a visual for displaying distribution of maths scores by race.\n\nexam %&gt;% \n  ggplot(aes(x=RACE,\n             y=MATHS)) +\n  stat_pointinterval() +\n  labs(title=\"Visualising confidence intervals of mean math score\",\n       subtitle=\"Mean Point + Multiple-interval plot\")\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThis function comes with many arguments, students are advised to read the syntax reference for more detail.\n\n\nFor example, in the code chunk below the following arguments are used:\n\n.width = 0.95\n.point = median\n.interval = qi\n\n\nexam %&gt;% \n  ggplot(aes(x=RACE,\n             y=MATHS)) +\n  stat_pointinterval(.width = 0.95,\n                     .point = median,\n                     .interval = qi) +\n  labs(title=\"Visualising confidence intervals of median math score\",\n       subtitle=\"Median Point + Multiple-interval plot\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nMakeover\n\n\n\nMakeover the plot on previous slide by showing 95% and 99% confidence intervals.\n\n\n\nexam %&gt;%\n  ggplot(aes(x = RACE, \n             y = MATHS)) +\n  stat_pointinterval(\n    show.legend = FALSE,\n    .point = median,\n    .interval = median_qi,\n    .width = c(0.95, 0.99)\n    ) +   \n  labs(\n    title = \"Visualising confidence intervals of median math score\",\n    subtitle = \"Median Point + Multiple-interval plot\")\n\n\n\n\nGentle advice: This function comes with many arguments, students are advised to read the syntax reference for more detail.\n\n\n\nIn the code chunk below, stat_gradientinterval() of ggdist is used to build a visual for displaying distribution of maths scores by race.\n\nexam %&gt;% \n  ggplot(aes(x=RACE,\n             y=MATHS)) +\n  stat_gradientinterval(fill = \"skyblue\",\n                        show.legend = T) +\n  labs(title=\"Visualising confidence intervals of mean math score\",\n       subtitle=\"Gradient + interval plot\")\n\n\n\n\nGentle advice: This function comes with many arguments, students are advised to read the syntax reference for more detail."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04c/Hands-on_Ex04c.html#visualising-uncertainty-with-hypothetical-outcome-plots-hops",
    "href": "Hands-on_Ex/Hands-on_Ex04c/Hands-on_Ex04c.html#visualising-uncertainty-with-hypothetical-outcome-plots-hops",
    "title": "Hands-on Exercise 4c",
    "section": "",
    "text": "Step 1: Installing ungeviz package\n\ndevtools::install_github(\"wilkelab/ungeviz\")\n\nNote: You only need to perform this step once.\nStep 2: Launch the application in R\n\nlibrary(ungeviz)\n\n\nggplot(data=exam,\n       (aes(x=factor(RACE),\n           y=MATHS))) +\n  geom_point(position = position_jitter(\n    height=0.3, width=0.05),\n    size=0.4, color=\"#0072B2\", alpha=1/2) +\n  geom_hpline(data=sampler(25, group=RACE), height=0.6, color=\"#D55E00\") +\n  theme_bw() +\n# `.draw` is a generated column indicating the sample draw\n  transition_states(.draw, 1, 3)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05a/Hands-on_Ex05a.html",
    "href": "Hands-on_Ex/Hands-on_Ex05a/Hands-on_Ex05a.html",
    "title": "Hands-on Exercise 5a",
    "section": "",
    "text": "Ternary plots are a way of displaying the distribution and variability of three-part compositional data. (For example, the proportion of aged, economy active and young population or sand, silt, and clay in soil.) It’s display is a triangle with sides scaled from 0 to 1. Each side represents one of the three components. A point is plotted so that a line drawn perpendicular from the point to each leg of the triangle intersect at the component values of the point.\nIn this hands-on, you will learn how to build ternary plot programmatically using R for visualising and analysing population structure of Singapore.\nThe hands-on exercise consists of four steps:\n\nInstall and launch tidyverse and ggtern packages.\nDerive three new measures using mutate() function of dplyr package.\nBuild a static ternary plot using ggtern() function of ggtern package.\nBuild an interactive ternary plot using plot-ly() function of Plotly R package.\n\n\n\n\nFor this exercise, two main R packages will be used in this hands-on exercise, they are:\n\nggtern, a ggplot extension specially designed to plot ternary diagrams. The package will be used to plot static ternary plots.\nPlotly R, an R package for creating interactive web-based graphs via plotly’s JavaScript graphing library, plotly.js . The plotly R libary contains the ggplotly function, which will convert ggplot2 figures into a Plotly object.\n\nWe will also need to ensure that selected tidyverse family package namely: readr, dplyr and tidyr are also installed and loaded.\nInIn this exercise, version 3.2.1 of ggplot2 will be installed instead of the latest version of ggplot2. This is because the current version of ggtern package is not compatible to the latest version of ggplot2.\nThe code chunks below will accomplish the task.\n\npacman::p_load('plotly', 'tidyverse', 'readr', 'dplyr', 'tidyr')\n\nInstalling ggtern:\n\nrequire(devtools)\ninstall_version(\"ggtern\", version = \"3.4.1\", repos = \"http://cran.us.r-project.org\")\n\nNext, load ggtern package into R environment by using the code chunk below.\n\nlibrary(ggtern)\n\n\n\n\n\n\nFor the purpose of this hands-on exercise, the Singapore Residents by Planning AreaSubzone, Age Group, Sex and Type of Dwelling, June 2000-2018 data will be used. The data set has been downloaded and included in the data sub-folder of the hands-on exercise folder. It is called respopagsex2000to2018_tidy.csv and is in csv file format.\n\n\n\nTo import respopagsex2000to2018_tidy.csv into R, read_csv() function of readr package will be used.\n\n#Reading the data into R environment\npop_data &lt;- read_csv(\"data/respopagsex2000to2018_tidy.csv\") \n\n\n\n\nNext, use the mutate() function of dplyr package to derive three new measures, namely: young, active, and old.\n\n#Deriving the young, economy active and old measures\nagpop_mutated &lt;- pop_data %&gt;%\n  mutate(`Year` = as.character(Year))%&gt;%\n  spread(AG, Population) %&gt;%\n  mutate(YOUNG = rowSums(.[4:8]))%&gt;%\n  mutate(ACTIVE = rowSums(.[9:16]))  %&gt;%\n  mutate(OLD = rowSums(.[17:21])) %&gt;%\n  mutate(TOTAL = rowSums(.[22:24])) %&gt;%\n  filter(Year == 2018)%&gt;%\n  filter(TOTAL &gt; 0)\n\n\n\n\n\n\n\nUse ggtern() function of ggtern package to create a simple ternary plot.\n\n#Building the static ternary plot\nggtern(data=agpop_mutated,aes(x=YOUNG,y=ACTIVE, z=OLD)) +\n  geom_point()\n\n\n\n\n\n#Building the static ternary plot\nggtern(data=agpop_mutated, aes(x=YOUNG,y=ACTIVE, z=OLD)) +\n  geom_point() +\n  labs(title=\"Population structure, 2015\") +\n  theme_rgbw()\n\n\n\n\n\n\n\nThe code below create an interactive ternary plot using plot_ly() function of Plotly R.\n\n# reusable function for creating annotation object\nlabel &lt;- function(txt) {\n  list(\n    text = txt, \n    x = 0.1, y = 1,\n    ax = 0, ay = 0,\n    xref = \"paper\", yref = \"paper\", \n    align = \"center\",\n    font = list(family = \"serif\", size = 15, color = \"white\"),\n    bgcolor = \"#b3b3b3\", bordercolor = \"black\", borderwidth = 2\n  )\n}\n\n# reusable function for axis formatting\naxis &lt;- function(txt) {\n  list(\n    title = txt, tickformat = \".0%\", tickfont = list(size = 10)\n  )\n}\n\nternaryAxes &lt;- list(\n  aaxis = axis(\"Young\"), \n  baxis = axis(\"Active\"), \n  caxis = axis(\"Old\")\n)\n\n# Initiating a plotly visualization \nplot_ly(\n  agpop_mutated, \n  a = ~YOUNG, \n  b = ~ACTIVE, \n  c = ~OLD, \n  color = I(\"salmon\"),\n  alpha = 0.6,\n  type = \"scatterternary\") %&gt;% \n  layout(\n    annotations = label(\"Ternary Markers\"), \n    ternary = ternaryAxes\n  )"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05a/Hands-on_Ex05a.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex05a/Hands-on_Ex05a.html#overview",
    "title": "Hands-on Exercise 5a",
    "section": "",
    "text": "Ternary plots are a way of displaying the distribution and variability of three-part compositional data. (For example, the proportion of aged, economy active and young population or sand, silt, and clay in soil.) It’s display is a triangle with sides scaled from 0 to 1. Each side represents one of the three components. A point is plotted so that a line drawn perpendicular from the point to each leg of the triangle intersect at the component values of the point.\nIn this hands-on, you will learn how to build ternary plot programmatically using R for visualising and analysing population structure of Singapore.\nThe hands-on exercise consists of four steps:\n\nInstall and launch tidyverse and ggtern packages.\nDerive three new measures using mutate() function of dplyr package.\nBuild a static ternary plot using ggtern() function of ggtern package.\nBuild an interactive ternary plot using plot-ly() function of Plotly R package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05a/Hands-on_Ex05a.html#installing-and-launching-r-packages",
    "href": "Hands-on_Ex/Hands-on_Ex05a/Hands-on_Ex05a.html#installing-and-launching-r-packages",
    "title": "Hands-on Exercise 5a",
    "section": "",
    "text": "For this exercise, two main R packages will be used in this hands-on exercise, they are:\n\nggtern, a ggplot extension specially designed to plot ternary diagrams. The package will be used to plot static ternary plots.\nPlotly R, an R package for creating interactive web-based graphs via plotly’s JavaScript graphing library, plotly.js . The plotly R libary contains the ggplotly function, which will convert ggplot2 figures into a Plotly object.\n\nWe will also need to ensure that selected tidyverse family package namely: readr, dplyr and tidyr are also installed and loaded.\nInIn this exercise, version 3.2.1 of ggplot2 will be installed instead of the latest version of ggplot2. This is because the current version of ggtern package is not compatible to the latest version of ggplot2.\nThe code chunks below will accomplish the task.\n\npacman::p_load('plotly', 'tidyverse', 'readr', 'dplyr', 'tidyr')\n\nInstalling ggtern:\n\nrequire(devtools)\ninstall_version(\"ggtern\", version = \"3.4.1\", repos = \"http://cran.us.r-project.org\")\n\nNext, load ggtern package into R environment by using the code chunk below.\n\nlibrary(ggtern)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05a/Hands-on_Ex05a.html#data-preparation",
    "href": "Hands-on_Ex/Hands-on_Ex05a/Hands-on_Ex05a.html#data-preparation",
    "title": "Hands-on Exercise 5a",
    "section": "",
    "text": "For the purpose of this hands-on exercise, the Singapore Residents by Planning AreaSubzone, Age Group, Sex and Type of Dwelling, June 2000-2018 data will be used. The data set has been downloaded and included in the data sub-folder of the hands-on exercise folder. It is called respopagsex2000to2018_tidy.csv and is in csv file format.\n\n\n\nTo import respopagsex2000to2018_tidy.csv into R, read_csv() function of readr package will be used.\n\n#Reading the data into R environment\npop_data &lt;- read_csv(\"data/respopagsex2000to2018_tidy.csv\") \n\n\n\n\nNext, use the mutate() function of dplyr package to derive three new measures, namely: young, active, and old.\n\n#Deriving the young, economy active and old measures\nagpop_mutated &lt;- pop_data %&gt;%\n  mutate(`Year` = as.character(Year))%&gt;%\n  spread(AG, Population) %&gt;%\n  mutate(YOUNG = rowSums(.[4:8]))%&gt;%\n  mutate(ACTIVE = rowSums(.[9:16]))  %&gt;%\n  mutate(OLD = rowSums(.[17:21])) %&gt;%\n  mutate(TOTAL = rowSums(.[22:24])) %&gt;%\n  filter(Year == 2018)%&gt;%\n  filter(TOTAL &gt; 0)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05a/Hands-on_Ex05a.html#plotting-ternary-diagram-with-r",
    "href": "Hands-on_Ex/Hands-on_Ex05a/Hands-on_Ex05a.html#plotting-ternary-diagram-with-r",
    "title": "Hands-on Exercise 5a",
    "section": "",
    "text": "Use ggtern() function of ggtern package to create a simple ternary plot.\n\n#Building the static ternary plot\nggtern(data=agpop_mutated,aes(x=YOUNG,y=ACTIVE, z=OLD)) +\n  geom_point()\n\n\n\n\n\n#Building the static ternary plot\nggtern(data=agpop_mutated, aes(x=YOUNG,y=ACTIVE, z=OLD)) +\n  geom_point() +\n  labs(title=\"Population structure, 2015\") +\n  theme_rgbw()\n\n\n\n\n\n\n\nThe code below create an interactive ternary plot using plot_ly() function of Plotly R.\n\n# reusable function for creating annotation object\nlabel &lt;- function(txt) {\n  list(\n    text = txt, \n    x = 0.1, y = 1,\n    ax = 0, ay = 0,\n    xref = \"paper\", yref = \"paper\", \n    align = \"center\",\n    font = list(family = \"serif\", size = 15, color = \"white\"),\n    bgcolor = \"#b3b3b3\", bordercolor = \"black\", borderwidth = 2\n  )\n}\n\n# reusable function for axis formatting\naxis &lt;- function(txt) {\n  list(\n    title = txt, tickformat = \".0%\", tickfont = list(size = 10)\n  )\n}\n\nternaryAxes &lt;- list(\n  aaxis = axis(\"Young\"), \n  baxis = axis(\"Active\"), \n  caxis = axis(\"Old\")\n)\n\n# Initiating a plotly visualization \nplot_ly(\n  agpop_mutated, \n  a = ~YOUNG, \n  b = ~ACTIVE, \n  c = ~OLD, \n  color = I(\"salmon\"),\n  alpha = 0.6,\n  type = \"scatterternary\") %&gt;% \n  layout(\n    annotations = label(\"Ternary Markers\"), \n    ternary = ternaryAxes\n  )"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05c/Hands-on_Ex05c.html",
    "href": "Hands-on_Ex/Hands-on_Ex05c/Hands-on_Ex05c.html",
    "title": "Hands-on Exercise 5c",
    "section": "",
    "text": "Heatmaps visualise data through variations in colouring. When applied to a tabular format, heatmaps are useful for cross-examining multivariate data, through placing variables in the columns and observation (or records) in rows and colouring the cells within the table. Heatmaps are good for showing variance across multiple variables, revealing any patterns, displaying whether any variables are similar to each other, and for detecting if any correlations exist in-between them.\nIn this hands-on exercise, you will gain hands-on experience on using R to plot static and interactive heatmap for visualising and analysing multivariate data.\n\n\n\nBefore you get started, you are required:\n\nto start a new R project, and\nto create a new R Markdown document.\n\nNext, you will use the code chunk below to install and launch seriation, heatmaply, dendextend and tidyverse in RStudio.\n\npacman::p_load(seriation, dendextend, heatmaply, tidyverse)\n\n\n\n\nIn this hands-on exercise, the data of World Happines 2018 report will be used. The data set is downloaded from here. The original data set is in Microsoft Excel format. It has been extracted and saved in csv file called WHData-2018.csv.\n\n\nIn the code chunk below, read_csv() of readr is used to import WHData-2018.csv into R and parsed it into tibble R data frame format.\n\nwh &lt;- read_csv(\"data/WHData-2018.csv\")\n\nThe output tibbled data frame is called wh.\n\n\n\nNext, we need to change the rows by country name instead of row number by using the code chunk below\n\nrow.names(wh) &lt;- wh$Country\n\nNotice that the row number has been replaced into the country name.\n\n\n\nThe data was loaded into a data frame, but it has to be a data matrix to make your heatmap.\nThe code chunk below will be used to transform wh data frame into a data matrix.\n\nwh1 &lt;- dplyr::select(wh, c(3, 7:12))\nwh_matrix &lt;- data.matrix(wh)\n\nNotice that wh_matrix is in R matrix format.\n\n\n\n\nThere are many R packages and functions can be used to drawing static heatmaps, they are:\n\nheatmap()of R stats package. It draws a simple heatmap.\nheatmap.2() of gplots R package. It draws an enhanced heatmap compared to the R base function.\npheatmap() of pheatmap R package. pheatmap package also known as Pretty Heatmap. The package provides functions to draws pretty heatmaps and provides more control to change the appearance of heatmaps.\nComplexHeatmap package of R/Bioconductor package. The package draws, annotates and arranges complex heatmaps (very useful for genomic data analysis). The full reference guide of the package is available here.\nsuperheat package: A Graphical Tool for Exploring Complex Datasets Using Heatmaps. A system for generating extendable and customizable heatmaps for exploring complex datasets, including big data and data with multiple data types. The full reference guide of the package is available here.\n\nIn this section, you will learn how to plot static heatmaps by using heatmap() of R Stats package.\n\n\nIn this sub-section, we will plot a heatmap by using heatmap() of Base Stats. The code chunk is given below.\n\nwh_heatmap &lt;- heatmap(wh_matrix, \n                      Rowv = NA, \n                      Colv = NA)\n\n\n\n\nNote:\n\nBy default, heatmap() plots a cluster heatmap. The arguments Rowv=NA and Colv=NA are used to switch off the option of plotting the row and column dendrograms.\n\nTo plot a cluster heatmap, we just have to use the default as shown in the code chunk below.\n\nwh_heatmap &lt;- heatmap(wh_matrix)\n\n\n\n\nNote:\n\nThe order of both rows and columns is different compare to the native wh_matrix. This is because heatmap do a reordering using clusterisation: it calculates the distance between each pair of rows and columns and try to order them by similarity. Moreover, the corresponding dendrogram are provided beside the heatmap.\n\nHere, red cells denotes small values, and red small ones. This heatmap is not really informative. Indeed, the Happiness Score variable have relatively higher values, what makes that the other variables with small values all look the same. Thus, we need to normalize this matrix. This is done using the scale argument. It can be applied to rows or to columns following your needs.\nThe code chunk below normalises the matrix column-wise.\n\nwh_heatmap &lt;- heatmap(wh_matrix,\n                      scale=\"column\",\n                      cexRow = 0.6, \n                      cexCol = 0.8,\n                      margins = c(10, 4))\n\n\n\n\nNotice that the values are scaled now. Also note that margins argument is used to ensure that the entire x-axis labels are displayed completely and, cexRow and cexCol arguments are used to define the font size used for y-axis and x-axis labels respectively.\n\n\n\n\nheatmaply is an R package for building interactive cluster heatmap that can be shared online as a stand-alone HTML file. It is designed and maintained by Tal Galili.\nBefore we get started, you should review the Introduction to Heatmaply to have an overall understanding of the features and functions of Heatmaply package. You are also required to have the user manualof the package handy with you for reference purposes.\nIn this section, you will gain hands-on experience on using heatmaply to design an interactive cluster heatmap. We will still use the wh_matrix as the input data.\n\n\n\nheatmaply(mtcars)\n\n\n\n\n\nThe code chunk below shows the basic syntax needed to create an interactive heatmap by using heatmaply package.\n\nheatmaply(wh_matrix[, -c(1, 2, 4, 5)])\n\n\n\n\n\nNote that:\n\nDifferent from heatmap(), for heatmaply() the default horizontal dendrogram is placed on the right hand side of the heatmap.\nThe text label of each raw, on the other hand, is placed on the left hand side of the heat map.\nWhen the x-axis marker labels are too long, they will be rotated by 135 degree from the north.\n\n\n\n\nWhen analysing multivariate data set, it is very common that the variables in the data sets includes values that reflect different types of measurement. In general, these variables’ values have their own range. In order to ensure that all the variables have comparable values, data transformation are commonly used before clustering.\nThree main data transformation methods are supported by heatmaply(), namely: scale, normalise and percentilse.\n\n\n\nWhen all variables are came from or assumed to come from some normal distribution, then scaling (i.e.: subtract the mean and divide by the standard deviation) would bring them all close to the standard normal distribution.\nIn such a case, each value would reflect the distance from the mean in units of standard deviation.\nThe scale argument in heatmaply() supports column and row scaling.\n\nThe code chunk below is used to scale variable values columewise.\n\nheatmaply(wh_matrix[, -c(1, 2, 4, 5)],\n          scale = \"column\")\n\n\n\n\n\n\n\n\n\nWhen variables in the data comes from possibly different (and non-normal) distributions, the normalize function can be used to bring data to the 0 to 1 scale by subtracting the minimum and dividing by the maximum of all observations.\nThis preserves the shape of each variable’s distribution while making them easily comparable on the same “scale”.\n\nDifferent from Scaling, the normalise method is performed on the input data set i.e. wh_matrix as shown in the code chunk below.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]))\n\n\n\n\n\n\n\n\n\nThis is similar to ranking the variables, but instead of keeping the rank values, divide them by the maximal rank.\nThis is done by using the ecdf of the variables on their own values, bringing each value to its empirical percentile.\nThe benefit of the percentize function is that each value has a relatively clear interpretation, it is the percent of observations that got that value or below it.\n\nSimilar to Normalize method, the Percentize method is also performed on the input data set i.e. wh_matrix as shown in the code chunk below.\n\nheatmaply(percentize(wh_matrix[, -c(1, 2, 4, 5)]))\n\n\n\n\n\n\n\n\n\nheatmaply supports a variety of hierarchical clustering algorithm. The main arguments provided are:\n\ndistfun: function used to compute the distance (dissimilarity) between both rows and columns. Defaults to dist. The options “pearson”, “spearman” and “kendall” can be used to use correlation-based clustering, which uses as.dist(1 - cor(t(x))) as the distance metric (using the specified correlation method).\nhclustfun: function used to compute the hierarchical clustering when Rowv or Colv are not dendrograms. Defaults to hclust.\ndist_method default is NULL, which results in “euclidean” to be used. It can accept alternative character strings indicating the method to be passed to distfun. By default distfun is “dist”” hence this can be one of “euclidean”, “maximum”, “manhattan”, “canberra”, “binary” or “minkowski”.\nhclust_method default is NULL, which results in “complete” method to be used. It can accept alternative character strings indicating the method to be passed to hclustfun. By default hclustfun is hclust hence this can be one of “ward.D”, “ward.D2”, “single”, “complete”, “average” (= UPGMA), “mcquitty” (= WPGMA), “median” (= WPGMC) or “centroid” (= UPGMC).\n\nIn general, a clustering model can be calibrated either manually or statistically.\n\n\n\nIn the code chunk below, the heatmap is plotted by using hierachical clustering algorithm with “Euclidean distance” and “ward.D” method.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          dist_method = \"euclidean\",\n          hclust_method = \"ward.D\")\n\n\n\n\n\n\n\n\nIn order to determine the best clustering method and number of cluster the dend_expend() and find_k() functions of dendextend package will be used.\nFirst, the dend_expend() will be used to determine the recommended clustering method to be used.\n\nwh_d &lt;- dist(normalize(wh_matrix[, -c(1, 2, 4, 5)]), method = \"euclidean\")\ndend_expend(wh_d)[[3]]\n\n  dist_methods hclust_methods     optim\n1      unknown         ward.D 0.6137851\n2      unknown        ward.D2 0.6289186\n3      unknown         single 0.4774362\n4      unknown       complete 0.6434009\n5      unknown        average 0.6701688\n6      unknown       mcquitty 0.5020102\n7      unknown         median 0.5901833\n8      unknown       centroid 0.6338734\n\n\nThe output table shows that “average” method should be used because it gave the high optimum value.\nNext, find_k() is used to determine the optimal number of cluster.\n\nwh_clust &lt;- hclust(wh_d, method = \"average\")\nnum_k &lt;- find_k(wh_clust)\nplot(num_k)\n\n\n\n\nFigure above shows that k=3 would be good.\nWith reference to the statistical analysis results, we can prepare the code chunk as shown below.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          dist_method = \"euclidean\",\n          hclust_method = \"average\",\n          k_row = 3)\n\n\n\n\n\n\n\n\nOne of the problems with hierarchical clustering is that it doesn’t actually place the rows in a definite order, it merely constrains the space of possible orderings. Take three items A, B and C. If you ignore reflections, there are three possible orderings: ABC, ACB, BAC. If clustering them gives you ((A+B)+C) as a tree, you know that C can’t end up between A and B, but it doesn’t tell you which way to flip the A+B cluster. It doesn’t tell you if the ABC ordering will lead to a clearer-looking heatmap than the BAC ordering.\nheatmaply uses the seriation package to find an optimal ordering of rows and columns. Optimal means to optimize the Hamiltonian path length that is restricted by the dendrogram structure. This, in other words, means to rotate the branches so that the sum of distances between each adjacent leaf (label) will be minimized. This is related to a restricted version of the travelling salesman problem.\nHere we meet our first seriation algorithm: Optimal Leaf Ordering (OLO). This algorithm starts with the output of an agglomerative clustering algorithm and produces a unique ordering, one that flips the various branches of the dendrogram around so as to minimize the sum of dissimilarities between adjacent leaves. Here is the result of applying Optimal Leaf Ordering to the same clustering result as the heatmap above.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"OLO\")\n\n\n\n\n\nThe default options is “OLO” (Optimal leaf ordering) which optimizes the above criterion (in O(n^4)). Another option is “GW” (Gruvaeus and Wainer) which aims for the same goal but uses a potentially faster heuristic.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"GW\")\n\n\n\n\n\nThe option “mean” gives the output we would get by default from heatmap functions in other packages such as gplots::heatmap.2.\n\nheatmaply(normalize(wh_matrix[, -c(1,2,4,5)]),\n          seriate = \"mean\")\n\n\n\n\n\nThe option “none” gives us the dendrograms without any rotation that is based on the data matrix.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"none\")\n\n\n\n\n\n\n\n\nThe default colour palette uses by heatmaply is viridis. heatmaply users, however, can use other colour palettes in order to improve the aestheticness and visual friendliness of the heatmap.\nIn the code chunk below, the Blues colour palette of rColorBrewer is used.\n\nheatmaply(normalize(wh_matrix[, -c(1,2,4,5)]),\n          seriate = \"mean\",\n          colors = Greens)\n\n\n\n\n\n\n\n\nBeside providing a wide collection of arguments for meeting the statistical analysis needs, heatmaply also provides many plotting features to ensure cartographic quality heatmap can be produced.\nIn the code chunk below the following arguments are used:\n\nk_row is used to produce 5 groups.\nmargins is used to change the top margin to 60 and row margin to 200.\nfontsizw_row and fontsize_col are used to change the font size for row and column labels to 4.\nmain is used to write the main title of the plot.\nxlab and ylab are used to write the x-axis and y-axis labels respectively.\n\n\nheatmaply(normalize(wh_matrix[, -c(1,2,4,5)]),\n          Colv=NA,\n          seriate=\"none\",\n          colors=Blues,\n          k_row=5,\n          margins=c(NA, 200, 60, NA),\n          fontsize_row=4,\n          fonrsize_col=5,\n          height = 1000,\n          main=\"World Happiness Score and Variables by Country, 2018 \\nDataTransformation using Normalise Method\",\n          xlab = \"World Happiness Indicators\",\n          ylab = \"World Countries\"\n          )\n\n\n\n\n\nAdditional practice -\n\nheatmaply(wh_matrix[,-c(1,2,4,5)],\n          seriate=\"mean\",\n          row_dend_left=T,\n          plot_method = \"plotly\",\n          k_row=3,\n          margins=c(NA, 200, 60, NA),\n          fontsize_row=4,\n          fonrsize_col=5,\n          height = 1000)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05c/Hands-on_Ex05c.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex05c/Hands-on_Ex05c.html#overview",
    "title": "Hands-on Exercise 5c",
    "section": "",
    "text": "Heatmaps visualise data through variations in colouring. When applied to a tabular format, heatmaps are useful for cross-examining multivariate data, through placing variables in the columns and observation (or records) in rows and colouring the cells within the table. Heatmaps are good for showing variance across multiple variables, revealing any patterns, displaying whether any variables are similar to each other, and for detecting if any correlations exist in-between them.\nIn this hands-on exercise, you will gain hands-on experience on using R to plot static and interactive heatmap for visualising and analysing multivariate data."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05c/Hands-on_Ex05c.html#installing-and-launching-r-packages",
    "href": "Hands-on_Ex/Hands-on_Ex05c/Hands-on_Ex05c.html#installing-and-launching-r-packages",
    "title": "Hands-on Exercise 5c",
    "section": "",
    "text": "Before you get started, you are required:\n\nto start a new R project, and\nto create a new R Markdown document.\n\nNext, you will use the code chunk below to install and launch seriation, heatmaply, dendextend and tidyverse in RStudio.\n\npacman::p_load(seriation, dendextend, heatmaply, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05c/Hands-on_Ex05c.html#importing-and-preparing-the-data-set",
    "href": "Hands-on_Ex/Hands-on_Ex05c/Hands-on_Ex05c.html#importing-and-preparing-the-data-set",
    "title": "Hands-on Exercise 5c",
    "section": "",
    "text": "In this hands-on exercise, the data of World Happines 2018 report will be used. The data set is downloaded from here. The original data set is in Microsoft Excel format. It has been extracted and saved in csv file called WHData-2018.csv.\n\n\nIn the code chunk below, read_csv() of readr is used to import WHData-2018.csv into R and parsed it into tibble R data frame format.\n\nwh &lt;- read_csv(\"data/WHData-2018.csv\")\n\nThe output tibbled data frame is called wh.\n\n\n\nNext, we need to change the rows by country name instead of row number by using the code chunk below\n\nrow.names(wh) &lt;- wh$Country\n\nNotice that the row number has been replaced into the country name.\n\n\n\nThe data was loaded into a data frame, but it has to be a data matrix to make your heatmap.\nThe code chunk below will be used to transform wh data frame into a data matrix.\n\nwh1 &lt;- dplyr::select(wh, c(3, 7:12))\nwh_matrix &lt;- data.matrix(wh)\n\nNotice that wh_matrix is in R matrix format."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05c/Hands-on_Ex05c.html#static-heatmap",
    "href": "Hands-on_Ex/Hands-on_Ex05c/Hands-on_Ex05c.html#static-heatmap",
    "title": "Hands-on Exercise 5c",
    "section": "",
    "text": "There are many R packages and functions can be used to drawing static heatmaps, they are:\n\nheatmap()of R stats package. It draws a simple heatmap.\nheatmap.2() of gplots R package. It draws an enhanced heatmap compared to the R base function.\npheatmap() of pheatmap R package. pheatmap package also known as Pretty Heatmap. The package provides functions to draws pretty heatmaps and provides more control to change the appearance of heatmaps.\nComplexHeatmap package of R/Bioconductor package. The package draws, annotates and arranges complex heatmaps (very useful for genomic data analysis). The full reference guide of the package is available here.\nsuperheat package: A Graphical Tool for Exploring Complex Datasets Using Heatmaps. A system for generating extendable and customizable heatmaps for exploring complex datasets, including big data and data with multiple data types. The full reference guide of the package is available here.\n\nIn this section, you will learn how to plot static heatmaps by using heatmap() of R Stats package.\n\n\nIn this sub-section, we will plot a heatmap by using heatmap() of Base Stats. The code chunk is given below.\n\nwh_heatmap &lt;- heatmap(wh_matrix, \n                      Rowv = NA, \n                      Colv = NA)\n\n\n\n\nNote:\n\nBy default, heatmap() plots a cluster heatmap. The arguments Rowv=NA and Colv=NA are used to switch off the option of plotting the row and column dendrograms.\n\nTo plot a cluster heatmap, we just have to use the default as shown in the code chunk below.\n\nwh_heatmap &lt;- heatmap(wh_matrix)\n\n\n\n\nNote:\n\nThe order of both rows and columns is different compare to the native wh_matrix. This is because heatmap do a reordering using clusterisation: it calculates the distance between each pair of rows and columns and try to order them by similarity. Moreover, the corresponding dendrogram are provided beside the heatmap.\n\nHere, red cells denotes small values, and red small ones. This heatmap is not really informative. Indeed, the Happiness Score variable have relatively higher values, what makes that the other variables with small values all look the same. Thus, we need to normalize this matrix. This is done using the scale argument. It can be applied to rows or to columns following your needs.\nThe code chunk below normalises the matrix column-wise.\n\nwh_heatmap &lt;- heatmap(wh_matrix,\n                      scale=\"column\",\n                      cexRow = 0.6, \n                      cexCol = 0.8,\n                      margins = c(10, 4))\n\n\n\n\nNotice that the values are scaled now. Also note that margins argument is used to ensure that the entire x-axis labels are displayed completely and, cexRow and cexCol arguments are used to define the font size used for y-axis and x-axis labels respectively."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05c/Hands-on_Ex05c.html#creating-interactive-heatmap",
    "href": "Hands-on_Ex/Hands-on_Ex05c/Hands-on_Ex05c.html#creating-interactive-heatmap",
    "title": "Hands-on Exercise 5c",
    "section": "",
    "text": "heatmaply is an R package for building interactive cluster heatmap that can be shared online as a stand-alone HTML file. It is designed and maintained by Tal Galili.\nBefore we get started, you should review the Introduction to Heatmaply to have an overall understanding of the features and functions of Heatmaply package. You are also required to have the user manualof the package handy with you for reference purposes.\nIn this section, you will gain hands-on experience on using heatmaply to design an interactive cluster heatmap. We will still use the wh_matrix as the input data.\n\n\n\nheatmaply(mtcars)\n\n\n\n\n\nThe code chunk below shows the basic syntax needed to create an interactive heatmap by using heatmaply package.\n\nheatmaply(wh_matrix[, -c(1, 2, 4, 5)])\n\n\n\n\n\nNote that:\n\nDifferent from heatmap(), for heatmaply() the default horizontal dendrogram is placed on the right hand side of the heatmap.\nThe text label of each raw, on the other hand, is placed on the left hand side of the heat map.\nWhen the x-axis marker labels are too long, they will be rotated by 135 degree from the north.\n\n\n\n\nWhen analysing multivariate data set, it is very common that the variables in the data sets includes values that reflect different types of measurement. In general, these variables’ values have their own range. In order to ensure that all the variables have comparable values, data transformation are commonly used before clustering.\nThree main data transformation methods are supported by heatmaply(), namely: scale, normalise and percentilse.\n\n\n\nWhen all variables are came from or assumed to come from some normal distribution, then scaling (i.e.: subtract the mean and divide by the standard deviation) would bring them all close to the standard normal distribution.\nIn such a case, each value would reflect the distance from the mean in units of standard deviation.\nThe scale argument in heatmaply() supports column and row scaling.\n\nThe code chunk below is used to scale variable values columewise.\n\nheatmaply(wh_matrix[, -c(1, 2, 4, 5)],\n          scale = \"column\")\n\n\n\n\n\n\n\n\n\nWhen variables in the data comes from possibly different (and non-normal) distributions, the normalize function can be used to bring data to the 0 to 1 scale by subtracting the minimum and dividing by the maximum of all observations.\nThis preserves the shape of each variable’s distribution while making them easily comparable on the same “scale”.\n\nDifferent from Scaling, the normalise method is performed on the input data set i.e. wh_matrix as shown in the code chunk below.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]))\n\n\n\n\n\n\n\n\n\nThis is similar to ranking the variables, but instead of keeping the rank values, divide them by the maximal rank.\nThis is done by using the ecdf of the variables on their own values, bringing each value to its empirical percentile.\nThe benefit of the percentize function is that each value has a relatively clear interpretation, it is the percent of observations that got that value or below it.\n\nSimilar to Normalize method, the Percentize method is also performed on the input data set i.e. wh_matrix as shown in the code chunk below.\n\nheatmaply(percentize(wh_matrix[, -c(1, 2, 4, 5)]))\n\n\n\n\n\n\n\n\n\nheatmaply supports a variety of hierarchical clustering algorithm. The main arguments provided are:\n\ndistfun: function used to compute the distance (dissimilarity) between both rows and columns. Defaults to dist. The options “pearson”, “spearman” and “kendall” can be used to use correlation-based clustering, which uses as.dist(1 - cor(t(x))) as the distance metric (using the specified correlation method).\nhclustfun: function used to compute the hierarchical clustering when Rowv or Colv are not dendrograms. Defaults to hclust.\ndist_method default is NULL, which results in “euclidean” to be used. It can accept alternative character strings indicating the method to be passed to distfun. By default distfun is “dist”” hence this can be one of “euclidean”, “maximum”, “manhattan”, “canberra”, “binary” or “minkowski”.\nhclust_method default is NULL, which results in “complete” method to be used. It can accept alternative character strings indicating the method to be passed to hclustfun. By default hclustfun is hclust hence this can be one of “ward.D”, “ward.D2”, “single”, “complete”, “average” (= UPGMA), “mcquitty” (= WPGMA), “median” (= WPGMC) or “centroid” (= UPGMC).\n\nIn general, a clustering model can be calibrated either manually or statistically.\n\n\n\nIn the code chunk below, the heatmap is plotted by using hierachical clustering algorithm with “Euclidean distance” and “ward.D” method.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          dist_method = \"euclidean\",\n          hclust_method = \"ward.D\")\n\n\n\n\n\n\n\n\nIn order to determine the best clustering method and number of cluster the dend_expend() and find_k() functions of dendextend package will be used.\nFirst, the dend_expend() will be used to determine the recommended clustering method to be used.\n\nwh_d &lt;- dist(normalize(wh_matrix[, -c(1, 2, 4, 5)]), method = \"euclidean\")\ndend_expend(wh_d)[[3]]\n\n  dist_methods hclust_methods     optim\n1      unknown         ward.D 0.6137851\n2      unknown        ward.D2 0.6289186\n3      unknown         single 0.4774362\n4      unknown       complete 0.6434009\n5      unknown        average 0.6701688\n6      unknown       mcquitty 0.5020102\n7      unknown         median 0.5901833\n8      unknown       centroid 0.6338734\n\n\nThe output table shows that “average” method should be used because it gave the high optimum value.\nNext, find_k() is used to determine the optimal number of cluster.\n\nwh_clust &lt;- hclust(wh_d, method = \"average\")\nnum_k &lt;- find_k(wh_clust)\nplot(num_k)\n\n\n\n\nFigure above shows that k=3 would be good.\nWith reference to the statistical analysis results, we can prepare the code chunk as shown below.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          dist_method = \"euclidean\",\n          hclust_method = \"average\",\n          k_row = 3)\n\n\n\n\n\n\n\n\nOne of the problems with hierarchical clustering is that it doesn’t actually place the rows in a definite order, it merely constrains the space of possible orderings. Take three items A, B and C. If you ignore reflections, there are three possible orderings: ABC, ACB, BAC. If clustering them gives you ((A+B)+C) as a tree, you know that C can’t end up between A and B, but it doesn’t tell you which way to flip the A+B cluster. It doesn’t tell you if the ABC ordering will lead to a clearer-looking heatmap than the BAC ordering.\nheatmaply uses the seriation package to find an optimal ordering of rows and columns. Optimal means to optimize the Hamiltonian path length that is restricted by the dendrogram structure. This, in other words, means to rotate the branches so that the sum of distances between each adjacent leaf (label) will be minimized. This is related to a restricted version of the travelling salesman problem.\nHere we meet our first seriation algorithm: Optimal Leaf Ordering (OLO). This algorithm starts with the output of an agglomerative clustering algorithm and produces a unique ordering, one that flips the various branches of the dendrogram around so as to minimize the sum of dissimilarities between adjacent leaves. Here is the result of applying Optimal Leaf Ordering to the same clustering result as the heatmap above.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"OLO\")\n\n\n\n\n\nThe default options is “OLO” (Optimal leaf ordering) which optimizes the above criterion (in O(n^4)). Another option is “GW” (Gruvaeus and Wainer) which aims for the same goal but uses a potentially faster heuristic.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"GW\")\n\n\n\n\n\nThe option “mean” gives the output we would get by default from heatmap functions in other packages such as gplots::heatmap.2.\n\nheatmaply(normalize(wh_matrix[, -c(1,2,4,5)]),\n          seriate = \"mean\")\n\n\n\n\n\nThe option “none” gives us the dendrograms without any rotation that is based on the data matrix.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"none\")\n\n\n\n\n\n\n\n\nThe default colour palette uses by heatmaply is viridis. heatmaply users, however, can use other colour palettes in order to improve the aestheticness and visual friendliness of the heatmap.\nIn the code chunk below, the Blues colour palette of rColorBrewer is used.\n\nheatmaply(normalize(wh_matrix[, -c(1,2,4,5)]),\n          seriate = \"mean\",\n          colors = Greens)\n\n\n\n\n\n\n\n\nBeside providing a wide collection of arguments for meeting the statistical analysis needs, heatmaply also provides many plotting features to ensure cartographic quality heatmap can be produced.\nIn the code chunk below the following arguments are used:\n\nk_row is used to produce 5 groups.\nmargins is used to change the top margin to 60 and row margin to 200.\nfontsizw_row and fontsize_col are used to change the font size for row and column labels to 4.\nmain is used to write the main title of the plot.\nxlab and ylab are used to write the x-axis and y-axis labels respectively.\n\n\nheatmaply(normalize(wh_matrix[, -c(1,2,4,5)]),\n          Colv=NA,\n          seriate=\"none\",\n          colors=Blues,\n          k_row=5,\n          margins=c(NA, 200, 60, NA),\n          fontsize_row=4,\n          fonrsize_col=5,\n          height = 1000,\n          main=\"World Happiness Score and Variables by Country, 2018 \\nDataTransformation using Normalise Method\",\n          xlab = \"World Happiness Indicators\",\n          ylab = \"World Countries\"\n          )\n\n\n\n\n\nAdditional practice -\n\nheatmaply(wh_matrix[,-c(1,2,4,5)],\n          seriate=\"mean\",\n          row_dend_left=T,\n          plot_method = \"plotly\",\n          k_row=3,\n          margins=c(NA, 200, 60, NA),\n          fontsize_row=4,\n          fonrsize_col=5,\n          height = 1000)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05e/Hands-on_Ex05e.html",
    "href": "Hands-on_Ex/Hands-on_Ex05e/Hands-on_Ex05e.html",
    "title": "Hands-on Exercise 5e",
    "section": "",
    "text": "In this hands-on exercise, you will gain hands-on experiences on designing treemap using appropriate R packages. The hands-on exercise consists of three main section. First, you will learn how to manipulate transaction data into a treemap strcuture by using selected functions provided in dplyr package. Then, you will learn how to plot static treemap by using treemap package. In the third section, you will learn how to design interactive treemap by using d3treeR package.\n\n\n\nBefore we get started, you are required to check if treemap and tidyverse pacakges have been installed in you R.\n\npacman::p_load(treemap, treemapify, tidyverse) \n\n\n\n\nIn this exercise, REALIS2018.csv data will be used. This dataset provides information of private property transaction records in 2018. The dataset is extracted from REALIS portal (https://spring.ura.gov.sg/lad/ore/login/index.cfm) of Urban Redevelopment Authority (URA).\n\n\nIn the code chunk below, read_csv() of readr is used to import realis2018.csv into R and parsed it into tibble R data.frame format.\n\nrealis2018 &lt;- read_csv(\"data/realis2018.csv\")\n\nThe output tibble data.frame is called realis2018.\n\n\n\nThe data.frame realis2018 is in trasaction record form, which is highly disaggregated and not appropriate to be used to plot a treemap. In this section, we will perform the following steps to manipulate and prepare a data.frame that is appropriate for treemap visualisation:\n\ngroup transaction records by Project Name, Planning Region, Planning Area, Property Type and Type of Sale, and\ncompute Total Unit Sold, Total Area, Median Unit Price and Median Transacted Price by applying appropriate summary statistics on No. of Units, Area (sqm), Unit Price ($ psm) and Transacted Price ($) respectively.\n\nTwo key verbs of dplyr package, namely: group_by() and summarize() will be used to perform these steps.\ngroup_by() breaks down a data.frame into specified groups of rows. When you then apply the verbs above on the resulting object they’ll be automatically applied “by group”.\nGrouping affects the verbs as follows:\n\ngrouped select() is the same as ungrouped select(), except that grouping variables are always retained.\ngrouped arrange() is the same as ungrouped; unless you set .by_group = TRUE, in which case it orders first by the grouping variables.\nmutate() and filter() are most useful in conjunction with window functions (like rank(), or min(x) == x). They are described in detail in vignette(“window-functions”).\nsample_n() and sample_frac() sample the specified number/fraction of rows in each group.\nsummarise() computes the summary for each group.\n\nIn our case, group_by() will used together with summarise() to derive the summarised data.frame.\n\n\n\n\n\n\nRecommendation\n\n\n\nStudents who are new to dplyr methods should consult Introduction to dplyr before moving on to the next section.\n\n\n\n\n\nThe code chank below shows a typical two lines code approach to perform the steps.\n\nrealis2018_grouped &lt;- group_by(realis2018, `Project Name`,\n                               `Planning Region`, `Planning Area`, \n                               `Property Type`, `Type of Sale`)\nrealis2018_summarised &lt;- summarise(realis2018_grouped, \n                          `Total Unit Sold` = sum(`No. of Units`, na.rm = TRUE),\n                          `Total Area` = sum(`Area (sqm)`, na.rm = TRUE),\n                          `Median Unit Price ($ psm)` = median(`Unit Price ($ psm)`, na.rm = TRUE), \n                          `Median Transacted Price` = median(`Transacted Price ($)`, na.rm = TRUE))\n\n\n\n\n\n\n\nNote\n\n\n\n\nAggregation functions such as sum() and median() obey the usual rule of missing values: if there’s any missing value in the input, the output will be a missing value. The argument na.rm = TRUE removes the missing values prior to computation.\n\n\n\nThe code chunk above is not very efficient because we have to give each intermediate data.frame a name, even though we don’t have to care about it.\n\n\n\nThe code chunk below shows a more efficient way to tackle the same processes by using the pipe, %&gt;%:\n\n\n\n\n\n\nRecommendation\n\n\n\nTo learn more about pipe, visit this excellent article: Pipes in R Tutorial For Beginners.\n\n\n\nrealis2018_summarised &lt;- realis2018 %&gt;% \n  group_by(`Project Name`,`Planning Region`, \n           `Planning Area`, `Property Type`, \n           `Type of Sale`) %&gt;%\n  summarise(`Total Unit Sold` = sum(`No. of Units`, na.rm = TRUE), \n            `Total Area` = sum(`Area (sqm)`, na.rm = TRUE),\n            `Median Unit Price ($ psm)` = median(`Unit Price ($ psm)`, na.rm = TRUE),\n            `Median Transacted Price` = median(`Transacted Price ($)`, na.rm = TRUE))\n\n\n\n\n\ntreemap package is a R package specially designed to offer great flexibility in drawing treemaps. The core function, namely: treemap() offers at least 43 arguments. In this section, we will only explore the major arguments for designing elegent and yet truthful treemaps.\n\n\nIn this section, treemap() of Treemap package is used to plot a treemap showing the distribution of median unit prices and total unit sold of resale condominium by geographic hierarchy in 2017.\nFirst, we will select records belongs to resale condominium property type from realis2018_selected data frame.\n\nrealis2018_selected &lt;- realis2018_summarised %&gt;% \n  filter(`Property Type` == \"Condominium\", `Type of Sale` == \"Resale\")\n\n\n\n\nThe code chunk below designed a treemap by using three core arguments of treemap(), namely: index, vSize and vColor.\n\ntreemap(realis2018_selected,\n        index = c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize = \"Total Unit Sold\",\n        vColor = \"Median Unit Price ($ psm)\",\n        title = \"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\nThings to learn from the three arguments used:\n\nindex\n\nThe index vector must consist of at least two column names or else no hierarchy treemap will be plotted.\nIf multiple column names are provided, such as the code chunk above, the first name is the highest aggregation level, the second name the second highest aggregation level, and so on.\n\nvSize\n\nThe column must not contain negative values. This is because it’s vaues will be used to map the sizes of the rectangles of the treemaps.\n\n\nWarning:\nThe treemap above was wrongly coloured. For a correctly designed treemap, the colours of the rectagles should be in different intensity showing, in our case, median unit prices.\nFor treemap(), vColor is used in combination with the argument type to determines the colours of the rectangles. Without defining type, like the code chunk above, treemap() assumes type = index, in our case, the hierarchy of planning areas.\n\n\n\nIn the code chunk below, type argument is define as value.\n\nType = valueType = dens\n\n\n\ntreemap(realis2018_selected,\n        index = c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize = \"Total Unit Sold\",\n        vColor = \"Median Unit Price ($ psm)\",\n        type = \"value\",\n        title = \"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\ntreemap(realis2018_selected,\n        index = c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize = \"Total Unit Sold\",\n        vColor = \"Median Unit Price ($ psm)\",\n        type = \"dens\",\n        title = \"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\nThinking to learn from the code chunk above.\n\nThe rectangles are coloured with different intensity of green, reflecting their respective median unit prices.\nThe legend reveals that the values are binned into ten bins, i.e. 0-5000, 5000-10000, etc. with an equal interval of 5000.\n\n\n\n\nThere are two arguments that determine the mapping to color palettes: mapping and palette. The only difference between “value” and “manual” is the default value for mapping. The “value” treemap considers palette to be a diverging color palette (say ColorBrewer’s “RdYlBu”), and maps it in such a way that 0 corresponds to the middle color (typically white or yellow), -max(abs(values)) to the left-end color, and max(abs(values)), to the right-end color. The “manual” treemap simply maps min(values) to the left-end color, max(values) to the right-end color, and mean(range(values)) to the middle color.\n\n\n\nThe code chunk below shows a value type treemap.\n\ntreemap(realis2018_selected,\n        index = c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize = \"Total Unit Sold\",\n        vColor = \"Median Unit Price ($ psm)\",\n        type = \"value\",\n        palette = \"RdYlBu\",\n        title = \"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\nThing to learn from the code chunk above:\n\nalthough the colour palette used is RdYlBu but there are no red rectangles in the treemap above. This is because all the median unit prices are positive.\nThe reason why we see only 5000 to 45000 in the legend is because the range argument is by default c(min(values, max(values)) with some pretty rounding.\n\n\n\n\nThe “manual” type does not interpret the values as the “value” type does. Instead, the value range is mapped linearly to the colour palette.\nThe code chunk below shows a manual type treemap.\n\ntreemap(realis2018_selected,\n        index = c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize = \"Total Unit Sold\",\n        vColor = \"Median Unit Price ($ psm)\",\n        type = \"manual\",\n        palette = \"RdYlBu\",\n        title = \"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\nThings to learn from the code chunk above:\n\nThe colour scheme used is very copnfusing. This is because mapping = (min(values), mean(range(values)), max(values)). It is not wise to use diverging colour palette such as RdYlBu if the values are all positive or negative\n\nTo overcome this problem, a single colour palette such as Blues should be used.\n\ntreemap(realis2018_selected,\n        index = c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize = \"Total Unit Sold\",\n        vColor = \"Median Unit Price ($ psm)\",\n        type = \"manual\",\n        palette = \"Greens\",\n        title = \"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\ntreemap() supports two popular treemap layouts, namely: “squarified” and “pivotSize”. The default is “pivotSize”.\nThe squarified treemap algorithm (Bruls et al., 2000) produces good aspect ratios, but ignores the sorting order of the rectangles (sortID). The ordered treemap, pivot-by-size, algorithm (Bederson et al., 2002) takes the sorting order (sortID) into account while aspect ratios are still acceptable.\n\n\n\nThe code chunk below plots a squarified treemap by changing the algorithm argument.\n\ntreemap(realis2018_selected,\n        index = c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize = \"Total Unit Sold\",\n        vColor = \"Median Unit Price ($ psm)\",\n        type = \"manual\",\n        palette = \"Oranges\",\n        algorithm = \"squarified\",\n        title = \"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\nWhen “pivotSize” algorithm is used, sortID argument can be used to dertemine the order in which the rectangles are placed from top left to bottom right.\n\np &lt;- treemap(realis2018_selected,\n        index = c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize = \"Total Unit Sold\",\n        vColor = \"Median Unit Price ($ psm)\",\n        type = \"manual\",\n        palette = \"Blues\",\n        algorithm = \"pivotSize\",\n        sortID = \"Median Transacted Price\",\n        title = \"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\n\ntreemapify is a R package specially developed to draw treemaps in ggplot2. In this section, you will learn how to designing treemps closely resemble treemaps designing in previous section by using treemapify. Before you getting started, you should read Introduction to “treemapify” its user guide.\n\n\n\nggplot(data=realis2018_selected,\n       aes(area = `Total Unit Sold`,\n           fill = `Median Unit Price ($ psm)`),\n       layout = \"scol\",\n       start = \"bottomleft\") +\n  geom_treemap() +\n  scale_fill_gradient(low = \"lightblue\", high = \"blue\")\n\n\n\n\n\n\n\nGroup by Planning Region\n\nggplot(data=realis2018_selected,\n       aes(area = `Total Unit Sold`,\n           fill = `Median Unit Price ($ psm)`,\n           subgroup = `Planning Region`),\n       start = \"topleft\") +\n  geom_treemap()\n\n\n\n\nGroup by Planning Area\n\nggplot(data=realis2018_selected,\n       aes(area = `Total Unit Sold`,\n           fill = `Median Unit Price ($ psm)`,\n           subgroup = `Planning Region`,\n           subgroup2 = `Planning Area`)) +\n  geom_treemap()\n\n\n\n\nAdding boundary line\n\nggplot(data=realis2018_selected,\n       aes(area = `Total Unit Sold`,\n           fill = `Median Unit Price ($ psm)`,\n           subgroup = `Planning Region`,\n           subgroup2 = `Planning Area`)) +\n  geom_treemap() +\n  geom_treemap_subgroup2_border(colour = \"gray40\",\n                                size = 2) +\n  geom_treemap_subgroup_border(colour = \"gray20\")\n\n\n\n\n\n\n\n\n\n\nThis slide shows you how to install a R package which is not available in cran.\n\nIf this is the first time you install a package from github, you should install devtools package by using the code below or else you can skip this step.\n\n\ninstall.packages(\"devtools\")\n\n\nNext, you will load the devtools library and install the package found in github by using the codes below.\n\n\nlibrary(devtools)\ninstall_github(\"timelyportfolio/d3treeR\")\n\n\nNow you are ready to launch d3treeR package’\n\n\nlibrary(d3treeR)\n\n\n\n\nThe codes below perform two processes.\n\ntreemap() is used to build a treemap by using selected variables in condominium data.frame. The treemap created is save as object called tm.\n\n\ntm &lt;- treemap(realis2018_summarised,\n              index=c(\"Planning Region\", \"Planning Area\"),\n              vSize=\"Total Unit Sold\",\n              vColor=\"Median Unit Price ($ psm)\",\n              type=\"value\",\n              title=\"Private Residential Property Sold, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\nThen d3tree() is used to build an interactive treemap.\n\n\nd3tree(tm,rootname = \"Singapore\" )\n\n\n\n\n\nTrying out interactive version of Sect 4.9\n\nd3tree(p,rootname = \"Singapore\" )"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05e/Hands-on_Ex05e.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex05e/Hands-on_Ex05e.html#overview",
    "title": "Hands-on Exercise 5e",
    "section": "",
    "text": "In this hands-on exercise, you will gain hands-on experiences on designing treemap using appropriate R packages. The hands-on exercise consists of three main section. First, you will learn how to manipulate transaction data into a treemap strcuture by using selected functions provided in dplyr package. Then, you will learn how to plot static treemap by using treemap package. In the third section, you will learn how to design interactive treemap by using d3treeR package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05e/Hands-on_Ex05e.html#installing-and-launching-r-packages",
    "href": "Hands-on_Ex/Hands-on_Ex05e/Hands-on_Ex05e.html#installing-and-launching-r-packages",
    "title": "Hands-on Exercise 5e",
    "section": "",
    "text": "Before we get started, you are required to check if treemap and tidyverse pacakges have been installed in you R.\n\npacman::p_load(treemap, treemapify, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05e/Hands-on_Ex05e.html#data-wrangling",
    "href": "Hands-on_Ex/Hands-on_Ex05e/Hands-on_Ex05e.html#data-wrangling",
    "title": "Hands-on Exercise 5e",
    "section": "",
    "text": "In this exercise, REALIS2018.csv data will be used. This dataset provides information of private property transaction records in 2018. The dataset is extracted from REALIS portal (https://spring.ura.gov.sg/lad/ore/login/index.cfm) of Urban Redevelopment Authority (URA).\n\n\nIn the code chunk below, read_csv() of readr is used to import realis2018.csv into R and parsed it into tibble R data.frame format.\n\nrealis2018 &lt;- read_csv(\"data/realis2018.csv\")\n\nThe output tibble data.frame is called realis2018.\n\n\n\nThe data.frame realis2018 is in trasaction record form, which is highly disaggregated and not appropriate to be used to plot a treemap. In this section, we will perform the following steps to manipulate and prepare a data.frame that is appropriate for treemap visualisation:\n\ngroup transaction records by Project Name, Planning Region, Planning Area, Property Type and Type of Sale, and\ncompute Total Unit Sold, Total Area, Median Unit Price and Median Transacted Price by applying appropriate summary statistics on No. of Units, Area (sqm), Unit Price ($ psm) and Transacted Price ($) respectively.\n\nTwo key verbs of dplyr package, namely: group_by() and summarize() will be used to perform these steps.\ngroup_by() breaks down a data.frame into specified groups of rows. When you then apply the verbs above on the resulting object they’ll be automatically applied “by group”.\nGrouping affects the verbs as follows:\n\ngrouped select() is the same as ungrouped select(), except that grouping variables are always retained.\ngrouped arrange() is the same as ungrouped; unless you set .by_group = TRUE, in which case it orders first by the grouping variables.\nmutate() and filter() are most useful in conjunction with window functions (like rank(), or min(x) == x). They are described in detail in vignette(“window-functions”).\nsample_n() and sample_frac() sample the specified number/fraction of rows in each group.\nsummarise() computes the summary for each group.\n\nIn our case, group_by() will used together with summarise() to derive the summarised data.frame.\n\n\n\n\n\n\nRecommendation\n\n\n\nStudents who are new to dplyr methods should consult Introduction to dplyr before moving on to the next section.\n\n\n\n\n\nThe code chank below shows a typical two lines code approach to perform the steps.\n\nrealis2018_grouped &lt;- group_by(realis2018, `Project Name`,\n                               `Planning Region`, `Planning Area`, \n                               `Property Type`, `Type of Sale`)\nrealis2018_summarised &lt;- summarise(realis2018_grouped, \n                          `Total Unit Sold` = sum(`No. of Units`, na.rm = TRUE),\n                          `Total Area` = sum(`Area (sqm)`, na.rm = TRUE),\n                          `Median Unit Price ($ psm)` = median(`Unit Price ($ psm)`, na.rm = TRUE), \n                          `Median Transacted Price` = median(`Transacted Price ($)`, na.rm = TRUE))\n\n\n\n\n\n\n\nNote\n\n\n\n\nAggregation functions such as sum() and median() obey the usual rule of missing values: if there’s any missing value in the input, the output will be a missing value. The argument na.rm = TRUE removes the missing values prior to computation.\n\n\n\nThe code chunk above is not very efficient because we have to give each intermediate data.frame a name, even though we don’t have to care about it.\n\n\n\nThe code chunk below shows a more efficient way to tackle the same processes by using the pipe, %&gt;%:\n\n\n\n\n\n\nRecommendation\n\n\n\nTo learn more about pipe, visit this excellent article: Pipes in R Tutorial For Beginners.\n\n\n\nrealis2018_summarised &lt;- realis2018 %&gt;% \n  group_by(`Project Name`,`Planning Region`, \n           `Planning Area`, `Property Type`, \n           `Type of Sale`) %&gt;%\n  summarise(`Total Unit Sold` = sum(`No. of Units`, na.rm = TRUE), \n            `Total Area` = sum(`Area (sqm)`, na.rm = TRUE),\n            `Median Unit Price ($ psm)` = median(`Unit Price ($ psm)`, na.rm = TRUE),\n            `Median Transacted Price` = median(`Transacted Price ($)`, na.rm = TRUE))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05e/Hands-on_Ex05e.html#designing-treemap-with-treemap-package",
    "href": "Hands-on_Ex/Hands-on_Ex05e/Hands-on_Ex05e.html#designing-treemap-with-treemap-package",
    "title": "Hands-on Exercise 5e",
    "section": "",
    "text": "treemap package is a R package specially designed to offer great flexibility in drawing treemaps. The core function, namely: treemap() offers at least 43 arguments. In this section, we will only explore the major arguments for designing elegent and yet truthful treemaps.\n\n\nIn this section, treemap() of Treemap package is used to plot a treemap showing the distribution of median unit prices and total unit sold of resale condominium by geographic hierarchy in 2017.\nFirst, we will select records belongs to resale condominium property type from realis2018_selected data frame.\n\nrealis2018_selected &lt;- realis2018_summarised %&gt;% \n  filter(`Property Type` == \"Condominium\", `Type of Sale` == \"Resale\")\n\n\n\n\nThe code chunk below designed a treemap by using three core arguments of treemap(), namely: index, vSize and vColor.\n\ntreemap(realis2018_selected,\n        index = c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize = \"Total Unit Sold\",\n        vColor = \"Median Unit Price ($ psm)\",\n        title = \"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\nThings to learn from the three arguments used:\n\nindex\n\nThe index vector must consist of at least two column names or else no hierarchy treemap will be plotted.\nIf multiple column names are provided, such as the code chunk above, the first name is the highest aggregation level, the second name the second highest aggregation level, and so on.\n\nvSize\n\nThe column must not contain negative values. This is because it’s vaues will be used to map the sizes of the rectangles of the treemaps.\n\n\nWarning:\nThe treemap above was wrongly coloured. For a correctly designed treemap, the colours of the rectagles should be in different intensity showing, in our case, median unit prices.\nFor treemap(), vColor is used in combination with the argument type to determines the colours of the rectangles. Without defining type, like the code chunk above, treemap() assumes type = index, in our case, the hierarchy of planning areas.\n\n\n\nIn the code chunk below, type argument is define as value.\n\nType = valueType = dens\n\n\n\ntreemap(realis2018_selected,\n        index = c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize = \"Total Unit Sold\",\n        vColor = \"Median Unit Price ($ psm)\",\n        type = \"value\",\n        title = \"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\ntreemap(realis2018_selected,\n        index = c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize = \"Total Unit Sold\",\n        vColor = \"Median Unit Price ($ psm)\",\n        type = \"dens\",\n        title = \"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\nThinking to learn from the code chunk above.\n\nThe rectangles are coloured with different intensity of green, reflecting their respective median unit prices.\nThe legend reveals that the values are binned into ten bins, i.e. 0-5000, 5000-10000, etc. with an equal interval of 5000.\n\n\n\n\nThere are two arguments that determine the mapping to color palettes: mapping and palette. The only difference between “value” and “manual” is the default value for mapping. The “value” treemap considers palette to be a diverging color palette (say ColorBrewer’s “RdYlBu”), and maps it in such a way that 0 corresponds to the middle color (typically white or yellow), -max(abs(values)) to the left-end color, and max(abs(values)), to the right-end color. The “manual” treemap simply maps min(values) to the left-end color, max(values) to the right-end color, and mean(range(values)) to the middle color.\n\n\n\nThe code chunk below shows a value type treemap.\n\ntreemap(realis2018_selected,\n        index = c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize = \"Total Unit Sold\",\n        vColor = \"Median Unit Price ($ psm)\",\n        type = \"value\",\n        palette = \"RdYlBu\",\n        title = \"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\nThing to learn from the code chunk above:\n\nalthough the colour palette used is RdYlBu but there are no red rectangles in the treemap above. This is because all the median unit prices are positive.\nThe reason why we see only 5000 to 45000 in the legend is because the range argument is by default c(min(values, max(values)) with some pretty rounding.\n\n\n\n\nThe “manual” type does not interpret the values as the “value” type does. Instead, the value range is mapped linearly to the colour palette.\nThe code chunk below shows a manual type treemap.\n\ntreemap(realis2018_selected,\n        index = c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize = \"Total Unit Sold\",\n        vColor = \"Median Unit Price ($ psm)\",\n        type = \"manual\",\n        palette = \"RdYlBu\",\n        title = \"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\nThings to learn from the code chunk above:\n\nThe colour scheme used is very copnfusing. This is because mapping = (min(values), mean(range(values)), max(values)). It is not wise to use diverging colour palette such as RdYlBu if the values are all positive or negative\n\nTo overcome this problem, a single colour palette such as Blues should be used.\n\ntreemap(realis2018_selected,\n        index = c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize = \"Total Unit Sold\",\n        vColor = \"Median Unit Price ($ psm)\",\n        type = \"manual\",\n        palette = \"Greens\",\n        title = \"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\ntreemap() supports two popular treemap layouts, namely: “squarified” and “pivotSize”. The default is “pivotSize”.\nThe squarified treemap algorithm (Bruls et al., 2000) produces good aspect ratios, but ignores the sorting order of the rectangles (sortID). The ordered treemap, pivot-by-size, algorithm (Bederson et al., 2002) takes the sorting order (sortID) into account while aspect ratios are still acceptable.\n\n\n\nThe code chunk below plots a squarified treemap by changing the algorithm argument.\n\ntreemap(realis2018_selected,\n        index = c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize = \"Total Unit Sold\",\n        vColor = \"Median Unit Price ($ psm)\",\n        type = \"manual\",\n        palette = \"Oranges\",\n        algorithm = \"squarified\",\n        title = \"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\nWhen “pivotSize” algorithm is used, sortID argument can be used to dertemine the order in which the rectangles are placed from top left to bottom right.\n\np &lt;- treemap(realis2018_selected,\n        index = c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize = \"Total Unit Sold\",\n        vColor = \"Median Unit Price ($ psm)\",\n        type = \"manual\",\n        palette = \"Blues\",\n        algorithm = \"pivotSize\",\n        sortID = \"Median Transacted Price\",\n        title = \"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05e/Hands-on_Ex05e.html#designing-treemap-using-treemapify-package",
    "href": "Hands-on_Ex/Hands-on_Ex05e/Hands-on_Ex05e.html#designing-treemap-using-treemapify-package",
    "title": "Hands-on Exercise 5e",
    "section": "",
    "text": "treemapify is a R package specially developed to draw treemaps in ggplot2. In this section, you will learn how to designing treemps closely resemble treemaps designing in previous section by using treemapify. Before you getting started, you should read Introduction to “treemapify” its user guide.\n\n\n\nggplot(data=realis2018_selected,\n       aes(area = `Total Unit Sold`,\n           fill = `Median Unit Price ($ psm)`),\n       layout = \"scol\",\n       start = \"bottomleft\") +\n  geom_treemap() +\n  scale_fill_gradient(low = \"lightblue\", high = \"blue\")\n\n\n\n\n\n\n\nGroup by Planning Region\n\nggplot(data=realis2018_selected,\n       aes(area = `Total Unit Sold`,\n           fill = `Median Unit Price ($ psm)`,\n           subgroup = `Planning Region`),\n       start = \"topleft\") +\n  geom_treemap()\n\n\n\n\nGroup by Planning Area\n\nggplot(data=realis2018_selected,\n       aes(area = `Total Unit Sold`,\n           fill = `Median Unit Price ($ psm)`,\n           subgroup = `Planning Region`,\n           subgroup2 = `Planning Area`)) +\n  geom_treemap()\n\n\n\n\nAdding boundary line\n\nggplot(data=realis2018_selected,\n       aes(area = `Total Unit Sold`,\n           fill = `Median Unit Price ($ psm)`,\n           subgroup = `Planning Region`,\n           subgroup2 = `Planning Area`)) +\n  geom_treemap() +\n  geom_treemap_subgroup2_border(colour = \"gray40\",\n                                size = 2) +\n  geom_treemap_subgroup_border(colour = \"gray20\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05e/Hands-on_Ex05e.html#designing-interactive-treemap-using-d3treer",
    "href": "Hands-on_Ex/Hands-on_Ex05e/Hands-on_Ex05e.html#designing-interactive-treemap-using-d3treer",
    "title": "Hands-on Exercise 5e",
    "section": "",
    "text": "This slide shows you how to install a R package which is not available in cran.\n\nIf this is the first time you install a package from github, you should install devtools package by using the code below or else you can skip this step.\n\n\ninstall.packages(\"devtools\")\n\n\nNext, you will load the devtools library and install the package found in github by using the codes below.\n\n\nlibrary(devtools)\ninstall_github(\"timelyportfolio/d3treeR\")\n\n\nNow you are ready to launch d3treeR package’\n\n\nlibrary(d3treeR)\n\n\n\n\nThe codes below perform two processes.\n\ntreemap() is used to build a treemap by using selected variables in condominium data.frame. The treemap created is save as object called tm.\n\n\ntm &lt;- treemap(realis2018_summarised,\n              index=c(\"Planning Region\", \"Planning Area\"),\n              vSize=\"Total Unit Sold\",\n              vColor=\"Median Unit Price ($ psm)\",\n              type=\"value\",\n              title=\"Private Residential Property Sold, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\nThen d3tree() is used to build an interactive treemap.\n\n\nd3tree(tm,rootname = \"Singapore\" )\n\n\n\n\n\nTrying out interactive version of Sect 4.9\n\nd3tree(p,rootname = \"Singapore\" )"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07a/Hands-on_Ex07a.html",
    "href": "Hands-on_Ex/Hands-on_Ex07a/Hands-on_Ex07a.html",
    "title": "Hands-on Exercise 7a",
    "section": "",
    "text": "Choropleth mapping involves the symbolisation of enumeration units, such as countries, provinces, states, counties or census units, using area patterns or graduated colors. For example, a social scientist may need to use a choropleth map to portray the spatial distribution of aged population of Singapore by Master Plan 2014 Subzone Boundary.\nIn this chapter, you will learn how to plot functional and truthful choropleth maps by using an R package called tmap package.\n\n\n\n\n\n\nTip\n\n\n\nIt is advisable for you to read the functional description of each function before using them.\n\n\n\n\n\nIn this hands-on exercise, the key R package use is tmap package in R. Beside tmap package, four other R packages will be used. They are:\n\nreadr for importing delimited text file,\ntidyr for tidying data,\ndplyr for wrangling data and\nsf for handling geospatial data.\n\nAmong the four packages, readr, tidyr and dplyr are part of tidyverse package.\nThe code chunk below will be used to install and load these packages in RStudio.\n\npacman::p_load(sf, tmap, tidyverse)\n\n\n\n\n\n\n\nNote\n\n\n\nNotice that, we only need to install tidyverse instead of readr, tidyr and dplyr individually.\n\n\n\n\n\n\n\nTwo data set will be used to create the choropleth map. They are:\n\nMaster Plan 2014 Subzone Boundary (Web) (i.e. MP14_SUBZONE_WEB_PL) in ESRI shapefile format. It can be downloaded at data.gov.sg This is a geospatial data. It consists of the geographical boundary of Singapore at the planning subzone level. The data is based on URA Master Plan 2014.\nSingapore Residents by Planning Area / Subzone, Age Group, Sex and Type of Dwelling, June 2011-2020 in csv format (i.e. respopagesextod2011to2020.csv). This is an aspatial data fie. It can be downloaded at Department of Statistics, Singapore Although it does not contain any coordinates values, but it’s PA and SZ fields can be used as unique identifiers to geocode to MP14_SUBZONE_WEB_PL shapefile.\n\n\n\n\nThe code chunk below uses the st_read() function of sf package to import MP14_SUBZONE_WEB_PL shapefile into R as a simple feature data frame called mpsz.\n\nmpsz &lt;- st_read(dsn = \"data/geospatial\", \n                layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\weimingfu\\ISSS608-VAA\\Hands-on_Ex\\Hands-on_Ex07a\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nYou can examine the content of mpsz by using the code chunk below.\n\nmpsz\n\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 10 features:\n   OBJECTID SUBZONE_NO       SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1         1          1    MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2         2          1    PEARL'S HILL    OTSZ01      Y          OUTRAM\n3         3          3       BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4         4          8  HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5         5          3         REDHILL    BMSZ03      N     BUKIT MERAH\n6         6          7  ALEXANDRA HILL    BMSZ07      N     BUKIT MERAH\n7         7          9   BUKIT HO SWEE    BMSZ09      N     BUKIT MERAH\n8         8          2     CLARKE QUAY    SRSZ02      Y SINGAPORE RIVER\n9         9         13 PASIR PANJANG 1    QTSZ13      N      QUEENSTOWN\n10       10          7       QUEENSWAY    QTSZ07      N      QUEENSTOWN\n   PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1          MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2          OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3          SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4          BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5          BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n6          BM CENTRAL REGION       CR 9D286521EF5E3B59 2014-12-05 25358.82\n7          BM CENTRAL REGION       CR 7839A8577144EFE2 2014-12-05 27680.06\n8          SR CENTRAL REGION       CR 48661DC0FBA09F7A 2014-12-05 29253.21\n9          QT CENTRAL REGION       CR 1F721290C421BFAB 2014-12-05 22077.34\n10         QT CENTRAL REGION       CR 3580D2AFFBEE914C 2014-12-05 24168.31\n     Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1  29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2  29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3  29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4  29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5  30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n6  29991.38   4428.913  1030378.8 MULTIPOLYGON (((25899.7 297...\n7  30230.86   3275.312   551732.0 MULTIPOLYGON (((27746.95 30...\n8  30222.86   2208.619   290184.7 MULTIPOLYGON (((29351.26 29...\n9  29893.78   6571.323  1084792.3 MULTIPOLYGON (((20996.49 30...\n10 30104.18   3454.239   631644.3 MULTIPOLYGON (((24472.11 29...\n\n\nNotice that only the first ten records will be displayed. Do you know why?\nIn R, when you view a simple feature dataframe (sf dataframe) using the default print method, typically only the first 10 records are shown. This is a default behavior designed to give you a quick overview of your data without overwhelming you with too much information, especially for large datasets.\n\n\n\nNext, we will import respopagsex2011to2020.csv file into RStudio and save the file into an R dataframe called popagsex.\nThe task will be performed by using read_csv() function of readr package as shown in the code chunk below.\n\npopdata &lt;- read_csv(\"data/aspatial/respopagesextod2011to2020.csv\")\n\n\n\n\nBefore a thematic map can be prepared, you are required to prepare a data table with year 2020 values. The data table should include the variables PA, SZ, YOUNG, ECONOMY ACTIVE, AGED, TOTAL, DEPENDENCY.\n\nYOUNG: age group 0 to 4 until age groyup 20 to 24,\nECONOMY ACTIVE: age group 25-29 until age group 60-64,\nAGED: age group 65 and above,\nTOTAL: all age group, and\nDEPENDENCY: the ratio between young and aged against economy active group\n\n\n\nThe following data wrangling and transformation functions will be used:\n\npivot_wider() of tidyr package, and\nmutate(), filter(), group_by() and select() of dplyr package\n\n\npopdata2020 &lt;- popdata %&gt;% \n  filter(Time == 2020) %&gt;% \n  group_by(PA, SZ, AG) %&gt;% \n  summarise(`POP` = sum(`Pop`)) %&gt;% \n  ungroup() %&gt;% \n  pivot_wider(names_from = AG,\n              values_from = POP) %&gt;% \n  mutate(`YOUNG` = rowSums(.[3:6]) + rowSums(.[12])) %&gt;% \n  mutate(`ECONOMY ACTIVE` = rowSums(.[7:11]) + rowSums(.[13:15])) %&gt;% \n  mutate(`AGED`=rowSums(.[16:21])) %&gt;% \n  mutate(`TOTAL`=rowSums(.[3:21])) %&gt;% \n  mutate(`DEPENDENCY` = (`YOUNG` + `AGED`)/`ECONOMY ACTIVE`) %&gt;% \n  select(`PA`, `SZ`, `YOUNG`, `ECONOMY ACTIVE`, `AGED`, `TOTAL`, `DEPENDENCY`)\n\n\n\n\nBefore we can perform the georelational join, one extra step is required to convert the values in PA and SZ fields to uppercase. This is because the values of PA and SZ fields are made up of upper- and lowercase. On the other, hand the SUBZONE_N and PLN_AREA_N are in uppercase.\n\npopdata2020 &lt;- popdata2020 %&gt;% \n  mutate_at(.vars = vars(PA,SZ),\n            .funs = funs(toupper)) %&gt;% \n  filter(`ECONOMY ACTIVE` &gt; 0)\n\nNext, left_join() of dplyr is used to join the geographical data and attribute table using planning subzone name e.g. SUBZONE_N and SZ as the common identifier.\n\nmpsz_pop2020 &lt;- left_join(mpsz, popdata2020,\n                          by = c(\"SUBZONE_N\" = \"SZ\"))\n\nThing to learn from the code chunk above:\n\nleft_join() of dplyr package is used with mpsz simple feature data frame as the left data table is to ensure that the output will be a simple features data frame.\n\n\nwrite_rds(mpsz_pop2020, \"data/rds/mpszpop2020.rds\")\n\n\n\n\n\n\nTwo approaches can be used to prepare thematic map using tmap, they are:\n\nPlotting a thematic map quickly by using qtm().\nPlotting highly customisable thematic map by using tmap elements.\n\n\n\nThe easiest and quickest to draw a choropleth map using tmap is using qtm(). It is concise and provides a good default visualisation in many cases.\nThe code chunk below will draw a cartographic standard choropleth map as shown below.\n\ntmap_mode(\"plot\")\nqtm(mpsz_pop2020, \n    fill = \"DEPENDENCY\")\n\n\n\n\nThings to learn from the code chunk above:\n\ntmap_mode() with “plot” option is used to produce a static map. For interactive mode, “view” option should be used.\nfill argument is used to map the attribute (i.e. DEPENDENCY)\n\n\n\n\nDespite its usefulness of drawing a choropleth map quickly and easily, the disadvantge of qtm() is that it makes aesthetics of individual layers harder to control. To draw a high quality cartographic choropleth map as shown in the figure below, tmap’s drawing elements should be used.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          style=\"quantile\",\n          palette=\"Blues\",\n          title=\"Dependency ratio\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45,\n            legend.width = 0.35,\n            frame = T) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size=2) +\n  tm_scale_bar() +\n  tm_grid(alpha=0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\",\n             position = c(\"left\", \"bottom\"))\n\n\n\n\nIn the following sub-section, we will share with you tmap functions that used to plot these elements.\n\n\nThe basic building block of tmap is tm_shape() followed by one or more layer elemments such as tm_fill() and tm_polygons().\nIn the code chunk below, tm_shape() is used to define the input data (i.e mpsz_pop2020) and tm_polygons() is used to draw the planning subzone polygons\n\ntm_shape(mpsz_pop2020) +\n  tm_polygons()\n\n\n\n\n\n\n\nTo draw a choropleth map showing the geographical distribution of a selected variable by planning subzone, we just need to assign the target variable such as Dependency to tm_polygons().\n\ntm_shape(mpsz_pop2020) +\n  tm_polygons(\"DEPENDENCY\")\n\n\n\n\nThings to learn from tm_polygons():\n\nThe default interval binning used to draw the choropleth map is called “pretty”. A detailed discussion of the data classification methods supported by tmap will be provided in sub-section 4.3.\nThe default colour scheme used is YlOrRd of ColorBrewer. You will learn more about the color scheme in sub-section 4.4.\nBy default, Missing value will be shaded in grey.\n\n\n\n\nActually, tm_polygons() is a wraper of tm_fill() and tm_border(). tm_fill() shades the polygons by using the default colour scheme and tm_borders() adds the borders of the shapefile onto the choropleth map.\nThe code chunk below draws a choropleth map by using tm_fill() alone.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\")\n\n\n\n\nNotice that the planning subzones are shared according to the respective dependecy values\nTo add the boundary of the planning subzones, tm_borders will be used as shown in the code chunk below.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\") +\n  tm_borders(lwd = 0.1,  alpha = 1)\n\n\n\n\nNotice that light-gray border lines have been added on the choropleth map.\nThe alpha argument is used to define transparency number between 0 (totally transparent) and 1 (not transparent). By default, the alpha value of the col is used (normally 1).\nBeside alpha argument, there are three other arguments for tm_borders(), they are:\n\ncol = border colour,\nlwd = border line width. The default is 1, and\nlty = border line type. The default is “solid”.\n\n\n\n\n\nMost choropleth maps employ some methods of data classification. The point of classification is to take a large number of observations and group them into data ranges or classes.\ntmap provides a total ten data classification methods, namely: fixed, sd, equal, pretty (default), quantile, kmeans, hclust, bclust, fisher, and jenks.\nTo define a data classification method, the style argument of tm_fill() or tm_polygons() will be used.\n\n\nThe code chunk below shows a jenks data classification that used 5 classes.\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\", \n          n=5,\n          style=\"jenks\") +\n  tm_borders(alpha=0.5)\n\n\n\n\nIn the code chunk below, equal data classification method is used.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\nNotice that the distribution of jenks data classification method are more evenly distributed then equal data classification method.\nComparing different data classification methods:\n\nsdequal and prettyquantile and kmeanshclust and bclustfisher and jenks\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"sd\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"pretty\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"kmeans\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"hclust\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"bclust\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\nCommittee Member: 1(1) 2(1) 3(1) 4(1) 5(1) 6(1) 7(1) 8(1) 9(1) 10(1)\nComputing Hierarchical Clustering\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"fisher\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"jenks\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\nComparing different number of classes using kmeans data classification method:\n\nNumber of classes = 2Number of classes = 6Number of classes = 10Number of classes = 20\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 2,\n          style = \"kmeans\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 6,\n          style = \"kmeans\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 10,\n          style = \"kmeans\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 20,\n          style = \"kmeans\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\nFor all the built-in styles, the category breaks are computed internally. In order to override these defaults, the breakpoints can be set explicitly by means of the breaks argument to the tm_fill(). It is important to note that, in tmap the breaks include a minimum and maximum. As a result, in order to end up with n categories, n+1 elements must be specified in the breaks option (the values must be in increasing order).\nBefore we get started, it is always a good practice to get some descriptive statistics on the variable before setting the break points. Code chunk below will be used to compute and display the descriptive statistics of DEPENDENCY field.\n\nsummary(mpsz_pop2020$DEPENDENCY)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n 0.1111  0.7147  0.7866  0.8585  0.8763 19.0000      92 \n\n\nWith reference to the results above, we set break point at 0.60, 0.70, 0.80, and 0.90. In addition, we also need to include a minimum and maximum, which we set at 0 and 100. Our breaks vector is thus c(0, 0.60, 0.70, 0.80, 0.90, 100)\nNow, we will plot the choropleth map by using the code chunk below.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          breaks = c(0, 0.60, 0.70, 0.80, 0.90, 100)) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\ntmap supports colour ramps either defined by the user or a set of predefined colour ramps from the RColorBrewer package.\n\n\nTo change the colour, we assign the preferred colour to palette argument of tm_fill() as shown in the code chunk below.\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          n=6,\n          style=\"quantile\",\n          palette=\"Blues\") +\n  tm_borders(alpha=0.5)\n\n\n\n\nNotice that the choropleth map is shaded in blue.’\nTo reverse the colour shading, add a “-” prefix.\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          n=6,\n          style=\"quantile\",\n          palette=\"-Greens\") +\n  tm_borders(alpha=0.5)\n\n\n\n\nNotice that the colour scheme has been reversed.\n\n\n\n\nMap layout refers to the combination of all map elements into a cohensive map. Map elements include among others the objects to be mapped, the title, the scale bar, the compass, margins and aspects ratios. Colour settings and data classification methods covered in the previous section relate to the palette and break-points are used to affect how the map looks.\n\n\nIn tmap, several legend options are provided to change the placement, format and appearance of the legend.\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          style=\"jenks\",\n          palette=\"Blues\",\n          legend.hist=T,\n          legend.is.portrait = T,\n          legend.hist.z = 0.1) +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone \\n(Jenks classification)\",\n            main.title.position = \"center\",\n            main.title.size = 1,\n            legend.height = 0.45,\n            legend.width = 0.35,\n            legend.outside = F,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = F) +\n  tm_borders(alpha=0.5)\n\n\n\n\n\n\n\ntmap allows a wide variety of layout settings to be changed. They can be called by using tmap_style().\nThe code chunk below shows the classic style is used.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"classic\")\n\n\n\n\n\n\n\nBeside map style, tmap also also provides arguments to draw other map furniture such as compass, scale bar and grid lines.\nIn the code chunk below, tm_compass(), tm_scale_bar() and tm_grid() are used to add compass, scale bar and grid lines onto the choropleth map.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"No. of persons\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio \\nby planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar(width = 0.15) +\n  tm_grid(lwd = 0.1, alpha = 0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\")) +\n  tmap_style(\"white\")\n\n\n\n\n\n\n\n\nSmall multiple maps, also referred to as facet maps, are composed of many maps arrange side-by-side, and sometimes stacked vertically. Small multiple maps enable the visualisation of how spatial relationships change with respect to another variable, such as time.\nIn tmap, small multiple maps can be plotted in three ways:\n\nby assigning multiple values to at least one of the asthetic arguments,\nby defining a group-by variable in tm_facets(), and\nby creating multiple stand-alone maps with tmap_arrange().\n\n\n\nIn this example, small multiple choropleth maps are created by defining ncols in tm_fill()\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(c(\"YOUNG\", \"AGED\"),\n          style = \"equal\",\n          palette = \"Blues\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\")) +\n  tm_borders(alpha=0.5) +\n  tmap_style(\"white\")\n\n\n\n\nIn this example, small multiple choropleth maps are created by assigning multiple values to at least one of the aesthetic arguments\n\ntm_shape(mpsz_pop2020)+ \n  tm_polygons(c(\"DEPENDENCY\",\"AGED\"),\n          style = c(\"equal\", \"quantile\"), \n          palette = list(\"Blues\",\"Greens\")) +\n  tm_layout(legend.position = c(\"right\", \"bottom\"))\n\n\n\n\n\n\n\nIn this example, multiple small choropleth maps are created by using tm_facets().\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"Blues\",\n          thres.poly = 0) + \n  tm_facets(by=\"REGION_N\", \n            free.coords=TRUE, \n            drop.shapes=FALSE) +\n  tm_layout(legend.show = FALSE,\n            title.position = c(\"center\", \"center\"), \n            title.size = 20) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\nIn this example, multiple small choropleth maps are created by creating multiple stand-alone maps with tmap_arrange().\n\nyoungmap &lt;- tm_shape(mpsz_pop2020) +\n  tm_polygons(\"YOUNG\",\n              style=\"quantile\",\n              palette=\"Blues\")\n\nagedmap &lt;- tm_shape(mpsz_pop2020) +\n  tm_polygons(\"AGED\",\n              style=\"quantile\",\n              palette=\"Blues\")\n\ntmap_arrange(youngmap, agedmap, asp=1, ncol=2)\n\n\n\n\n\n\n\n\nInstead of creating small multiple choropleth map, you can also use selection funtion to map spatial objects meeting the selection criterion.\n\ntm_shape(mpsz_pop2020[mpsz_pop2020$REGION_N==\"CENTRAL REGION\", ]) +\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(legend.outside = TRUE,\n            legend.height = 0.45, \n            legend.width = 5.0,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha=0.5)\n\n\n\n\n\n\n\n\n\n\n\ntmap: Thematic Maps in R\ntmap\ntmap: get started!\ntmap: changes in version 2.0\ntmap: creating thematic maps in a flexible way (useR!2015)\nExploring and presenting maps with tmap (useR!2017)\n\n\n\n\n\nsf: Simple Features for R\nSimple Features for R: StandardizedSupport for Spatial Vector Data\nReading, Writing and Converting Simple Features\n\n\n\n\n\ndplyr\nTidy data\ntidyr: Easily Tidy Data with ‘spread()’ and ‘gather()’ Functions"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07a/Hands-on_Ex07a.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex07a/Hands-on_Ex07a.html#overview",
    "title": "Hands-on Exercise 7a",
    "section": "",
    "text": "Choropleth mapping involves the symbolisation of enumeration units, such as countries, provinces, states, counties or census units, using area patterns or graduated colors. For example, a social scientist may need to use a choropleth map to portray the spatial distribution of aged population of Singapore by Master Plan 2014 Subzone Boundary.\nIn this chapter, you will learn how to plot functional and truthful choropleth maps by using an R package called tmap package.\n\n\n\n\n\n\nTip\n\n\n\nIt is advisable for you to read the functional description of each function before using them."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07a/Hands-on_Ex07a.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex07a/Hands-on_Ex07a.html#getting-started",
    "title": "Hands-on Exercise 7a",
    "section": "",
    "text": "In this hands-on exercise, the key R package use is tmap package in R. Beside tmap package, four other R packages will be used. They are:\n\nreadr for importing delimited text file,\ntidyr for tidying data,\ndplyr for wrangling data and\nsf for handling geospatial data.\n\nAmong the four packages, readr, tidyr and dplyr are part of tidyverse package.\nThe code chunk below will be used to install and load these packages in RStudio.\n\npacman::p_load(sf, tmap, tidyverse)\n\n\n\n\n\n\n\nNote\n\n\n\nNotice that, we only need to install tidyverse instead of readr, tidyr and dplyr individually."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07a/Hands-on_Ex07a.html#importing-data-into-r",
    "href": "Hands-on_Ex/Hands-on_Ex07a/Hands-on_Ex07a.html#importing-data-into-r",
    "title": "Hands-on Exercise 7a",
    "section": "",
    "text": "Two data set will be used to create the choropleth map. They are:\n\nMaster Plan 2014 Subzone Boundary (Web) (i.e. MP14_SUBZONE_WEB_PL) in ESRI shapefile format. It can be downloaded at data.gov.sg This is a geospatial data. It consists of the geographical boundary of Singapore at the planning subzone level. The data is based on URA Master Plan 2014.\nSingapore Residents by Planning Area / Subzone, Age Group, Sex and Type of Dwelling, June 2011-2020 in csv format (i.e. respopagesextod2011to2020.csv). This is an aspatial data fie. It can be downloaded at Department of Statistics, Singapore Although it does not contain any coordinates values, but it’s PA and SZ fields can be used as unique identifiers to geocode to MP14_SUBZONE_WEB_PL shapefile.\n\n\n\n\nThe code chunk below uses the st_read() function of sf package to import MP14_SUBZONE_WEB_PL shapefile into R as a simple feature data frame called mpsz.\n\nmpsz &lt;- st_read(dsn = \"data/geospatial\", \n                layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\weimingfu\\ISSS608-VAA\\Hands-on_Ex\\Hands-on_Ex07a\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nYou can examine the content of mpsz by using the code chunk below.\n\nmpsz\n\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 10 features:\n   OBJECTID SUBZONE_NO       SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1         1          1    MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2         2          1    PEARL'S HILL    OTSZ01      Y          OUTRAM\n3         3          3       BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4         4          8  HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5         5          3         REDHILL    BMSZ03      N     BUKIT MERAH\n6         6          7  ALEXANDRA HILL    BMSZ07      N     BUKIT MERAH\n7         7          9   BUKIT HO SWEE    BMSZ09      N     BUKIT MERAH\n8         8          2     CLARKE QUAY    SRSZ02      Y SINGAPORE RIVER\n9         9         13 PASIR PANJANG 1    QTSZ13      N      QUEENSTOWN\n10       10          7       QUEENSWAY    QTSZ07      N      QUEENSTOWN\n   PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1          MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2          OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3          SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4          BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5          BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n6          BM CENTRAL REGION       CR 9D286521EF5E3B59 2014-12-05 25358.82\n7          BM CENTRAL REGION       CR 7839A8577144EFE2 2014-12-05 27680.06\n8          SR CENTRAL REGION       CR 48661DC0FBA09F7A 2014-12-05 29253.21\n9          QT CENTRAL REGION       CR 1F721290C421BFAB 2014-12-05 22077.34\n10         QT CENTRAL REGION       CR 3580D2AFFBEE914C 2014-12-05 24168.31\n     Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1  29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2  29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3  29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4  29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5  30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n6  29991.38   4428.913  1030378.8 MULTIPOLYGON (((25899.7 297...\n7  30230.86   3275.312   551732.0 MULTIPOLYGON (((27746.95 30...\n8  30222.86   2208.619   290184.7 MULTIPOLYGON (((29351.26 29...\n9  29893.78   6571.323  1084792.3 MULTIPOLYGON (((20996.49 30...\n10 30104.18   3454.239   631644.3 MULTIPOLYGON (((24472.11 29...\n\n\nNotice that only the first ten records will be displayed. Do you know why?\nIn R, when you view a simple feature dataframe (sf dataframe) using the default print method, typically only the first 10 records are shown. This is a default behavior designed to give you a quick overview of your data without overwhelming you with too much information, especially for large datasets.\n\n\n\nNext, we will import respopagsex2011to2020.csv file into RStudio and save the file into an R dataframe called popagsex.\nThe task will be performed by using read_csv() function of readr package as shown in the code chunk below.\n\npopdata &lt;- read_csv(\"data/aspatial/respopagesextod2011to2020.csv\")\n\n\n\n\nBefore a thematic map can be prepared, you are required to prepare a data table with year 2020 values. The data table should include the variables PA, SZ, YOUNG, ECONOMY ACTIVE, AGED, TOTAL, DEPENDENCY.\n\nYOUNG: age group 0 to 4 until age groyup 20 to 24,\nECONOMY ACTIVE: age group 25-29 until age group 60-64,\nAGED: age group 65 and above,\nTOTAL: all age group, and\nDEPENDENCY: the ratio between young and aged against economy active group\n\n\n\nThe following data wrangling and transformation functions will be used:\n\npivot_wider() of tidyr package, and\nmutate(), filter(), group_by() and select() of dplyr package\n\n\npopdata2020 &lt;- popdata %&gt;% \n  filter(Time == 2020) %&gt;% \n  group_by(PA, SZ, AG) %&gt;% \n  summarise(`POP` = sum(`Pop`)) %&gt;% \n  ungroup() %&gt;% \n  pivot_wider(names_from = AG,\n              values_from = POP) %&gt;% \n  mutate(`YOUNG` = rowSums(.[3:6]) + rowSums(.[12])) %&gt;% \n  mutate(`ECONOMY ACTIVE` = rowSums(.[7:11]) + rowSums(.[13:15])) %&gt;% \n  mutate(`AGED`=rowSums(.[16:21])) %&gt;% \n  mutate(`TOTAL`=rowSums(.[3:21])) %&gt;% \n  mutate(`DEPENDENCY` = (`YOUNG` + `AGED`)/`ECONOMY ACTIVE`) %&gt;% \n  select(`PA`, `SZ`, `YOUNG`, `ECONOMY ACTIVE`, `AGED`, `TOTAL`, `DEPENDENCY`)\n\n\n\n\nBefore we can perform the georelational join, one extra step is required to convert the values in PA and SZ fields to uppercase. This is because the values of PA and SZ fields are made up of upper- and lowercase. On the other, hand the SUBZONE_N and PLN_AREA_N are in uppercase.\n\npopdata2020 &lt;- popdata2020 %&gt;% \n  mutate_at(.vars = vars(PA,SZ),\n            .funs = funs(toupper)) %&gt;% \n  filter(`ECONOMY ACTIVE` &gt; 0)\n\nNext, left_join() of dplyr is used to join the geographical data and attribute table using planning subzone name e.g. SUBZONE_N and SZ as the common identifier.\n\nmpsz_pop2020 &lt;- left_join(mpsz, popdata2020,\n                          by = c(\"SUBZONE_N\" = \"SZ\"))\n\nThing to learn from the code chunk above:\n\nleft_join() of dplyr package is used with mpsz simple feature data frame as the left data table is to ensure that the output will be a simple features data frame.\n\n\nwrite_rds(mpsz_pop2020, \"data/rds/mpszpop2020.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07a/Hands-on_Ex07a.html#choropleth-mapping-geospatial-data-using-tmap",
    "href": "Hands-on_Ex/Hands-on_Ex07a/Hands-on_Ex07a.html#choropleth-mapping-geospatial-data-using-tmap",
    "title": "Hands-on Exercise 7a",
    "section": "",
    "text": "Two approaches can be used to prepare thematic map using tmap, they are:\n\nPlotting a thematic map quickly by using qtm().\nPlotting highly customisable thematic map by using tmap elements.\n\n\n\nThe easiest and quickest to draw a choropleth map using tmap is using qtm(). It is concise and provides a good default visualisation in many cases.\nThe code chunk below will draw a cartographic standard choropleth map as shown below.\n\ntmap_mode(\"plot\")\nqtm(mpsz_pop2020, \n    fill = \"DEPENDENCY\")\n\n\n\n\nThings to learn from the code chunk above:\n\ntmap_mode() with “plot” option is used to produce a static map. For interactive mode, “view” option should be used.\nfill argument is used to map the attribute (i.e. DEPENDENCY)\n\n\n\n\nDespite its usefulness of drawing a choropleth map quickly and easily, the disadvantge of qtm() is that it makes aesthetics of individual layers harder to control. To draw a high quality cartographic choropleth map as shown in the figure below, tmap’s drawing elements should be used.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          style=\"quantile\",\n          palette=\"Blues\",\n          title=\"Dependency ratio\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45,\n            legend.width = 0.35,\n            frame = T) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size=2) +\n  tm_scale_bar() +\n  tm_grid(alpha=0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\",\n             position = c(\"left\", \"bottom\"))\n\n\n\n\nIn the following sub-section, we will share with you tmap functions that used to plot these elements.\n\n\nThe basic building block of tmap is tm_shape() followed by one or more layer elemments such as tm_fill() and tm_polygons().\nIn the code chunk below, tm_shape() is used to define the input data (i.e mpsz_pop2020) and tm_polygons() is used to draw the planning subzone polygons\n\ntm_shape(mpsz_pop2020) +\n  tm_polygons()\n\n\n\n\n\n\n\nTo draw a choropleth map showing the geographical distribution of a selected variable by planning subzone, we just need to assign the target variable such as Dependency to tm_polygons().\n\ntm_shape(mpsz_pop2020) +\n  tm_polygons(\"DEPENDENCY\")\n\n\n\n\nThings to learn from tm_polygons():\n\nThe default interval binning used to draw the choropleth map is called “pretty”. A detailed discussion of the data classification methods supported by tmap will be provided in sub-section 4.3.\nThe default colour scheme used is YlOrRd of ColorBrewer. You will learn more about the color scheme in sub-section 4.4.\nBy default, Missing value will be shaded in grey.\n\n\n\n\nActually, tm_polygons() is a wraper of tm_fill() and tm_border(). tm_fill() shades the polygons by using the default colour scheme and tm_borders() adds the borders of the shapefile onto the choropleth map.\nThe code chunk below draws a choropleth map by using tm_fill() alone.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\")\n\n\n\n\nNotice that the planning subzones are shared according to the respective dependecy values\nTo add the boundary of the planning subzones, tm_borders will be used as shown in the code chunk below.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\") +\n  tm_borders(lwd = 0.1,  alpha = 1)\n\n\n\n\nNotice that light-gray border lines have been added on the choropleth map.\nThe alpha argument is used to define transparency number between 0 (totally transparent) and 1 (not transparent). By default, the alpha value of the col is used (normally 1).\nBeside alpha argument, there are three other arguments for tm_borders(), they are:\n\ncol = border colour,\nlwd = border line width. The default is 1, and\nlty = border line type. The default is “solid”.\n\n\n\n\n\nMost choropleth maps employ some methods of data classification. The point of classification is to take a large number of observations and group them into data ranges or classes.\ntmap provides a total ten data classification methods, namely: fixed, sd, equal, pretty (default), quantile, kmeans, hclust, bclust, fisher, and jenks.\nTo define a data classification method, the style argument of tm_fill() or tm_polygons() will be used.\n\n\nThe code chunk below shows a jenks data classification that used 5 classes.\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\", \n          n=5,\n          style=\"jenks\") +\n  tm_borders(alpha=0.5)\n\n\n\n\nIn the code chunk below, equal data classification method is used.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\nNotice that the distribution of jenks data classification method are more evenly distributed then equal data classification method.\nComparing different data classification methods:\n\nsdequal and prettyquantile and kmeanshclust and bclustfisher and jenks\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"sd\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"pretty\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"kmeans\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"hclust\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"bclust\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\nCommittee Member: 1(1) 2(1) 3(1) 4(1) 5(1) 6(1) 7(1) 8(1) 9(1) 10(1)\nComputing Hierarchical Clustering\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"fisher\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"jenks\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\nComparing different number of classes using kmeans data classification method:\n\nNumber of classes = 2Number of classes = 6Number of classes = 10Number of classes = 20\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 2,\n          style = \"kmeans\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 6,\n          style = \"kmeans\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 10,\n          style = \"kmeans\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 20,\n          style = \"kmeans\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\nFor all the built-in styles, the category breaks are computed internally. In order to override these defaults, the breakpoints can be set explicitly by means of the breaks argument to the tm_fill(). It is important to note that, in tmap the breaks include a minimum and maximum. As a result, in order to end up with n categories, n+1 elements must be specified in the breaks option (the values must be in increasing order).\nBefore we get started, it is always a good practice to get some descriptive statistics on the variable before setting the break points. Code chunk below will be used to compute and display the descriptive statistics of DEPENDENCY field.\n\nsummary(mpsz_pop2020$DEPENDENCY)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n 0.1111  0.7147  0.7866  0.8585  0.8763 19.0000      92 \n\n\nWith reference to the results above, we set break point at 0.60, 0.70, 0.80, and 0.90. In addition, we also need to include a minimum and maximum, which we set at 0 and 100. Our breaks vector is thus c(0, 0.60, 0.70, 0.80, 0.90, 100)\nNow, we will plot the choropleth map by using the code chunk below.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          breaks = c(0, 0.60, 0.70, 0.80, 0.90, 100)) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\ntmap supports colour ramps either defined by the user or a set of predefined colour ramps from the RColorBrewer package.\n\n\nTo change the colour, we assign the preferred colour to palette argument of tm_fill() as shown in the code chunk below.\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          n=6,\n          style=\"quantile\",\n          palette=\"Blues\") +\n  tm_borders(alpha=0.5)\n\n\n\n\nNotice that the choropleth map is shaded in blue.’\nTo reverse the colour shading, add a “-” prefix.\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          n=6,\n          style=\"quantile\",\n          palette=\"-Greens\") +\n  tm_borders(alpha=0.5)\n\n\n\n\nNotice that the colour scheme has been reversed.\n\n\n\n\nMap layout refers to the combination of all map elements into a cohensive map. Map elements include among others the objects to be mapped, the title, the scale bar, the compass, margins and aspects ratios. Colour settings and data classification methods covered in the previous section relate to the palette and break-points are used to affect how the map looks.\n\n\nIn tmap, several legend options are provided to change the placement, format and appearance of the legend.\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          style=\"jenks\",\n          palette=\"Blues\",\n          legend.hist=T,\n          legend.is.portrait = T,\n          legend.hist.z = 0.1) +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone \\n(Jenks classification)\",\n            main.title.position = \"center\",\n            main.title.size = 1,\n            legend.height = 0.45,\n            legend.width = 0.35,\n            legend.outside = F,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = F) +\n  tm_borders(alpha=0.5)\n\n\n\n\n\n\n\ntmap allows a wide variety of layout settings to be changed. They can be called by using tmap_style().\nThe code chunk below shows the classic style is used.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"classic\")\n\n\n\n\n\n\n\nBeside map style, tmap also also provides arguments to draw other map furniture such as compass, scale bar and grid lines.\nIn the code chunk below, tm_compass(), tm_scale_bar() and tm_grid() are used to add compass, scale bar and grid lines onto the choropleth map.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"No. of persons\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio \\nby planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar(width = 0.15) +\n  tm_grid(lwd = 0.1, alpha = 0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\")) +\n  tmap_style(\"white\")\n\n\n\n\n\n\n\n\nSmall multiple maps, also referred to as facet maps, are composed of many maps arrange side-by-side, and sometimes stacked vertically. Small multiple maps enable the visualisation of how spatial relationships change with respect to another variable, such as time.\nIn tmap, small multiple maps can be plotted in three ways:\n\nby assigning multiple values to at least one of the asthetic arguments,\nby defining a group-by variable in tm_facets(), and\nby creating multiple stand-alone maps with tmap_arrange().\n\n\n\nIn this example, small multiple choropleth maps are created by defining ncols in tm_fill()\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(c(\"YOUNG\", \"AGED\"),\n          style = \"equal\",\n          palette = \"Blues\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\")) +\n  tm_borders(alpha=0.5) +\n  tmap_style(\"white\")\n\n\n\n\nIn this example, small multiple choropleth maps are created by assigning multiple values to at least one of the aesthetic arguments\n\ntm_shape(mpsz_pop2020)+ \n  tm_polygons(c(\"DEPENDENCY\",\"AGED\"),\n          style = c(\"equal\", \"quantile\"), \n          palette = list(\"Blues\",\"Greens\")) +\n  tm_layout(legend.position = c(\"right\", \"bottom\"))\n\n\n\n\n\n\n\nIn this example, multiple small choropleth maps are created by using tm_facets().\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"Blues\",\n          thres.poly = 0) + \n  tm_facets(by=\"REGION_N\", \n            free.coords=TRUE, \n            drop.shapes=FALSE) +\n  tm_layout(legend.show = FALSE,\n            title.position = c(\"center\", \"center\"), \n            title.size = 20) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\nIn this example, multiple small choropleth maps are created by creating multiple stand-alone maps with tmap_arrange().\n\nyoungmap &lt;- tm_shape(mpsz_pop2020) +\n  tm_polygons(\"YOUNG\",\n              style=\"quantile\",\n              palette=\"Blues\")\n\nagedmap &lt;- tm_shape(mpsz_pop2020) +\n  tm_polygons(\"AGED\",\n              style=\"quantile\",\n              palette=\"Blues\")\n\ntmap_arrange(youngmap, agedmap, asp=1, ncol=2)\n\n\n\n\n\n\n\n\nInstead of creating small multiple choropleth map, you can also use selection funtion to map spatial objects meeting the selection criterion.\n\ntm_shape(mpsz_pop2020[mpsz_pop2020$REGION_N==\"CENTRAL REGION\", ]) +\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(legend.outside = TRUE,\n            legend.height = 0.45, \n            legend.width = 5.0,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha=0.5)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07a/Hands-on_Ex07a.html#reference",
    "href": "Hands-on_Ex/Hands-on_Ex07a/Hands-on_Ex07a.html#reference",
    "title": "Hands-on Exercise 7a",
    "section": "",
    "text": "tmap: Thematic Maps in R\ntmap\ntmap: get started!\ntmap: changes in version 2.0\ntmap: creating thematic maps in a flexible way (useR!2015)\nExploring and presenting maps with tmap (useR!2017)\n\n\n\n\n\nsf: Simple Features for R\nSimple Features for R: StandardizedSupport for Spatial Vector Data\nReading, Writing and Converting Simple Features\n\n\n\n\n\ndplyr\nTidy data\ntidyr: Easily Tidy Data with ‘spread()’ and ‘gather()’ Functions"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07c/Hands-on_Ex07c.html",
    "href": "Hands-on_Ex/Hands-on_Ex07c/Hands-on_Ex07c.html",
    "title": "Hands-on Exercise 7c",
    "section": "",
    "text": "In this in-class exercise, you will gain hands-on experience on using appropriate R methods to plot analytical maps.\n\n\n\nBy the end of this in-class exercise, you will be able to use appropriate functions of tmap and tidyverse to perform the following tasks:\n\nImporting geospatial data in rds format into R environment.\nCreating cartographic quality choropleth maps by using appropriate tmap functions.\nCreating rate map\nCreating percentile map\nCreating boxmap\n\n\n\n\n\n\n\n\npacman::p_load(sf, tmap, tidyverse)\n\n\n\n\nFor the purpose of this hands-on exercise, a prepared data set called NGA_wp.rds will be used. The data set is a polygon feature data.frame providing information on water point of Nigeria at the LGA level. You can find the data set in the rds sub-direct of the hands-on data folder.\n\nNGA_wp &lt;- read_rds(\"data/rds/NGA_wp.rds\")\n\n\n\n\n\n\n\n\np1 &lt;-  tm_shape(NGA_wp) +\n  tm_fill(\"wp_functional\",\n          n=10,\n          stype=\"equal\",\n          palette=\"Blues\") +\n  tm_borders(lwd=0.1,\n             alpha=1) +\n  tm_layout(main.title = \"Distribution of functional water point by LGAs\",\n            legend.outside=F)\n\np2 &lt;-  tm_shape(NGA_wp) +\n  tm_fill(\"total_wp\",\n          n=10,\n          stype=\"equal\",\n          palette=\"Blues\") +\n  tm_borders(lwd=0.1,\n             alpha=1) +\n  tm_layout(main.title = \"Distribution of total water point by LGAs\",\n            legend.outside=F)\n\n\ntmap_arrange(p2, p1, nrow=1)\n\n\n\n\n\np3 &lt;- tm_shape(NGA_wp) +\n  tm_fill(\"wp_nonfunctional\",\n          n=10,\n          stype=\"equal\",\n          palette=\"Greens\") +\n  tm_borders(lwd=0.1,\n             alpha=1) +\n  tm_layout(main.title = \"Distribution of non-functional water point by LGAs\",\n            legend.outside=F)\n\n\ntmap_arrange(p2, p3, nrow=1)\n\n\n\n\n\n\n\n\nIn much of our readings we have now seen the importance to map rates rather than counts of things, and that is for the simple reason that water points are not equally distributed in space. That means that if we do not account for how many water points are somewhere, we end up mapping total water point size rather than our topic of interest.\n\n\nWe will tabulate the proportion of functional water points and the proportion of non-functional water points in each LGA. In the following code chunk, mutate() from dplyr package is used to derive two fields, namely pct_functional and pct_nonfunctional.\n\nNGA_wp &lt;- NGA_wp %&gt;% \n  mutate(pct_functional = wp_functional/total_wp) %&gt;% \n  mutate(pct_nonfunctional = wp_nonfunctional/total_wp)\n\n\n\n\n\ntm_shape(NGA_wp) +\n  tm_fill(\"pct_functional\",\n          n=10,\n          stype=\"equal\",\n          palette=\"Greens\",\n          legend.hist = T)+\n  tm_borders(lwd=0.1,\n             alpha=1) +\n  tm_layout(main.title = \"Rate map of functional water point by LGAs\",\n            legend.outside=F)\n\n\n\n\n\n\n\n\nExtreme value maps are variations of common choropleth maps where the classification is designed to highlight extreme values at the lower and upper end of the scale, with the goal of identifying outliers. These maps were developed in the spirit of spatializing EDA, i.e., adding spatial features to commonly used approaches in non-spatial EDA (Anselin 1994).\n\n\nThe percentile map is a special type of quantile map with six specific categories: 0-1%,1-10%, 10-50%,50-90%,90-99%, and 99-100%. The corresponding breakpoints can be derived by means of the base R quantile command, passing an explicit vector of cumulative probabilities as c(0,.01,.1,.5,.9,.99,1). Note that the begin and endpoint need to be included.\n\n\nStep 1: Exclude records with NA by using the code chunk below.\n\nNGA_wp &lt;- NGA_wp %&gt;% \n  drop_na()\n\nStep 2: Creating customised classification and extracting values\n\npercent &lt;- c(0,.01,.1,.5,.9,.99,1)\nvar &lt;- NGA_wp[\"pct_functional\"] %&gt;% \n  st_set_geometry(NULL)\nquantile(var[,1], percent)\n\n       0%        1%       10%       50%       90%       99%      100% \n0.0000000 0.0000000 0.2169811 0.4791667 0.8611111 1.0000000 1.0000000 \n\n\n\n\n\n\n\n\nImportant\n\n\n\nWhen variables are extracted from an sf data.frame, the geometry is extracted as well. For mapping and spatial manipulation, this is the expected behavior, but many base R functions cannot deal with the geometry. Specifically, the quantile() gives an error. As a result st_set_geomtry(NULL) is used to drop geomtry field.\n\n\n\n\n\nWriting a function has three big advantages over using copy-and-paste:\n\nYou can give a function an evocative name that makes your code easier to understand.\nAs requirements change, you only need to update code in one place, instead of many.\nYou eliminate the chance of making incidental mistakes when you copy and paste (i.e. updating a variable name in one place, but not in another).\n\nSource: Chapter 19: Functions of R for Data Science.\n\n\n\nFirstly, we will write an R function as shown below to extract a variable (i.e. wp_nonfunctional) as a vector out of an sf data.frame.\n\narguments:\n\nvname: variable name (as character, in quotes)\ndf: name of sf data frame\n\nreturns:\n\nv: vector with values (without a column name)\n\n\n\nget.var &lt;- function(vname, df) {\n  v &lt;- df[vname] %&gt;% \n    st_set_geometry(NULL)\n  v &lt;- unname(v[,1])\n  return(v)\n}\n\n\n\n\nNext, we will write a percentile mapping function by using the code chunk below.\n\npercentmap &lt;- function(vnam, df, legtitle=NA, mtitle=\"Percentile Map\"){\n  percent &lt;- c(0,.01,.1,.5,.9,.99,1)\n  var &lt;- get.var(vnam, df)\n  bperc &lt;- quantile(var, percent)\n  tm_shape(df) +\n  tm_polygons() +\n  tm_shape(df) +\n     tm_fill(vnam,\n             title=legtitle,\n             breaks=bperc,\n             palette=\"Blues\",\n          labels=c(\"&lt; 1%\", \"1% - 10%\", \"10% - 50%\", \"50% - 90%\", \"90% - 99%\", \"&gt; 99%\"))  +\n  tm_borders() +\n  tm_layout(main.title = mtitle, \n            title.position = c(\"right\",\"bottom\"))\n}\n\n\n\n\nTo run the function, type the code chunk as shown below.\n\npercentmap(\"total_wp\", NGA_wp)\n\n\n\n\nNote that this is just a bare bones implementation. Additional arguments such as the title, legend positioning just to name a few of them, could be passed to customise various features of the map.\n\n\n\n\nIn essence, a box map is an augmented quartile map, with an additional lower and upper category. When there are lower outliers, then the starting point for the breaks is the minimum value, and the second break is the lower fence. In contrast, when there are no lower outliers, then the starting point for the breaks will be the lower fence, and the second break is the minimum value (there will be no observations that fall in the interval between the lower fence and the minimum value).\n\nggplot(data = NGA_wp,\n       aes(x = \"\",\n           y = wp_nonfunctional)) +\n  geom_boxplot()\n\n\n\n\n\nDisplaying summary statistics on a choropleth map by using the basic principles of boxplot.\nTo create a box map, a custom breaks specification will be used. However, there is a complication. The break points for the box map vary depending on whether lower or upper outliers are present.\n\n\n\nThe code chunk below is an R function that creating break points for a box map.\n\narguments:\n\nv: vector with observations\nmult: multiplier for IQR (default 1.5)\n\nreturns:\n\nbb: vector with 7 break points compute quartile and fences\n\n\n\nboxbreaks &lt;- function(v, mult=1.5) {\n  qv &lt;- unname(quantile(v))\n  iqr &lt;- qv[4] - qv[2]\n  upfence &lt;- qv[4] + mult * iqr\n  lofence &lt;- qv[2] - mult * iqr\n  #initialize break points vector\n  bb &lt;- vector(mode=\"numeric\", length=7)\n  #logic for lower and upper fences\n  if (lofence &lt; qv[1]) {  # no lower outliers\n    bb[1] &lt;- lofence\n    bb[2] &lt;- floor(qv[1])\n  } else {\n    bb[2] &lt;- lofence\n    bb[1] &lt;- qv[1]\n  }\n  if (upfence &gt; qv[5]) {  # no upper outliers\n    bb[7] &lt;- upfence\n    bb[6] &lt;- ceiling(qv[5])\n  } else {\n    bb[6] &lt;- upfence\n    bb[7] &lt;- qv[5]\n  }\n  bb[3:5] &lt;- qv[2:4]\n  return(bb)\n}\n\n\n\n\nThe code chunk below is an R function to extract a variable as a vector out of an sf data frame.\n\narguments:\n\nvname: variable name (as character, in quotes)\ndf: name of sf data frame\n\nreturns:\n\nv: vector with values (without a column name)\n\n\n\nget.var &lt;- function(vname,df) {\n  v &lt;- df[vname] %&gt;% st_set_geometry(NULL)\n  v &lt;- unname(v[,1])\n  return(v)\n}\n\n\n\n\nLet’s test the newly created function\n\nvar &lt;- get.var(\"wp_nonfunctional\", NGA_wp) \nboxbreaks(var)\n\n[1] -56.5   0.0  14.0  34.0  61.0 131.5 278.0\n\n\n\n\n\nThe code chunk below is an R function to create a box map. - arguments: - vnam: variable name (as character, in quotes) - df: simple features polygon layer - legtitle: legend title - mtitle: map title - mult: multiplier for IQR - returns: - a tmap-element (plots a map)\n\nboxmap &lt;- function(vnam, df,\n                   legtitle=NA,\n                   mtitle=\"Box Map\",\n                   mult=1.5) {\n  var &lt;- get.var(vnam, df)\n  bb &lt;- boxbreaks(var)\n  tm_shape(df) +\n    tm_polygons() +\n    tm_shape(df) +\n    tm_fill(vnam, title=legtitle,\n            breaks=bb,\n            palette=\"Blues\",\n            labels=c(\"lower outlier\",\"&lt;25%\",\"25%-50%\",\"50%-75%\",\"&gt;75%\",\"upper outlier\")) +\n    tm_borders() +\n    tm_layout(main.title = mtitle,\n              title.position = c(\"left\", \"top\"))\n}\n\n\ntmap_mode(\"plot\")\nboxmap(\"wp_nonfunctional\", NGA_wp)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07c/Hands-on_Ex07c.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex07c/Hands-on_Ex07c.html#overview",
    "title": "Hands-on Exercise 7c",
    "section": "",
    "text": "In this in-class exercise, you will gain hands-on experience on using appropriate R methods to plot analytical maps.\n\n\n\nBy the end of this in-class exercise, you will be able to use appropriate functions of tmap and tidyverse to perform the following tasks:\n\nImporting geospatial data in rds format into R environment.\nCreating cartographic quality choropleth maps by using appropriate tmap functions.\nCreating rate map\nCreating percentile map\nCreating boxmap"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07c/Hands-on_Ex07c.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex07c/Hands-on_Ex07c.html#getting-started",
    "title": "Hands-on Exercise 7c",
    "section": "",
    "text": "pacman::p_load(sf, tmap, tidyverse)\n\n\n\n\nFor the purpose of this hands-on exercise, a prepared data set called NGA_wp.rds will be used. The data set is a polygon feature data.frame providing information on water point of Nigeria at the LGA level. You can find the data set in the rds sub-direct of the hands-on data folder.\n\nNGA_wp &lt;- read_rds(\"data/rds/NGA_wp.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07c/Hands-on_Ex07c.html#basic-choropleth-mapping",
    "href": "Hands-on_Ex/Hands-on_Ex07c/Hands-on_Ex07c.html#basic-choropleth-mapping",
    "title": "Hands-on Exercise 7c",
    "section": "",
    "text": "p1 &lt;-  tm_shape(NGA_wp) +\n  tm_fill(\"wp_functional\",\n          n=10,\n          stype=\"equal\",\n          palette=\"Blues\") +\n  tm_borders(lwd=0.1,\n             alpha=1) +\n  tm_layout(main.title = \"Distribution of functional water point by LGAs\",\n            legend.outside=F)\n\np2 &lt;-  tm_shape(NGA_wp) +\n  tm_fill(\"total_wp\",\n          n=10,\n          stype=\"equal\",\n          palette=\"Blues\") +\n  tm_borders(lwd=0.1,\n             alpha=1) +\n  tm_layout(main.title = \"Distribution of total water point by LGAs\",\n            legend.outside=F)\n\n\ntmap_arrange(p2, p1, nrow=1)\n\n\n\n\n\np3 &lt;- tm_shape(NGA_wp) +\n  tm_fill(\"wp_nonfunctional\",\n          n=10,\n          stype=\"equal\",\n          palette=\"Greens\") +\n  tm_borders(lwd=0.1,\n             alpha=1) +\n  tm_layout(main.title = \"Distribution of non-functional water point by LGAs\",\n            legend.outside=F)\n\n\ntmap_arrange(p2, p3, nrow=1)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07c/Hands-on_Ex07c.html#choropleth-map-for-rates",
    "href": "Hands-on_Ex/Hands-on_Ex07c/Hands-on_Ex07c.html#choropleth-map-for-rates",
    "title": "Hands-on Exercise 7c",
    "section": "",
    "text": "In much of our readings we have now seen the importance to map rates rather than counts of things, and that is for the simple reason that water points are not equally distributed in space. That means that if we do not account for how many water points are somewhere, we end up mapping total water point size rather than our topic of interest.\n\n\nWe will tabulate the proportion of functional water points and the proportion of non-functional water points in each LGA. In the following code chunk, mutate() from dplyr package is used to derive two fields, namely pct_functional and pct_nonfunctional.\n\nNGA_wp &lt;- NGA_wp %&gt;% \n  mutate(pct_functional = wp_functional/total_wp) %&gt;% \n  mutate(pct_nonfunctional = wp_nonfunctional/total_wp)\n\n\n\n\n\ntm_shape(NGA_wp) +\n  tm_fill(\"pct_functional\",\n          n=10,\n          stype=\"equal\",\n          palette=\"Greens\",\n          legend.hist = T)+\n  tm_borders(lwd=0.1,\n             alpha=1) +\n  tm_layout(main.title = \"Rate map of functional water point by LGAs\",\n            legend.outside=F)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07c/Hands-on_Ex07c.html#extreme-value-maps",
    "href": "Hands-on_Ex/Hands-on_Ex07c/Hands-on_Ex07c.html#extreme-value-maps",
    "title": "Hands-on Exercise 7c",
    "section": "",
    "text": "Extreme value maps are variations of common choropleth maps where the classification is designed to highlight extreme values at the lower and upper end of the scale, with the goal of identifying outliers. These maps were developed in the spirit of spatializing EDA, i.e., adding spatial features to commonly used approaches in non-spatial EDA (Anselin 1994).\n\n\nThe percentile map is a special type of quantile map with six specific categories: 0-1%,1-10%, 10-50%,50-90%,90-99%, and 99-100%. The corresponding breakpoints can be derived by means of the base R quantile command, passing an explicit vector of cumulative probabilities as c(0,.01,.1,.5,.9,.99,1). Note that the begin and endpoint need to be included.\n\n\nStep 1: Exclude records with NA by using the code chunk below.\n\nNGA_wp &lt;- NGA_wp %&gt;% \n  drop_na()\n\nStep 2: Creating customised classification and extracting values\n\npercent &lt;- c(0,.01,.1,.5,.9,.99,1)\nvar &lt;- NGA_wp[\"pct_functional\"] %&gt;% \n  st_set_geometry(NULL)\nquantile(var[,1], percent)\n\n       0%        1%       10%       50%       90%       99%      100% \n0.0000000 0.0000000 0.2169811 0.4791667 0.8611111 1.0000000 1.0000000 \n\n\n\n\n\n\n\n\nImportant\n\n\n\nWhen variables are extracted from an sf data.frame, the geometry is extracted as well. For mapping and spatial manipulation, this is the expected behavior, but many base R functions cannot deal with the geometry. Specifically, the quantile() gives an error. As a result st_set_geomtry(NULL) is used to drop geomtry field.\n\n\n\n\n\nWriting a function has three big advantages over using copy-and-paste:\n\nYou can give a function an evocative name that makes your code easier to understand.\nAs requirements change, you only need to update code in one place, instead of many.\nYou eliminate the chance of making incidental mistakes when you copy and paste (i.e. updating a variable name in one place, but not in another).\n\nSource: Chapter 19: Functions of R for Data Science.\n\n\n\nFirstly, we will write an R function as shown below to extract a variable (i.e. wp_nonfunctional) as a vector out of an sf data.frame.\n\narguments:\n\nvname: variable name (as character, in quotes)\ndf: name of sf data frame\n\nreturns:\n\nv: vector with values (without a column name)\n\n\n\nget.var &lt;- function(vname, df) {\n  v &lt;- df[vname] %&gt;% \n    st_set_geometry(NULL)\n  v &lt;- unname(v[,1])\n  return(v)\n}\n\n\n\n\nNext, we will write a percentile mapping function by using the code chunk below.\n\npercentmap &lt;- function(vnam, df, legtitle=NA, mtitle=\"Percentile Map\"){\n  percent &lt;- c(0,.01,.1,.5,.9,.99,1)\n  var &lt;- get.var(vnam, df)\n  bperc &lt;- quantile(var, percent)\n  tm_shape(df) +\n  tm_polygons() +\n  tm_shape(df) +\n     tm_fill(vnam,\n             title=legtitle,\n             breaks=bperc,\n             palette=\"Blues\",\n          labels=c(\"&lt; 1%\", \"1% - 10%\", \"10% - 50%\", \"50% - 90%\", \"90% - 99%\", \"&gt; 99%\"))  +\n  tm_borders() +\n  tm_layout(main.title = mtitle, \n            title.position = c(\"right\",\"bottom\"))\n}\n\n\n\n\nTo run the function, type the code chunk as shown below.\n\npercentmap(\"total_wp\", NGA_wp)\n\n\n\n\nNote that this is just a bare bones implementation. Additional arguments such as the title, legend positioning just to name a few of them, could be passed to customise various features of the map.\n\n\n\n\nIn essence, a box map is an augmented quartile map, with an additional lower and upper category. When there are lower outliers, then the starting point for the breaks is the minimum value, and the second break is the lower fence. In contrast, when there are no lower outliers, then the starting point for the breaks will be the lower fence, and the second break is the minimum value (there will be no observations that fall in the interval between the lower fence and the minimum value).\n\nggplot(data = NGA_wp,\n       aes(x = \"\",\n           y = wp_nonfunctional)) +\n  geom_boxplot()\n\n\n\n\n\nDisplaying summary statistics on a choropleth map by using the basic principles of boxplot.\nTo create a box map, a custom breaks specification will be used. However, there is a complication. The break points for the box map vary depending on whether lower or upper outliers are present.\n\n\n\nThe code chunk below is an R function that creating break points for a box map.\n\narguments:\n\nv: vector with observations\nmult: multiplier for IQR (default 1.5)\n\nreturns:\n\nbb: vector with 7 break points compute quartile and fences\n\n\n\nboxbreaks &lt;- function(v, mult=1.5) {\n  qv &lt;- unname(quantile(v))\n  iqr &lt;- qv[4] - qv[2]\n  upfence &lt;- qv[4] + mult * iqr\n  lofence &lt;- qv[2] - mult * iqr\n  #initialize break points vector\n  bb &lt;- vector(mode=\"numeric\", length=7)\n  #logic for lower and upper fences\n  if (lofence &lt; qv[1]) {  # no lower outliers\n    bb[1] &lt;- lofence\n    bb[2] &lt;- floor(qv[1])\n  } else {\n    bb[2] &lt;- lofence\n    bb[1] &lt;- qv[1]\n  }\n  if (upfence &gt; qv[5]) {  # no upper outliers\n    bb[7] &lt;- upfence\n    bb[6] &lt;- ceiling(qv[5])\n  } else {\n    bb[6] &lt;- upfence\n    bb[7] &lt;- qv[5]\n  }\n  bb[3:5] &lt;- qv[2:4]\n  return(bb)\n}\n\n\n\n\nThe code chunk below is an R function to extract a variable as a vector out of an sf data frame.\n\narguments:\n\nvname: variable name (as character, in quotes)\ndf: name of sf data frame\n\nreturns:\n\nv: vector with values (without a column name)\n\n\n\nget.var &lt;- function(vname,df) {\n  v &lt;- df[vname] %&gt;% st_set_geometry(NULL)\n  v &lt;- unname(v[,1])\n  return(v)\n}\n\n\n\n\nLet’s test the newly created function\n\nvar &lt;- get.var(\"wp_nonfunctional\", NGA_wp) \nboxbreaks(var)\n\n[1] -56.5   0.0  14.0  34.0  61.0 131.5 278.0\n\n\n\n\n\nThe code chunk below is an R function to create a box map. - arguments: - vnam: variable name (as character, in quotes) - df: simple features polygon layer - legtitle: legend title - mtitle: map title - mult: multiplier for IQR - returns: - a tmap-element (plots a map)\n\nboxmap &lt;- function(vnam, df,\n                   legtitle=NA,\n                   mtitle=\"Box Map\",\n                   mult=1.5) {\n  var &lt;- get.var(vnam, df)\n  bb &lt;- boxbreaks(var)\n  tm_shape(df) +\n    tm_polygons() +\n    tm_shape(df) +\n    tm_fill(vnam, title=legtitle,\n            breaks=bb,\n            palette=\"Blues\",\n            labels=c(\"lower outlier\",\"&lt;25%\",\"25%-50%\",\"50%-75%\",\"&gt;75%\",\"upper outlier\")) +\n    tm_borders() +\n    tm_layout(main.title = mtitle,\n              title.position = c(\"left\", \"top\"))\n}\n\n\ntmap_mode(\"plot\")\nboxmap(\"wp_nonfunctional\", NGA_wp)"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Set Sail into the Adventures of ISSS608-VAA",
    "section": "",
    "text": "Welcome to ISSS608 Visual Analytics and Applications. In this website, you will find the “expeditions” which I have experienced for this course.\n\n“The greatest value of a picture is when it forces us to notice what we never expected to see.” -John Tukey\n\n\n\n\n\n\n\nSee my latest destinations……\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHands-on Exercise 7c\n\n\n\n\n\n\n\n\n\nFeb 22, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nHands-on Exercise 7a\n\n\n\n\n\n\n\n\n\nFeb 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nHands-on Exercise 7b\n\n\n\n\n\n\n\n\n\nFeb 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nBe Weatherwise or Otherwise\n\n\n\n\n\n\n\n\n\nFeb 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nHands-on Exercise 6\n\n\n\n\n\n\n\n\n\nFeb 14, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nHands-on Exercise 5e\n\n\n\n\n\n\n\n\n\nFeb 5, 2024\n\n\n\n\n\n\n\n\nNo matching items\n\n\n  \n\n Back to top"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html",
    "title": "DataViz Makeover of Take-Home Exercise 1",
    "section": "",
    "text": "In this take-home exercise, a Take-home Exercise 1 submission (original submission here) prepared by my classmate in ISSS608 AY 2023-24 Jan Term, was chosen for DataViz makeover. The submission was assessed in terms of both clarity and aesthetics, and a sketch of an alternative DataViz design was prepared using data visualisation design principles and best practices learnt in first 2 lessons. The alternative design was next implemented using R ggplot2, ggplot2 extensions and tidyverse packages."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#loading-r-packages",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#loading-r-packages",
    "title": "DataViz Makeover of Take-Home Exercise 1",
    "section": "2.1 Loading R packages",
    "text": "2.1 Loading R packages\nThe pacman::p_load() function is used to install and load the required R packages into the R environment, as below.\n\n\nCode\npacman::p_load(tidyverse, haven, ggrepel, patchwork, ggplot2, \n               ggthemes, hrbrthemes, dplyr, tidyr, knitr, ggridges, ggdist, ggstance)\n\n\nCompared to the original submission, these 2 additional package were loaded:\n\nggdist: an R package that provides a flexible set of ggplot2 geoms and stats for visualising distributions and uncertainties\nggstance: an R paclage that extends ggplot2 and provides the horizontal versions of ggplot2 geoms"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#importing-pisa-data",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#importing-pisa-data",
    "title": "DataViz Makeover of Take-Home Exercise 1",
    "section": "2.2 Importing PISA data",
    "text": "2.2 Importing PISA data\nTo reproduce the steps used in the original submission in preparing the dataset, the following code chunk uses the read_sas() of haven to import PISA data into R environment.\n\n\nCode\nstu_qqq &lt;- read_sas(\"data/cy08msp_stu_qqq.sas7bdat\")\n\n\nFiltering the entire data file for records belonging to Singapore students.\n\n\nCode\nstu_qqq_SG &lt;- stu_qqq %&gt;%\n  filter(CNT == \"SGP\")\n\n\nSaving the records belonging to Singapore students into “stu_qqq_SG.rds” file for easier loading (no need to extract the records from the entire dataset repeatedly).\n\n\nCode\nwrite_rds(stu_qqq_SG,\n          \"data/stu_qqq_SG.rds\")\n\n\nLoading the extract records from the saved “stu_qqq_SG.rds” file.\n\n\nCode\nsfu_qqq_SG &lt;- read_rds(\"data/stu_qqq_SG.rds\")\n\n\nFollowing code chunk uses select() to extract selected variables for further analyses.\n\n\nCode\nstu_qqq_SG_v2 &lt;- sfu_qqq_SG %&gt;%\n  select(CNTSTUID,PV1MATH,PV1READ,PV1SCIE,STRATUM,ST004D01T,ESCS) %&gt;%\n  rename(STUDENT_ID=CNTSTUID,\n         MATH=PV1MATH,\n         READING=PV1READ,\n         SCIENCE=PV1SCIE,\n         SCHOOL=STRATUM,\n         SOCIOECONOMIC_STATUS=ESCS,\n         GENDER=ST004D01T)\n\n\n\n\n\n\n\n\nOriginal Submission\n\n\n\nAccording to the original submission, only PV1 values were used for further analysis."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#data-wrangling",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#data-wrangling",
    "title": "DataViz Makeover of Take-Home Exercise 1",
    "section": "2.3 Data Wrangling",
    "text": "2.3 Data Wrangling\n\nRemove missing valuesRecoding and binning\n\n\nThe code chunk below uses to check missing values:\n\n\nCode\nsum(is.na(stu_qqq_SG_v2))\n\n\n[1] 47\n\n\nThe code chunk below uses drop_na() to remove missing values:\n\n\nCode\nstu_qqq_SG_v3 &lt;- stu_qqq_SG_v2 %&gt;%   \n  drop_na() \nsum(is.na(stu_qqq_SG_v3))\n\n\n[1] 0\n\n\n\n\nCode below use recode() to recode gender and nitle() to bin socioeconomic status\n\n\nCode\nstu_qqq_SG_final &lt;- stu_qqq_SG_v3 %&gt;%\n  mutate(GENDER = recode(GENDER,\n                         `1` = \"Female\",\n                         `2` = \"Male\"),\n         SCHOOL = recode(SCHOOL,\n                         \"SGP01\" = \"Public School\",\n                         \"SGP03\" = \"Private School\")) %&gt;%\n  mutate(SOCIOECONOMIC_STATUS = ntile(SOCIOECONOMIC_STATUS, 4), .after = SOCIOECONOMIC_STATUS) %&gt;%\n  mutate(SOCIOECONOMIC_STATUS = recode(SOCIOECONOMIC_STATUS,\n                                      `1` = \"Highly Disadvantaged\",\n                                      `2` = \"Disadvantaged\",\n                                      `3` = \"Advantaged\",\n                                      `4` = \"Highly Advantaged\")) %&gt;%\n  mutate(SOCIOECONOMIC_STATUS = factor(SOCIOECONOMIC_STATUS, \n                                      levels = c(\"Highly Disadvantaged\", \"Disadvantaged\", \n                                                 \"Advantaged\", \"Highly Advantaged\"),\n                                      ordered = TRUE))"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#final-dataset",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#final-dataset",
    "title": "DataViz Makeover of Take-Home Exercise 1",
    "section": "2.4 Final Dataset",
    "text": "2.4 Final Dataset\nThe final data is displayed by using knitr::kable() function.\n\n\nCode\nkable(head(stu_qqq_SG_final), \"simple\")\n\n\n\n\n\nSTUDENT_ID\nMATH\nREADING\nSCIENCE S\nCHOOL G\nENDER S\nOCIOECONOMIC_STATUS\n\n\n\n\n70200001\n639.004\n676.298\n710.634\nPublic School\nFemale\nDisadvantaged\n\n\n70200002\n697.191\n625.585\n670.646\nPublic School\nMale\nAdvantaged\n\n\n70200003\n693.710\n620.116\n666.095\nPublic School\nMale\nHighly Disadvantaged\n\n\n70200004\n427.317\n381.495\n340.308\nPublic School\nMale\nHighly Disadvantaged\n\n\n70200005\n436.462\n448.199\n456.333\nPublic School\nFemale\nDisadvantaged\n\n\n70200006\n569.982\n469.441\n475.158\nPublic School\nFemale\nDisadvantaged\n\n\n\n\n\n\n\n\n\n\n\nOriginal Submission\n\n\n\nVerified that sample data of final dataset is similar to that used in original submission."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#makeover-1-distribution-of-students-performance",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#makeover-1-distribution-of-students-performance",
    "title": "DataViz Makeover of Take-Home Exercise 1",
    "section": "3.1 Makeover 1: Distribution of Students’ Performance",
    "text": "3.1 Makeover 1: Distribution of Students’ Performance\n\n3.1.1 Original DataViz\n\nMATHREADINGSCIENCE\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n3.1.2 Critique\n\n\n\n\n\n\nClarity\n\n💚 Axes labeling is generally neat and clear, with similar x-axis and y-axis limits across the 3 plots. A small improvement can be achieved in rotating the y-axis label so that it is more readable.\n💚 Use of annotation and different colours to indicate the values of mean and median is clear.\n❌ Title of the plot can include an overview of key insights generated from the plot, rather than just showing the conventional description of the plot. A subtitle can also be used to provide more details on the insights. The original submission did not make use of a subtitle.\n❌ The distributions of the 3 domains are in separate plots on different tabs, as such, this makes any comparisons difficult.\n❌ The addition of geom_vlines for the mean and median values on a histogram may be confusing, that is, it does provide any further insights apart from comparing the values across the 3 plots, which can be better achieved if they were combined and stacked in a single plot. To similarly indicate these values on the plot, a better approach will be to use a box plot, which can provide more quantile values for analysis.\n\n\n\nAesthetics\n\n💚 Title position on the chart is aligned.\n💚 Use of different “soft” colours for different domains on different plots helps to make the plots less dull.\n❌ There seemed to be too much gridlines on the chart, which makes the chart area a bit busy. It would be better to use a theme that uses less gridlines.\n❌ Both the mean and median lines, though in dashed ‘-’ lines, are in darker colors than the plot, which may give an impression that the focus is on the 2 statistic values.\n\n\n\n\n\n\n3.1.3 Sketch of Makeover design\n\n\n\n\n\n\n\n3.1.4 Makeover DataViz\nThe code chunk below was used to provide the DataViz makeover to address the above critique:\n\n\nCode\nstu_viz1 &lt;- stu_qqq_SG_final %&gt;% \n  select(c(\"STUDENT_ID\", \"MATH\", \"READING\", \"SCIENCE\")) %&gt;% \n  pivot_longer(cols = c(\"MATH\", \"READING\", \"SCIENCE\"), names_to = \"Domain\", values_to = \"SCORE\")\n\npal &lt;- c(\"#159090\", \"#A034F0\", \"#FF8C00\" )\n\n# below chunk is for annotation\nannotate &lt;- data.frame(\n  label = c(paste(\"Median = \", toString(median(stu_qqq_SG_final$MATH))), \n            paste(\"Median = \", toString(median(stu_qqq_SG_final$READING))),\n            paste(\"Median = \", toString(median(stu_qqq_SG_final$SCIENCE)))),\n  Domain = c(\"MATH\", \"READING\", \"SCIENCE\"),\n  x = c(575, 550, 560),\n  y = c(300, 300, 300))\n\npp &lt;- ggplot(stu_viz1,\n       aes(x = SCORE,\n           y = 0,\n           fill = Domain)) +\n  geom_histogram(aes(y=after_stat(count)), bins = 25, alpha = 0.3, color = \"grey\") +\n  ggstance::geom_boxploth(width = 100,\n                          outlier.alpha = 0.4,\n                          alpha = 0.5) +\n  guides(fill=FALSE,\n         color=FALSE) + \n  scale_fill_manual(values = pal, guide = \"none\") +\n  labs(x=\"Domain Score\", \n       y=\"Count\") +\n  scale_y_continuous(limits = c(-50,1000)) +\n  facet_wrap(~Domain, nrow = 3, scales = \"free_y\", strip.position = \"top\") +\n  theme_bw() +\n  theme(strip.background = element_blank(),\n        strip.placement = \"outside\",\n        axis.title.y = element_text(angle=0, vjust = 0.5)) +\n  plot_annotation(title = \"Singapore students performed better in Math and Science than Reading\", subtitle = \"2022 PISA: Median performance for both Math and Science were higher than that for Reading, \\nbut differences are small\")\n\npp + geom_label(data = annotate,\n                mapping = aes(x=x, y=y, label=label),\n                size = 2.5,\n                fill = NA)\n\n\n\n\n\nImprovements from the makeover:\nClarity:\n\nTitle and subtitle used to provide meaningful context for the plot, so that the audience can better make their own interpretations and form their own insights.\nCombined the 3 separate plots into 1 plot, sharing the same x- and y-axis scale, so that easier visual comparisons can be made.\nInstead of showing the mean and median as vertical lines, a box plot is used to visualise the quantile values.\nThe clear annotation in original submission is retained.\n\nAesthetics:\n\nNumber of gridlines are reduced and ink reduced as well, so that they do not interfere too much with the important details on the plot.\ny-axis title is rotated for easier reading\nUse of soft colors which are friendly for people with colour-blindness for the histograms.\n\n\n\n\n\n\n\nAdditional Comments\n\n\n\nThe usage of a histogram follows the choice of the original designer, assuming that there is a reason for using a histogram. Another option would be to use a kernel density curve instead of a histogram, which will provide a smooth curve that estimates the frequency distribution without having to “bin” the data."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#makeover-2-performance-and-gender",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#makeover-2-performance-and-gender",
    "title": "DataViz Makeover of Take-Home Exercise 1",
    "section": "3.2 Makeover 2: Performance and Gender",
    "text": "3.2 Makeover 2: Performance and Gender\n\n3.2.1 Original DataViz\n\n\n\n\n\n\n\n3.2.2 Critique\n\n\n\n\n\n\nClarity\n\n💚 Placing the plots for the 3 domains one on top of the other is good, as it helps the viewer to make visual comparisons.\n❌ However, stacking the 2 density distributions for the 2 genders together on the same grid makes the plot difficult to read, as the 2 distributions are very similar and nearly overlap each other. A better plot would be to use the ridgeline plot.\n❌ Does not have a title and subtitle to provide context and/or insights derived from the visualisation.\n❌ The y-axis of the 3 plots are in different ranges, hence making them more difficult to be compared visually.\n\n\n\nAesthetics\n\n💚 Overall, the plot is neat and the information is shown in clear fonts and font sizes.\n💚 Use of different “soft” colours for different genders helps to make the plots less dull.\n❌ There seemed to be too much gridlines on the chart, which makes the chart area a bit busy. It would be better to use a theme that uses less gridlines. In this case, gridlines are more or less redundant.\n❌ The same legend is repeated 3 times, which is redundant.\n\n\n\n\n\n\n3.2.3 Sketch of Makeover design\n\n\n\n\n\n\n\n3.2.4 Makeover DataViz\nThe code chunk below was used to provide the DataViz makeover to address the above critique:\n\n\nCode\nstu_viz2 &lt;- stu_qqq_SG_final %&gt;% \n  select(c(\"STUDENT_ID\", \"MATH\", \"READING\", \"SCIENCE\", \"GENDER\")) %&gt;% \n  pivot_longer(cols = c(\"MATH\", \"READING\", \"SCIENCE\"), names_to = \"Domain\", values_to = \"SCORE\")\n\nstu_viz2[\"Gender_Domain\"] &lt;- paste0(stu_viz2$Domain, \" (\", stu_viz2$GENDER, \")\")\n\nggplot(stu_viz2,\n       aes(x=SCORE,\n           y=Gender_Domain,\n           fill=factor(stat(quantile)))) +\n  stat_density_ridges(\n    geom=\"density_ridges_gradient\",\n    calc_ecdf = T,\n    quantiles = 4,\n    quantile_lines = T) +\n  scale_fill_viridis_d(name = \"Quantiles\", alpha = 0.5,\n                       labels = c(\"(0,0.25]\",\n                                  \"(0.25,0.5]\",\n                                  \"(0.5, 0.75]\",\n                                  \"(0.75, 1]\")) +\n  labs(x = \"Domain score\",\n       y = \"Domain by \\nGender\") +\n  theme_ridges() +\n  theme(axis.title.y = element_text(angle = 0, hjust = 0.5),\n        axis.title.x = element_text(hjust = 0.5),\n        axis.text = element_text(size = 8, color = \"grey10\"),\n        text = element_text(size = 12, color = \"grey10\")) +\n  plot_annotation(title = \"Male students performed better in Math and Science\", subtitle = \"More male students obtained higher scores for Math and Science, while female students did \\nbetter in Reading\")\n\n\n\n\n\nImprovements from the makeover:\nClarity:\n\nRidgeline plot is used for visualising the 6 density distributions as it provides a good way to compare multiple distributions on the same plot.\nTitle and subtitle used to provide meaningful context for the plot, so that the audience can better make their own interpretations and form their own insights.\nSynchronised the y- and x-axis for all the plots for easier visual comparisons.\nAdded quantiles on the density curve so that finer comparisons can be made on quantile values.\n\nAesthetics:\n\nNumber of gridlines are reduced and ink reduced as well, so that they do not interfere too much with the important details on the plot.\ny-axis title is rotated for easier reading\nReduced the need for legend to show GENDER as this is already indicated on the Rigeline plot."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#makeover-3-performance-and-school-type",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#makeover-3-performance-and-school-type",
    "title": "DataViz Makeover of Take-Home Exercise 1",
    "section": "3.3 Makeover 3: Performance and School Type",
    "text": "3.3 Makeover 3: Performance and School Type\nFor this makeover, the original focused more on the Math performance, hence I have used the Math performance for my makeover too.\n\n3.3.1 Original DataViz\n\n\n\n\n\n\n\n3.2.2 Critique\n\n\n\n\n\n\nClarity\n\n💚 Individually, both the box plot and the density distribution of the Math score by school type are clear in showing the data.\n❌ However, they 2 plots are plotted separately. A better plot would be one where the boxplot is placed below each density curve, such as that of the raincloud plot.\n❌ Does not have a title and subtitle to provide context and/or insights derived from the visualisation.\n❌ The axes of the 2 plots are switched, hence making them more difficult to be compared visually.\n\n\n\nAesthetics\n\n💚 Overall, the individual plots are neat and the information is shown in clear fonts and font sizes.\n❌ x-axis ticks on the boxplot is redundant since x is a categorical variable.\n❌ The colours used in both plots are different, though there is not much reason for them to be different since both plots are referirng to the school type.\n❌ y-axis titles can be flipped for better readability.\n\n\n\n\n\n\n3.3.3 Sketch of Makeover design\n\n\n\n\n\n\n\n3.3.4 Makeover DataViz\nThe code chunk below was used to provide the DataViz makeover to address the above critique:\n\n\nCode\nstu_viz3 &lt;- stu_qqq_SG_final %&gt;% \n  select(c(\"STUDENT_ID\", \"MATH\", \"SCHOOL\"))\n\nggplot(stu_viz3,\n       aes(x=SCHOOL,\n           y=MATH)) +\n  stat_halfeye(adjust=0.5,\n               justification=-0.2,\n               .width=0,\n               point_colour = NA,\n               scale=0.4,\n               fill = \"blue\",\n               alpha = 0.4) +\n  geom_boxplot(width=.1,\n               outlier.alpha = 0.4,\n               outlier.color = \"blue\") +\n  stat_dots(side = \"left\",\n            justification = 1.1,\n            binwidth = unit(0.0022, \"npc\"),\n            dotsize = 1,\n            alpha = 0.4,\n            position = \"dodge\",\n            color = \"black\") +\n  labs(y=\"Math score\") +\n  coord_flip(xlim = c(1.4, 1.8)) +\n  theme_economist() +\n  theme(axis.title.y = element_blank(),\n        axis.title.x = element_text(color = \"grey30\")) +\n  plot_annotation(title = \"Private school students achieve better performance in PISA 2022\", subtitle = \"Deeper look suggests possible reason due to performance of public schools \\nbeing more disparate\")\n\n\n\n\n\nImprovements from the makeover:\nClarity:\n\nRaincloud plot is used as it allows for both the density curve and boxplot used in the original submission to be placed on the same plot.\nTitle and subtitle used to provide meaningful context for the plot, so that the audience can better make their own interpretations and form their own insights.\nSynchronised the y- and x-axis for all the plots for easier visual comparisons.\nThe dot plot that is added provided additional perspectives, e.g. showing that the number of private school students is much smaller than that of public school students.\n\nAesthetics:\n\nSynchronised the x-axis for easier comparisons.\nGridlines are removed since they are redundant in the raincloud plot."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#makeover-4-performance-and-socioeconomic-status",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#makeover-4-performance-and-socioeconomic-status",
    "title": "DataViz Makeover of Take-Home Exercise 1",
    "section": "3.4 Makeover 4: Performance and Socioeconomic Status",
    "text": "3.4 Makeover 4: Performance and Socioeconomic Status\nFor this makeover, the original focused more on the Math performance, hence I have used the Math performance for my makeover too.\n\n3.4.1 Original DataViz\n\n\n\n\n\n\n\n3.4.2 Critique\nThe critique is similar to that in 3.3 as the plots used are similar.\n\n\n\n\n\n\nClarity\n\n💚 Individually, both the box plot and the density distribution of the Math score by socioeconomic status are clear in showing the data.\n❌ However, they 2 plots are plotted separately. A better plot would be one where the boxplot is placed below the density curve, such as that of the raincloud plot.\n❌ Does not have a title and subtitle to provide context and/or insights derived from the visualisation.\n❌ The axes of the 2 plots are switched, hence making them more difficult to be compared visually.\n\n\n\nAesthetics\n\n💚 Overall, the individual plots are neat and the information is shown in clear fonts and font sizes.\n❌ x-axis ticks on the boxplot is redundant since x is a categorical variable.\n❌ The colours used in both plots are different, though there is not much reason for them to be different since both plots are referirng to the school type.\n❌ y-axis titles can be flipped for better readability.\n❌ Use of different themes for both plots makes the overall look and feel somewhat disjointed.\n\n\n\n\n\n\n3.4.3 Sketch of Makeover design\n\n\n\n\n\n\n\n3.4.4 Makeover DataViz\nThe code chunk below was used to provide the DataViz makeover to address the above critique:\n\n\nCode\nstu_viz4 &lt;- stu_qqq_SG_final %&gt;% \n  select(c(\"STUDENT_ID\", \"MATH\", \"SOCIOECONOMIC_STATUS\"))\n\npal &lt;- c(\"#FF8C00\", \"#A034F0\", \"#159090\", \"red\")\n\nggplot(stu_viz4,\n       aes(x=SOCIOECONOMIC_STATUS,\n           y=MATH)) +\n  stat_halfeye(aes(color=SOCIOECONOMIC_STATUS, \n                   fill=after_scale(colorspace::lighten(color, .3))),\n               adjust=0.5,\n               justification=-0.3,\n               .width=0,\n               point_colour = NA,\n               scale=0.7,\n               alpha = 0.4) +\n  geom_boxplot(width=.1,\n               outlier.alpha = 0.4,\n               outlier.color = \"blue\") +\n  scale_color_manual(values = pal, guide = \"none\") +\n  scale_fill_manual(values = pal, guide = \"none\") +\n  labs(y=\"Math score\") +\n  coord_flip() +\n  theme_minimal() +\n  theme(axis.title.y = element_blank(),\n        axis.title.x = element_text(color = \"grey30\")) +\n  plot_annotation(title = \"Students with better socioeconomic status achieve better performance\", subtitle = \"Results show relatively big difference between upper and lower tiers of socioeconomic status\")\n\n\n\n\n\nImprovements from the makeover:\nClarity:\n\nCombined the density curve and the boxplot on the same plot for easier comparisons, but did not choose the full raincloud plot (since the dot plot is not included) so that the plot will not be too cluttered.\nTitle and subtitle used to provide meaningful context for the plot, so that the audience can better make their own interpretations and form their own insights.\nSynchronised the y- and x-axis for all the plots for easier visual comparisons.\n\nAesthetics:\n\nSynchronised the x-axis for easier comparisons.\nNumber of gridlines are reduced and ink reduced as well, so that they do not interfere too much with the important details on the plot."
  }
]